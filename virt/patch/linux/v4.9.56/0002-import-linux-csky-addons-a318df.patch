From 721a07830287886e9ce7f9355349f4c29b509e16 Mon Sep 17 00:00:00 2001
From: Wu Zhangjin <wuzhangjin@gmail.com>
Date: Tue, 21 Nov 2017 22:16:48 +0800
Subject: [PATCH 2/3] import linux-csky-addons a318df

https://github.com/c-sky/linux-csky-addons

Signed-off-by: Wu Zhangjin <wuzhangjin@gmail.com>
---
 addons/Kconfig                                   |    4 +
 addons/Makefile                                  |    8 +
 addons/drivers/Kconfig                           |   14 +
 addons/drivers/Makefile                          |   13 +
 addons/drivers/clk/csky/Kconfig                  |    6 +
 addons/drivers/clk/csky/Makefile                 |    4 +
 addons/drivers/clk/csky/csky-clk-gate.c          |  121 ++
 addons/drivers/clk/csky/csky-clk-mux.c           |   95 ++
 addons/drivers/crypto/Kconfig                    |   28 +
 addons/drivers/crypto/Makefile                   |   21 +
 addons/drivers/crypto/csky_aes.c                 |  661 +++++++++++
 addons/drivers/crypto/csky_aes.h                 |   45 +
 addons/drivers/crypto/csky_crc.c                 |  793 +++++++++++++
 addons/drivers/crypto/csky_crc.h                 |   47 +
 addons/drivers/crypto/csky_rsa.c                 | 1352 ++++++++++++++++++++++
 addons/drivers/crypto/csky_rsa.h                 |   71 ++
 addons/drivers/crypto/csky_sha.c                 | 1000 ++++++++++++++++
 addons/drivers/crypto/csky_sha.h                 |   71 ++
 addons/drivers/crypto/csky_tdes.c                |  639 ++++++++++
 addons/drivers/crypto/csky_tdes.h                |   50 +
 addons/drivers/gpu/drm/csky/Kconfig              |   11 +
 addons/drivers/gpu/drm/csky/Makefile             |    6 +
 addons/drivers/gpu/drm/csky/csky_hdmi.c          |  740 ++++++++++++
 addons/drivers/gpu/drm/csky/csky_hdmi.h          |  432 +++++++
 addons/drivers/mailbox/Kconfig                   |   22 +
 addons/drivers/mailbox/Makefile                  |    9 +
 addons/drivers/mailbox/mailbox-client-csky.c     |  337 ++++++
 addons/drivers/mailbox/mailbox-csky-internal.h   |   44 +
 addons/drivers/mailbox/mailbox-csky.c            |  298 +++++
 addons/drivers/mailbox/mailbox-csky.h            |   68 ++
 addons/drivers/mailbox/tty-mailbox-client-csky.c |  399 +++++++
 addons/drivers/mailbox/tty-mailbox-csky.c        |  460 ++++++++
 addons/drivers/pinctrl/Kconfig                   |   22 +
 addons/drivers/pinctrl/Makefile                  |    4 +
 addons/drivers/pinctrl/pinctrl-csky.c            | 1349 +++++++++++++++++++++
 addons/drivers/pinctrl/pinctrl-csky.h            |   35 +
 addons/drivers/pwm/Kconfig                       |   13 +
 addons/drivers/pwm/Makefile                      |    4 +
 addons/drivers/pwm/pwm-csky.c                    |  274 +++++
 addons/drivers/reset/Kconfig                     |    7 +
 addons/drivers/reset/Makefile                    |    3 +
 addons/drivers/reset/reset-csky.c                |  128 ++
 addons/drivers/video/fbdev/Kconfig               |   12 +
 addons/drivers/video/fbdev/Makefile              |    2 +
 addons/drivers/video/fbdev/csky-fb.c             |  715 ++++++++++++
 addons/drivers/video/fbdev/csky-fb.h             |  196 ++++
 addons/drivers/vpu/Kconfig                       |   24 +
 addons/drivers/watchdog/Kconfig                  |   12 +
 addons/drivers/watchdog/Makefile                 |    2 +
 addons/drivers/watchdog/csky-wdt.c               |  275 +++++
 addons/drivers/watchdog/csky-wdt.h               |   40 +
 addons/sound/soc/codecs/Kconfig                  |    7 +
 addons/sound/soc/codecs/Makefile                 |    2 +
 addons/sound/soc/codecs/csky-dummy-codec.c       |   99 ++
 addons/sound/soc/csky/Kconfig                    |   16 +
 addons/sound/soc/csky/Makefile                   |    2 +
 addons/sound/soc/csky/csky-i2s.c                 |  688 +++++++++++
 addons/sound/soc/csky/csky-i2s.h                 |  214 ++++
 addons/sound/soc/csky/csky-pcm-pio.c             |  300 +++++
 addons/sound/soc/csky/csky-pcm.c                 |  600 ++++++++++
 60 files changed, 12914 insertions(+)
 create mode 100644 addons/Kconfig
 create mode 100644 addons/Makefile
 create mode 100644 addons/drivers/Kconfig
 create mode 100644 addons/drivers/Makefile
 create mode 100644 addons/drivers/clk/csky/Kconfig
 create mode 100644 addons/drivers/clk/csky/Makefile
 create mode 100644 addons/drivers/clk/csky/csky-clk-gate.c
 create mode 100644 addons/drivers/clk/csky/csky-clk-mux.c
 create mode 100644 addons/drivers/crypto/Kconfig
 create mode 100644 addons/drivers/crypto/Makefile
 create mode 100644 addons/drivers/crypto/csky_aes.c
 create mode 100644 addons/drivers/crypto/csky_aes.h
 create mode 100644 addons/drivers/crypto/csky_crc.c
 create mode 100644 addons/drivers/crypto/csky_crc.h
 create mode 100644 addons/drivers/crypto/csky_rsa.c
 create mode 100644 addons/drivers/crypto/csky_rsa.h
 create mode 100644 addons/drivers/crypto/csky_sha.c
 create mode 100644 addons/drivers/crypto/csky_sha.h
 create mode 100644 addons/drivers/crypto/csky_tdes.c
 create mode 100644 addons/drivers/crypto/csky_tdes.h
 create mode 100644 addons/drivers/gpu/drm/csky/Kconfig
 create mode 100644 addons/drivers/gpu/drm/csky/Makefile
 create mode 100644 addons/drivers/gpu/drm/csky/csky_hdmi.c
 create mode 100644 addons/drivers/gpu/drm/csky/csky_hdmi.h
 create mode 100644 addons/drivers/mailbox/Kconfig
 create mode 100644 addons/drivers/mailbox/Makefile
 create mode 100644 addons/drivers/mailbox/mailbox-client-csky.c
 create mode 100644 addons/drivers/mailbox/mailbox-csky-internal.h
 create mode 100644 addons/drivers/mailbox/mailbox-csky.c
 create mode 100644 addons/drivers/mailbox/mailbox-csky.h
 create mode 100644 addons/drivers/mailbox/tty-mailbox-client-csky.c
 create mode 100644 addons/drivers/mailbox/tty-mailbox-csky.c
 create mode 100644 addons/drivers/pinctrl/Kconfig
 create mode 100644 addons/drivers/pinctrl/Makefile
 create mode 100644 addons/drivers/pinctrl/pinctrl-csky.c
 create mode 100644 addons/drivers/pinctrl/pinctrl-csky.h
 create mode 100644 addons/drivers/pwm/Kconfig
 create mode 100644 addons/drivers/pwm/Makefile
 create mode 100644 addons/drivers/pwm/pwm-csky.c
 create mode 100644 addons/drivers/reset/Kconfig
 create mode 100644 addons/drivers/reset/Makefile
 create mode 100644 addons/drivers/reset/reset-csky.c
 create mode 100644 addons/drivers/video/fbdev/Kconfig
 create mode 100644 addons/drivers/video/fbdev/Makefile
 create mode 100644 addons/drivers/video/fbdev/csky-fb.c
 create mode 100644 addons/drivers/video/fbdev/csky-fb.h
 create mode 100644 addons/drivers/vpu/Kconfig
 create mode 100644 addons/drivers/watchdog/Kconfig
 create mode 100644 addons/drivers/watchdog/Makefile
 create mode 100644 addons/drivers/watchdog/csky-wdt.c
 create mode 100644 addons/drivers/watchdog/csky-wdt.h
 create mode 100644 addons/sound/soc/codecs/Kconfig
 create mode 100644 addons/sound/soc/codecs/Makefile
 create mode 100644 addons/sound/soc/codecs/csky-dummy-codec.c
 create mode 100644 addons/sound/soc/csky/Kconfig
 create mode 100644 addons/sound/soc/csky/Makefile
 create mode 100644 addons/sound/soc/csky/csky-i2s.c
 create mode 100644 addons/sound/soc/csky/csky-i2s.h
 create mode 100644 addons/sound/soc/csky/csky-pcm-pio.c
 create mode 100644 addons/sound/soc/csky/csky-pcm.c

diff --git a/addons/Kconfig b/addons/Kconfig
new file mode 100644
index 0000000..aba189f
--- /dev/null
+++ b/addons/Kconfig
@@ -0,0 +1,4 @@
+
+source "addons/drivers/Kconfig"
+source "addons/sound/soc/csky/Kconfig"
+source "addons/sound/soc/codecs/Kconfig"
diff --git a/addons/Makefile b/addons/Makefile
new file mode 100644
index 0000000..9a80051
--- /dev/null
+++ b/addons/Makefile
@@ -0,0 +1,8 @@
+#
+# Makefile for the Linux kernel addon device drivers.
+#
+KBUILD_CFLAGS   += -O0
+
+obj-y += drivers/
+obj-y += sound/soc/csky/
+obj-y += sound/soc/codecs/
diff --git a/addons/drivers/Kconfig b/addons/drivers/Kconfig
new file mode 100644
index 0000000..89bced4
--- /dev/null
+++ b/addons/drivers/Kconfig
@@ -0,0 +1,14 @@
+menu "Device Drivers"
+
+source "addons/drivers/pinctrl/Kconfig"
+source "addons/drivers/vpu/Kconfig"
+source "addons/drivers/video/fbdev/Kconfig"
+source "addons/drivers/reset/Kconfig"
+source "addons/drivers/mailbox/Kconfig"
+source "addons/drivers/crypto/Kconfig"
+source "addons/drivers/watchdog/Kconfig"
+source "addons/drivers/clk/csky/Kconfig"
+source "addons/drivers/pwm/Kconfig"
+source "addons/drivers/gpu/drm/csky/Kconfig"
+endmenu
+
diff --git a/addons/drivers/Makefile b/addons/drivers/Makefile
new file mode 100644
index 0000000..b2725ab
--- /dev/null
+++ b/addons/drivers/Makefile
@@ -0,0 +1,13 @@
+#
+# Makefile for the Linux kernel addon device drivers.
+#
+
+obj-y	+= pinctrl/
+obj-y	+= video/fbdev/
+obj-y	+= reset/
+obj-y	+= mailbox/
+obj-y	+= crypto/
+obj-y	+= watchdog/
+obj-y	+= clk/csky/
+obj-y	+= pwm/
+obj-y	+= gpu/drm/csky/
diff --git a/addons/drivers/clk/csky/Kconfig b/addons/drivers/clk/csky/Kconfig
new file mode 100644
index 0000000..2032649
--- /dev/null
+++ b/addons/drivers/clk/csky/Kconfig
@@ -0,0 +1,6 @@
+
+config CLK_CSKY
+	bool "C-SKY Clock Driver"
+	default n
+	help
+	  Support for the C-SKY SoC Family clocks.
diff --git a/addons/drivers/clk/csky/Makefile b/addons/drivers/clk/csky/Makefile
new file mode 100644
index 0000000..fc8541b
--- /dev/null
+++ b/addons/drivers/clk/csky/Makefile
@@ -0,0 +1,4 @@
+
+obj-$(CONFIG_CLK_CSKY) += \
+		csky-clk-mux.o \
+		csky-clk-gate.o
diff --git a/addons/drivers/clk/csky/csky-clk-gate.c b/addons/drivers/clk/csky/csky-clk-gate.c
new file mode 100644
index 0000000..f1859b5
--- /dev/null
+++ b/addons/drivers/clk/csky/csky-clk-gate.c
@@ -0,0 +1,121 @@
+/*
+ * C-SKY SoCs Clock driver
+ *
+ * Copyright (C) 2017 C-SKY MicroSystems Co.,Ltd.
+ *
+ * Author: Lei Ling <lei_ling@c-sky.com>
+ *
+ * This software is licensed under the terms of the GNU General Public
+ * License version 2, as published by the Free Software Foundation, and
+ * may be copied, distributed, and modified under those terms.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include <linux/clk.h>
+#include <linux/clk-provider.h>
+#include <linux/of.h>
+#include <linux/of_address.h>
+#include <linux/slab.h>
+#include <linux/spinlock.h>
+
+static DEFINE_SPINLOCK(clk_gate_lock);
+
+static void unregister_clk_gate(struct clk_onecell_data *clk_data)
+{
+	unsigned int i;
+
+	if ((clk_data == NULL) || (clk_data->clks == NULL))
+		return;
+
+	for (i = 0; i <= clk_data->clk_num; i++) {
+		if (clk_data->clks[i] != NULL) {
+			clk_unregister_gate(clk_data->clks[i]);
+			clk_data->clks[i] = NULL;
+		}
+	}
+}
+
+static void __init csky_clk_gate_init(struct device_node *node)
+{
+	struct clk_onecell_data *clk_data;
+	int clk_num;
+	const char *clk_parent;
+	const char *clk_name;
+	void __iomem *reg;
+	void __iomem *clk_reg;
+	u8 clk_bit;
+	struct property *prop;
+	const __be32 *p;
+	u32 index;
+	int i = 0;
+	struct resource res;
+
+	reg = of_io_request_and_map(node, 0, of_node_full_name(node));
+	if (IS_ERR(reg)) {
+		pr_err("Failed to map registers for clk: %s\n",
+		       of_node_full_name(node));
+		return;
+	}
+
+	clk_data = kzalloc(sizeof(struct clk_onecell_data), GFP_KERNEL);
+	if (!clk_data) {
+		pr_err("Failed to allocate memory\n");
+		goto err_unmap;
+	}
+
+	clk_num = of_property_count_u32_elems(node, "clock-indices");
+	of_property_read_u32_index(node, "clock-indices",
+				   clk_num - 1, &clk_num);
+	clk_num++;
+
+	clk_data->clk_num = clk_num;
+	clk_data->clks = kzalloc(clk_num * sizeof(struct clk *), GFP_KERNEL);
+	if (!clk_data->clks) {
+		pr_err("Failed to allocate clk\n");
+		goto err_free_data;
+	}
+
+	clk_parent = of_clk_get_parent_name(node, 0);
+
+	of_property_for_each_u32(node, "clock-indices", prop, p, index) {
+		of_property_read_string_index(node, "clock-output-names",
+					      i, &clk_name);
+		i++;
+
+		clk_reg = reg + 4 * (index / 32);
+		clk_bit = index % 32;
+
+		clk_data->clks[index] = clk_register_gate(NULL, clk_name,
+							  clk_parent, 0,
+							  clk_reg, clk_bit,
+							  0, &clk_gate_lock);
+		if (IS_ERR(clk_data->clks[index])) {
+			pr_err("Failed to register clk: %s\n", clk_name);
+			goto err_unregister_clk;
+		}
+	}
+
+	if (of_clk_add_provider(node, of_clk_src_onecell_get, clk_data)) {
+		pr_err("Failed to add clock provider for gate\n");
+		goto err_unregister_clk;
+	}
+
+	return;
+
+err_unregister_clk:
+	unregister_clk_gate(clk_data);
+err_free_data:
+	if (clk_data->clks != NULL)
+		kfree(clk_data->clks);
+	kfree(clk_data);
+err_unmap:
+	iounmap(reg);
+	of_address_to_resource(node, 0, &res);
+	release_mem_region(res.start, resource_size(&res));
+}
+
+CLK_OF_DECLARE(csky_clk_gate, "csky,clk-gate", csky_clk_gate_init);
diff --git a/addons/drivers/clk/csky/csky-clk-mux.c b/addons/drivers/clk/csky/csky-clk-mux.c
new file mode 100644
index 0000000..3c5fcf1
--- /dev/null
+++ b/addons/drivers/clk/csky/csky-clk-mux.c
@@ -0,0 +1,95 @@
+/*
+ * C-SKY SoCs Clock driver
+ *
+ * Copyright (C) 2017 C-SKY MicroSystems Co.,Ltd.
+ *
+ * Author: Lei Ling <lei_ling@c-sky.com>
+ *
+ * This software is licensed under the terms of the GNU General Public
+ * License version 2, as published by the Free Software Foundation, and
+ * may be copied, distributed, and modified under those terms.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include <linux/clk.h>
+#include <linux/clk-provider.h>
+#include <linux/clkdev.h>
+#include <linux/of.h>
+#include <linux/of_address.h>
+#include <linux/reset-controller.h>
+#include <linux/slab.h>
+#include <linux/spinlock.h>
+
+static DEFINE_SPINLOCK(clk_mux_lock);
+
+/* Maximum number of parents our clocks have */
+#define CSKY_CLK_MAX_PARENTS	16
+
+static void __init csky_clk_mux_init(struct device_node *node)
+{
+	struct clk *clk;
+	const char *clk_name = node->name;
+	const char *parents[CSKY_CLK_MAX_PARENTS];
+	int num_parents;
+	void __iomem *reg;
+	u32 bit_shift;
+	u32 bit_width;
+	unsigned long flags;
+
+	reg = of_iomap(node, 0);
+	if (!reg) {
+		pr_err("Failed to map registers for clk: %s\n",
+		       of_node_full_name(node));
+		return;
+	}
+
+	num_parents = of_clk_parent_fill(node, parents, CSKY_CLK_MAX_PARENTS);
+
+	if (of_property_read_string(node, "clock-output-names", &clk_name)) {
+		pr_err("%s: failed to read clock-output-names from \"%s\"\n",
+		       __func__, of_node_full_name(node));
+		goto out_unmap;
+	}
+
+	if (of_property_read_u32(node, "bit-shift", &bit_shift) < 0) {
+		pr_err("Failed to get property: bit-shift\n");
+		goto out_unmap;
+	}
+
+	if (of_property_read_u32(node, "bit-width", &bit_width) < 0) {
+		pr_err("Failed to get property: bit-width\n");
+		goto out_unmap;
+	}
+
+	flags = CLK_SET_RATE_PARENT;
+	if (of_property_read_bool(node, "read-only"))
+		flags |= CLK_MUX_READ_ONLY;
+
+	clk = clk_register_mux(NULL, clk_name,
+			       parents, num_parents,
+			       flags,
+			       reg, bit_shift, bit_width,
+			       0, &clk_mux_lock);
+	if (IS_ERR(clk)) {
+		pr_err("%s: failed to register clk %s: %ld\n", __func__,
+		       clk_name, PTR_ERR(clk));
+		goto out_unmap;
+	}
+
+	if (of_clk_add_provider(node, of_clk_src_simple_get, clk)) {
+		pr_err("%s: failed to add clock provider for %s\n",
+		       __func__, clk_name);
+		clk_unregister_mux(clk);
+		goto out_unmap;
+	}
+
+	return;
+out_unmap:
+	iounmap(reg);
+	return;
+}
+CLK_OF_DECLARE(csky_clk_mux, "csky,clk-mux", csky_clk_mux_init);
diff --git a/addons/drivers/crypto/Kconfig b/addons/drivers/crypto/Kconfig
new file mode 100644
index 0000000..2bdb4a2
--- /dev/null
+++ b/addons/drivers/crypto/Kconfig
@@ -0,0 +1,28 @@
+#
+# CSKY CRYPTOGRAHPIC HW Engine Support
+#
+menuconfig CRYPTO_DEV_CSKY
+    tristate "C-SKY Cryptographic Engine Support"
+    depends on CSKY
+    help
+        This driver interface with the hardware crypto accelerator.
+        Supporting SHA, CRC, AES, TripDES and RSA
+
+if CRYPTO_DEV_CSKY
+
+config CSKY_CRYPTO_AES
+    bool "Support AES Engine Driver"
+
+config CSKY_CRYPTO_TDES
+    bool "Support TDES Engine Driver"
+
+config CSKY_CRYPTO_CRC
+    bool "Support CRC Engine Driver"
+
+config CSKY_CRYPTO_RSA
+    bool "Support RSA Engine Driver"
+
+config CSKY_CRYPTO_SHA
+    bool "Support SHA Engine Driver"
+
+endif # CRYPTO_DEV_CSKY
diff --git a/addons/drivers/crypto/Makefile b/addons/drivers/crypto/Makefile
new file mode 100644
index 0000000..8e26040
--- /dev/null
+++ b/addons/drivers/crypto/Makefile
@@ -0,0 +1,21 @@
+obj-$(CONFIG_CRYPTO_DEV_CSKY) += csky-cipher.o
+
+ifeq ($(CONFIG_CSKY_CRYPTO_AES), y)
+csky-cipher-objs += csky_aes.o
+endif
+
+ifeq ($(CONFIG_CSKY_CRYPTO_TDES), y)
+csky-cipher-objs += csky_tdes.o
+endif
+
+ifeq ($(CONFIG_CSKY_CRYPTO_CRC), y)
+csky-cipher-objs += csky_crc.o
+endif
+
+ifeq ($(CONFIG_CSKY_CRYPTO_RSA), y)
+csky-cipher-objs += csky_rsa.o
+endif
+
+ifeq ($(CONFIG_CSKY_CRYPTO_SHA), y)
+csky-cipher-objs += csky_sha.o
+endif
diff --git a/addons/drivers/crypto/csky_aes.c b/addons/drivers/crypto/csky_aes.c
new file mode 100644
index 0000000..e6eafb6
--- /dev/null
+++ b/addons/drivers/crypto/csky_aes.c
@@ -0,0 +1,661 @@
+/*
+ * Copyright (C) 2017 C-SKY MicroSystems Co.,Ltd.
+ * Author: Vincent Cui <xiaoxia_cui@c-sky.com>
+ *
+ * This software is licensed under the terms of the GNU General Public
+ * License version 2, as published by the Free Software Foundation, and
+ * may be copied, distributed, and modified under those terms.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ */
+
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/err.h>
+#include <linux/io.h>
+#include <linux/platform_device.h>
+#include <linux/device.h>
+#include <linux/errno.h>
+#include <linux/interrupt.h>
+#include <linux/irq.h>
+#include <linux/of_device.h>
+#include <linux/crypto.h>
+#include <crypto/algapi.h>
+#include <crypto/aes.h>
+#include "csky_aes.h"
+
+#define CSKY_AES_BUFFER_ORDER	2
+#define CSKY_AES_BUFFER_SIZE	(PAGE_SIZE << CSKY_AES_BUFFER_ORDER)
+
+#define AES_FLAGS_ENC		BIT(0)
+#define AES_FLAGS_DEC		BIT(1)
+#define AES_FLAGS_ECB		BIT(2)
+#define AES_FLAGS_CBC		BIT(3)
+
+#define AES_FLAGS_INIT		BIT(8)
+#define AES_FLAGS_BUSY		BIT(9)
+
+#define CSKY_AES_QUEUE_LENGTH	10
+
+#define SIZE_IN_WORDS(x)	(x>>2)
+
+#define HTOL(x)			((x & 0xff) << 24 | (x & 0xff00) << 8 | \
+				 (x & 0xff0000) >> 8 | (x & 0xff000000) >> 24)
+
+struct csky_aes_dev;
+
+struct csky_aes_base_ctx {
+	struct csky_aes_dev *dd;
+	int keylen;
+	u32 key[AES_KEYSIZE_256 / sizeof(u32)];
+	u32 block_size;
+};
+
+struct csky_aes_ctx {
+	struct csky_aes_base_ctx base;
+};
+
+struct csky_aes_reqctx {
+	unsigned long	mode;
+};
+
+struct csky_aes_dev {
+	struct list_head		list;
+	struct crypto_async_request	*areq;
+	struct csky_aes_base_ctx	*ctx;
+	struct device			*dev;
+	struct aes_reg __iomem		*reg_base;
+	struct tasklet_struct		done_task;
+
+	struct crypto_queue 		queue;
+	struct scatterlist 		*real_dst;
+	unsigned long			flags;
+	spinlock_t			lock;
+	size_t				total;
+	size_t				datalen;
+	u32				*data;
+	size_t				buflen;
+	void				*buf;
+};
+
+struct csky_aes_drv {
+	struct list_head	dev_list;
+	spinlock_t		lock;
+};
+
+static struct csky_aes_drv csky_aes = {
+	.dev_list = LIST_HEAD_INIT(csky_aes.dev_list),
+	.lock	  = __SPIN_LOCK_UNLOCKED(csky_aes.lock),
+};
+
+static struct csky_aes_dev *csky_aes_find_dev(struct csky_aes_base_ctx *ctx)
+{
+	struct csky_aes_dev *aes_dd = NULL;
+	struct csky_aes_dev *tmp;
+
+	spin_lock_bh(&csky_aes.lock);
+	if (!ctx->dd) {
+		list_for_each_entry(tmp, &csky_aes.dev_list, list) {
+			aes_dd = tmp;
+			break;
+		}
+		ctx->dd = aes_dd;
+	} else {
+		aes_dd = ctx->dd;
+	}
+	spin_unlock_bh(&csky_aes.lock);
+
+	return aes_dd;
+}
+
+static inline void csky_aes_setopcode(struct csky_aes_dev *dd, uint32_t opr)
+{
+	uint32_t tmp;
+
+	tmp  = readl_relaxed(&dd->reg_base->ctrl);
+	tmp &= ~0x00c0;
+	if (opr == AES_OPC_ENC)
+		tmp |= AES_OPC_ENC << 6;
+	else if (opr == AES_OPC_DEC)
+		tmp |= AES_OPC_DEC << 6;
+	else
+		tmp |= AES_OPC_EXP << 6;
+	writel_relaxed(tmp, &dd->reg_base->ctrl);
+}
+
+static inline void csky_aes_config_mode(struct csky_aes_dev *dd, int cbc_mode)
+{
+	uint32_t tmp;
+
+	tmp  = readl_relaxed(&dd->reg_base->ctrl);
+	tmp &= ~0x0008;
+	tmp |= (cbc_mode) ? (1 << 3): 0;
+	writel_relaxed(tmp, &dd->reg_base->ctrl);
+}
+
+static inline void csky_aes_set_key_length(struct csky_aes_dev *dd, int keylen)
+{
+	uint32_t tmp;
+	uint32_t key_len;
+
+	if (keylen == AES_KEYSIZE_128)
+		key_len = AES_KL_128;
+	else if (keylen == AES_KEYSIZE_192)
+		key_len = AES_KL_192;
+	else
+		key_len = AES_KL_256;
+
+	tmp = readl_relaxed(&dd->reg_base->ctrl);
+	tmp &= ~0x0030;
+	tmp |= key_len << 4;
+	writel_relaxed(tmp, &dd->reg_base->ctrl);
+}
+
+static inline void csky_aes_enable(struct csky_aes_dev *dd)
+{
+	uint32_t tmp;
+
+	tmp  = readl_relaxed(&dd->reg_base->ctrl);
+	tmp |= 1;
+	writel_relaxed(tmp, &dd->reg_base->ctrl);
+}
+
+static inline void csky_aes_disable(struct csky_aes_dev *dd)
+{
+	uint32_t tmp;
+
+	tmp  = readl_relaxed(&dd->reg_base->ctrl);
+	tmp &= ~1;
+	writel_relaxed(tmp, &dd->reg_base->ctrl);
+}
+
+static inline void csky_aes_set_endian(struct csky_aes_dev *dd,
+				       uint32_t endian)
+{
+	uint32_t tmp;
+
+	tmp = readl_relaxed(&dd->reg_base->ctrl);
+	if (endian == AES_ENDIAN_LT)
+		tmp &= ~AES_ENDIAN;
+	else
+		tmp |= AES_ENDIAN;
+	writel_relaxed(tmp, &dd->reg_base->ctrl);
+}
+
+static inline void csky_aes_init(struct csky_aes_dev *dd)
+{
+#ifdef __LITTLE_ENDIAN
+	csky_aes_set_endian(dd, AES_ENDIAN_LT);
+#else
+	csky_aes_set_endian(dd, AES_ENDIAN_BG);
+#endif
+	if (!(dd->flags & AES_FLAGS_INIT))
+		dd->flags |= AES_FLAGS_INIT;
+}
+
+static inline int csky_aes_check_int_status(struct csky_aes_dev *dd,
+					    uint32_t flag)
+{
+	return (readl_relaxed(&dd->reg_base->state) & flag) ? 1 : 0;
+}
+
+static inline size_t csky_aes_padlen(size_t len, size_t block_size)
+{
+	len &= block_size - 1;
+	return len ? block_size - len : 0;
+}
+
+static inline void csky_aes_in_block(struct csky_aes_dev *dd, uint32_t *data)
+{
+	int i;
+
+	for (i = 0; i < SIZE_IN_WORDS(AES_BLOCK_SIZE); i ++)
+		writel_relaxed(HTOL(data[i]),
+			&dd->reg_base->datain[SIZE_IN_WORDS(AES_BLOCK_SIZE)
+						- 1 - i]);
+}
+
+static inline void csky_aes_out_block(struct csky_aes_dev *dd, uint32_t *data)
+{
+	int i;
+
+	for (i = 0; i < SIZE_IN_WORDS(AES_BLOCK_SIZE); i ++)
+		data[i] = HTOL(readl_relaxed(
+			&dd->reg_base->dataout[SIZE_IN_WORDS(AES_BLOCK_SIZE)
+						- 1 - i]));
+}
+
+static inline int csky_aes_complete(struct csky_aes_dev *dd, int err)
+{
+	dd->flags &= ~AES_FLAGS_BUSY;
+	dd->areq->complete(dd->areq, err);
+
+	tasklet_schedule(&dd->done_task);
+
+	return err;
+}
+
+static int csky_aes_engine_op(struct csky_aes_dev *dd)
+{
+	int cbc_mode = dd->flags & AES_FLAGS_CBC;
+	int i;
+	int err = 0;
+	int len;
+
+	csky_aes_config_mode(dd, cbc_mode);
+	for (i = 0; i < dd->datalen; i += AES_BLOCK_SIZE) {
+		csky_aes_in_block(dd, dd->data);
+
+		csky_aes_enable(dd);
+		csky_aes_check_int_status(dd, AES_IT_BUSY);
+		csky_aes_disable(dd);
+
+		csky_aes_out_block(dd, dd->data);
+		dd->data += SIZE_IN_WORDS(AES_BLOCK_SIZE);
+	}
+
+	if (dd->flags & AES_FLAGS_ENC)
+		len = dd->datalen;
+	else if (dd->flags & AES_FLAGS_DEC)
+		len = dd->total;
+	else
+		return csky_aes_complete(dd, -EINVAL);
+
+	if (!sg_copy_from_buffer(dd->real_dst, sg_nents(dd->real_dst),
+							dd->buf, len))
+		err = -EINVAL;
+
+	return csky_aes_complete(dd, err);
+}
+
+static int csky_aes_start(struct csky_aes_dev *dd,
+			  struct scatterlist *src,
+			  struct scatterlist *dst,
+			  size_t len)
+{
+	size_t padlen = csky_aes_padlen(len, AES_BLOCK_SIZE);
+
+	if (!(dd->flags & AES_FLAGS_INIT)) {
+		return -EACCES;
+	}
+
+	if (unlikely(len == 0))
+		return -EINVAL;
+
+	sg_copy_to_buffer(src, sg_nents(src), dd->buf, len);
+
+	dd->real_dst= dst;
+	dd->total   = len;
+	dd->datalen = len + padlen;
+	dd->data	= (u32 *)dd->buf;
+
+	return 0;
+}
+
+static int csky_aes_set_key(struct csky_aes_dev *dd, const uint32_t *iv)
+{
+	int i;
+	uint32_t *key	= dd->ctx->key;
+	uint32_t  keylen = dd->ctx->keylen;
+
+	for (i = 0; i < SIZE_IN_WORDS(dd->ctx->keylen); i++)
+		writel_relaxed(HTOL(key[i]),
+			&dd->reg_base->key[SIZE_IN_WORDS(dd->ctx->keylen)
+					   - 1 - i]);
+
+	csky_aes_set_key_length(dd, keylen);
+
+	if (dd->flags & AES_FLAGS_ENC)
+		csky_aes_setopcode(dd, AES_OPC_ENC);
+	else if (dd->flags & AES_FLAGS_DEC) {
+		csky_aes_setopcode(dd, AES_OPC_EXP);
+		csky_aes_enable(dd);
+		while (csky_aes_check_int_status(dd, AES_IT_KEYINT));
+		csky_aes_disable(dd);
+		csky_aes_setopcode(dd, AES_OPC_DEC);
+	}
+
+	if (dd->flags & AES_FLAGS_CBC) {
+		for (i = 0; i < SIZE_IN_WORDS(AES_BLOCK_SIZE); i++) {
+			writel_relaxed(HTOL(iv[i]),
+				&dd->reg_base->iv[SIZE_IN_WORDS(AES_BLOCK_SIZE)
+						  - 1 - i]);
+		}
+	}
+
+	return 0;
+}
+
+static int csky_aes_handle(struct csky_aes_dev *dd)
+{
+	struct ablkcipher_request *req = ablkcipher_request_cast(dd->areq);
+	struct csky_aes_reqctx	*rctx  = ablkcipher_request_ctx(req);
+	int ret;
+
+	dd->flags &= ~(AES_FLAGS_ECB | AES_FLAGS_CBC |
+				   AES_FLAGS_ENC | AES_FLAGS_DEC);
+	dd->flags |= rctx->mode;
+
+	csky_aes_init(dd);
+	ret = csky_aes_start(dd, req->src, req->dst, req->nbytes);
+	if (ret)
+		return ret;
+
+	ret = csky_aes_set_key(dd, req->info);
+	if (ret)
+		return ret;
+
+	ret = csky_aes_engine_op(dd);
+	return ret;
+}
+
+static int csky_aes_handle_queue(struct csky_aes_dev *dd,
+				 struct crypto_async_request *new_areq)
+{
+	struct crypto_async_request *areq, *backlog;
+	struct csky_aes_base_ctx	*ctx;
+	unsigned long flags;
+	int ret = 0;
+
+	spin_lock_irqsave(&dd->lock, flags);
+	if (new_areq)
+		ret = crypto_enqueue_request(&dd->queue, new_areq);
+	if (dd->flags & AES_FLAGS_BUSY) {
+		spin_unlock_irqrestore(&dd->lock, flags);
+		return ret;
+	}
+	backlog = crypto_get_backlog(&dd->queue);
+	areq 	= crypto_dequeue_request(&dd->queue);
+	if (areq)
+		dd->flags |= AES_FLAGS_BUSY;
+	spin_unlock_irqrestore(&dd->lock, flags);
+
+	if (!areq)
+		return ret;
+
+	if (backlog)
+		backlog->complete(backlog, -EINPROGRESS);
+
+	ctx		 = crypto_tfm_ctx(areq->tfm);
+	dd->areq = areq;
+	dd->ctx  = ctx;
+
+	return csky_aes_handle(dd);
+}
+
+static int csky_aes_crypt(struct ablkcipher_request *req, unsigned long mode)
+{
+	struct csky_aes_base_ctx *ctx;
+	struct csky_aes_reqctx   *rctx;
+	struct csky_aes_dev		 *dd;
+
+	ctx = crypto_ablkcipher_ctx(crypto_ablkcipher_reqtfm(req));
+	if (!ctx)
+		return -ENOMEM;
+	dd  = csky_aes_find_dev(ctx);
+	if (!dd)
+		return -ENODEV;
+
+	rctx		= ablkcipher_request_ctx(req);
+	rctx->mode  = mode;
+
+	if ((mode & AES_FLAGS_ECB) || (mode & AES_FLAGS_CBC))
+		ctx->block_size = AES_BLOCK_SIZE;
+
+	return csky_aes_handle_queue(dd, &req->base);
+}
+
+static int csky_aes_setkey(struct crypto_ablkcipher *tfm, const u8 *key,
+						   unsigned int keylen)
+{
+	struct csky_aes_base_ctx *ctx = crypto_ablkcipher_ctx(tfm);
+
+	if (keylen != AES_KEYSIZE_128 &&
+		keylen != AES_KEYSIZE_192 &&
+		keylen != AES_KEYSIZE_256) {
+		crypto_ablkcipher_set_flags(tfm, CRYPTO_TFM_RES_BAD_KEY_LEN);
+		return -EINVAL;
+	}
+
+	memcpy(ctx->key, key, keylen);
+	ctx->keylen = keylen;
+
+	return 0;
+}
+
+static int csky_aes_ecb_encrypt(struct ablkcipher_request *req)
+{
+	return csky_aes_crypt(req, AES_FLAGS_ECB | AES_FLAGS_ENC);
+}
+
+static int csky_aes_ecb_decrypt(struct ablkcipher_request *req)
+{
+	return csky_aes_crypt(req, AES_FLAGS_ECB | AES_FLAGS_DEC);
+}
+
+static int csky_aes_cbc_encrypt(struct ablkcipher_request *req)
+{
+	return csky_aes_crypt(req, AES_FLAGS_CBC | AES_FLAGS_ENC);
+}
+
+static int csky_aes_cbc_decrypt(struct ablkcipher_request *req)
+{
+	return csky_aes_crypt(req, AES_FLAGS_CBC | AES_FLAGS_DEC);
+}
+
+static int csky_aes_cra_init(struct crypto_tfm *tfm)
+{
+	tfm->crt_ablkcipher.reqsize = sizeof(struct csky_aes_reqctx);
+
+	return 0;
+}
+
+static void csky_aes_cra_exit(struct crypto_tfm *tfm)
+{
+
+}
+
+static struct crypto_alg csky_aes_algs[] = {
+	{
+		.cra_name		= "ecb(aes)",
+		.cra_driver_name	= "csky-ecb-aes",
+		.cra_priority		= 200,
+		.cra_flags 		= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,
+		.cra_blocksize		= AES_BLOCK_SIZE,
+		.cra_ctxsize		= sizeof(struct csky_aes_ctx),
+		.cra_alignmask		= 0xf,
+		.cra_type		= &crypto_ablkcipher_type,
+		.cra_module		= THIS_MODULE,
+		.cra_init		= csky_aes_cra_init,
+		.cra_exit		= csky_aes_cra_exit,
+		.cra_u.ablkcipher	= {
+			.min_keysize	= AES_MIN_KEY_SIZE,
+			.max_keysize	= AES_MAX_KEY_SIZE,
+			.setkey		= csky_aes_setkey,
+			.encrypt	= csky_aes_ecb_encrypt,
+			.decrypt	= csky_aes_ecb_decrypt,
+		}
+	},
+	{
+		.cra_name		= "cbc(aes)",
+		.cra_driver_name	= "csky-cbc-aes",
+		.cra_priority		= 200,
+		.cra_flags		= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,
+		.cra_blocksize		= AES_BLOCK_SIZE,
+		.cra_ctxsize		= sizeof(struct csky_aes_ctx),
+		.cra_alignmask		= 0xf,
+		.cra_type		= &crypto_ablkcipher_type,
+		.cra_module		= THIS_MODULE,
+		.cra_init		= csky_aes_cra_init,
+		.cra_exit		= csky_aes_cra_exit,
+		.cra_u.ablkcipher	= {
+			.min_keysize	= AES_MIN_KEY_SIZE,
+			.max_keysize	= AES_MAX_KEY_SIZE,
+			.ivsize		= AES_BLOCK_SIZE,
+			.setkey		= csky_aes_setkey,
+			.encrypt	= csky_aes_cbc_encrypt,
+			.decrypt	= csky_aes_cbc_decrypt,
+		}
+	},
+
+};
+
+static int csky_aes_buff_init(struct csky_aes_dev *dd)
+{
+	dd->buf		= (void *)__get_free_pages(GFP_KERNEL, CSKY_AES_BUFFER_ORDER);
+	dd->buflen	= CSKY_AES_BUFFER_SIZE;
+	dd->buflen &= ~(AES_BLOCK_SIZE - 1);
+
+	if (!dd->buf) {
+		dev_err(dd->dev, "unable to alloc pages.\n");
+		return -ENOMEM;
+	}
+
+	return 0;
+}
+
+static void csky_aes_buff_cleanup(struct csky_aes_dev *dd)
+{
+	if ((unsigned long)dd->buf)
+		free_pages((unsigned long)dd->buf, CSKY_AES_BUFFER_ORDER);
+}
+
+static void csky_aes_done_task(unsigned long data)
+{
+	struct csky_aes_dev *dd = (struct csky_aes_dev *)data;
+
+	csky_aes_handle_queue(dd, NULL);
+}
+
+static void csky_aes_unregister_algs(struct csky_aes_dev *dd)
+{
+	int i;
+
+	for (i = 0; i < ARRAY_SIZE(csky_aes_algs); i++)
+		crypto_unregister_alg(&csky_aes_algs[i]);
+}
+
+static int csky_aes_register_algs(struct csky_aes_dev *dd)
+{
+	int err, i, j;
+
+	for (i = 0; i < ARRAY_SIZE(csky_aes_algs); i++) {
+		err = crypto_register_alg(&csky_aes_algs[i]);
+		if (err) {
+			for (j = 0; j < i; j++)
+				crypto_unregister_alg(&csky_aes_algs[j]);
+			return err;
+		}
+	}
+
+	return 0;
+}
+
+static int csky_aes_probe(struct platform_device *pdev)
+{
+	struct csky_aes_dev *aes_dd;
+	struct device *dev = &pdev->dev;
+	struct resource *aes_res;
+	int err;
+
+	aes_dd = devm_kzalloc(&pdev->dev, sizeof(*aes_dd), GFP_KERNEL);
+	if (aes_dd == NULL) {
+		dev_err(dev, "unable to alloc data struct.\n");
+		err = -ENOMEM;
+		goto aes_dd_err;
+	}
+
+	aes_dd->dev = dev;
+
+	platform_set_drvdata(pdev, aes_dd);
+
+	INIT_LIST_HEAD(&aes_dd->list);
+	spin_lock_init(&aes_dd->lock);
+
+	tasklet_init(&aes_dd->done_task, csky_aes_done_task, (unsigned long)aes_dd);
+
+	crypto_init_queue(&aes_dd->queue, CSKY_AES_QUEUE_LENGTH);
+
+	aes_res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	if (!aes_res) {
+		err = -ENODEV;
+		goto res_err;
+	}
+
+	aes_dd->reg_base = devm_ioremap_resource(dev, aes_res);
+	if (IS_ERR(aes_dd->reg_base)) {
+		err = PTR_ERR(aes_dd->reg_base);
+		goto res_err;
+	}
+
+	err = csky_aes_buff_init(aes_dd);
+	if (err)
+		goto res_err;
+
+	spin_lock(&csky_aes.lock);
+	list_add_tail(&aes_dd->list, &csky_aes.dev_list);
+	spin_unlock(&csky_aes.lock);
+
+	err = csky_aes_register_algs(aes_dd);
+	if (err)
+		goto err_algs;
+
+	dev_info(dev, "CSKY AES Driver Initialized\n");
+
+	return 0;
+
+err_algs:
+	spin_lock(&csky_aes.lock);
+	list_del(&aes_dd->list);
+	spin_unlock(&csky_aes.lock);
+res_err:
+	tasklet_kill(&aes_dd->done_task);
+aes_dd_err:
+
+	return err;
+}
+
+static int csky_aes_remove(struct platform_device *pdev)
+{
+	static struct csky_aes_dev *aes_dd;
+
+	aes_dd = platform_get_drvdata(pdev);
+	if (!aes_dd)
+		return -ENODEV;
+
+	spin_lock(&csky_aes.lock);
+	list_del(&aes_dd->list);
+	spin_unlock(&csky_aes.lock);
+
+	csky_aes_buff_cleanup(aes_dd);
+
+	tasklet_kill(&aes_dd->done_task);
+	csky_aes_unregister_algs(aes_dd);
+
+	return 0;
+}
+
+static const struct of_device_id csky_aes_dt_ids[] = {
+	{ .compatible = "csky,aes-v1" },
+	{ /* sentinel */ }
+};
+MODULE_DEVICE_TABLE(of, csky_aes_dt_ids);
+
+static struct platform_driver csky_aes_driver = {
+	.probe	= csky_aes_probe,
+	.remove	= csky_aes_remove,
+	.driver	= {
+		.name = "csky_aes",
+		.of_match_table = of_match_ptr(csky_aes_dt_ids),
+	},
+};
+
+module_platform_driver(csky_aes_driver);
+
+MODULE_DESCRIPTION("CSKY AES hw acceleration support.");
+MODULE_LICENSE("GPL v2");
+MODULE_AUTHOR("Vincent Cui <xiaoxia_cui@c-sky.com>");
diff --git a/addons/drivers/crypto/csky_aes.h b/addons/drivers/crypto/csky_aes.h
new file mode 100644
index 0000000..d39fc50
--- /dev/null
+++ b/addons/drivers/crypto/csky_aes.h
@@ -0,0 +1,45 @@
+/*
+ * Copyright (C) 2017 C-SKY MicroSystems Co.,Ltd.
+ * Author: Vincent Cui <xiaoxia_cui@c-sky.com>
+ *
+ * This software is licensed under the terms of the GNU General Public
+ * License version 2, as published by the Free Software Foundation, and
+ * may be copied, distributed, and modified under those terms.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ */
+#ifndef __CSKY_AES_H
+#define __CSKY_AES_H
+
+
+#define AES_ENDIAN	0x00000100
+#define AES_ENDIAN_LT	0
+#define AES_ENDIAN_BG	1
+
+#define AES_IT_DATAINT	0x4
+#define AES_IT_KEYINT	0x2
+#define AES_IT_BUSY	0x1
+#define AES_IT_ALL	0x7
+
+#define AES_OPC_ENC	0x00
+#define AES_OPC_DEC	0x01
+#define AES_OPC_EXP	0X02
+
+#define AES_KL_128	0
+#define AES_KL_192	1
+#define AES_KL_256	2
+
+struct aes_reg {
+	uint32_t datain[4];	/* Data input 0~127 */
+	uint32_t key[8];	/* Key 0~255        */
+	uint32_t iv[4];		/* Initial Vector: 0~127 */
+	uint32_t ctrl;		/* AES Control Register */
+	uint32_t state;		/* AES State Register */
+	uint32_t dataout[4];	/* Data Output 0~127 */
+};
+
+#endif /* __CSKY_AES_H */
\ No newline at end of file
diff --git a/addons/drivers/crypto/csky_crc.c b/addons/drivers/crypto/csky_crc.c
new file mode 100644
index 0000000..70ac6c4
--- /dev/null
+++ b/addons/drivers/crypto/csky_crc.c
@@ -0,0 +1,793 @@
+/*
+ * Copyright (C) 2017 C-SKY MicroSystems Co.,Ltd.
+ * Author: Vincent Cui <xiaoxia_cui@c-sky.com>
+ *
+ * This software is licensed under the terms of the GNU General Public
+ * License version 2, as published by the Free Software Foundation, and
+ * may be copied, distributed, and modified under those terms.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ */
+
+#include <linux/err.h>
+#include <linux/device.h>
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/errno.h>
+#include <linux/interrupt.h>
+#include <linux/kernel.h>
+#include <linux/irq.h>
+#include <linux/io.h>
+#include <linux/of_device.h>
+#include <linux/platform_device.h>
+#include <linux/delay.h>
+#include <linux/crypto.h>
+#include <linux/cryptohash.h>
+#include <crypto/algapi.h>
+#include <crypto/hash.h>
+#include <crypto/internal/hash.h>
+#include <asm/unaligned.h>
+#include "csky_crc.h"
+
+#define CRC_CCRYPTO_QUEUE_LENGTH	5
+
+#define CHKSUM_BLOCK_SIZE		4
+#define CHKSUM32_DIGEST_SIZE		4
+#define CHKSUM16_DIGEST_SIZE		2
+#define CHKSUM8_DIGEST_SIZE		1
+#define CHKSUM_DIGEST_SIZE		CHKSUM32_DIGEST_SIZE
+
+#define CRC_CRYPTO_STATE_UPDATE		1
+#define CRC_CRYPTO_STATE_FINALUPDATE	2
+#define CRC_CRYPTO_STATE_FINISH		3
+
+struct csky_crc_reqctx {
+	u32 dummy;
+};
+
+struct csky_crypto_crc {
+	struct list_head		list;
+	struct device			*dev;
+	spinlock_t			lock;
+
+	struct crc_register __iomem	*regs;
+	struct ahash_request		*req;
+	struct tasklet_struct		done_task;
+	struct crypto_queue		queue;
+
+	u8				busy;
+};
+
+static struct csky_crypto_crc_list {
+	struct list_head dev_list;
+	spinlock_t	 lock;
+};
+
+static struct csky_crypto_crc_list crc_list = {
+	.dev_list = LIST_HEAD_INIT(crc_list.dev_list),
+	.lock	  = __SPIN_LOCK_UNLOCKED(crc_list.lock),
+};
+
+struct csky_crypto_crc_reqctx {
+	struct csky_crypto_crc *crc;
+
+	u32	total;
+	size_t	bufnext_len;
+	u8	bufnext[CHKSUM_DIGEST_SIZE];
+	u8	flag;
+};
+
+struct csky_crypto_crc_ctx {
+	struct csky_crypto_crc *crc;
+
+	u32	key;
+	u32	sel;
+	crc_mod_e mod;
+	crc_std_e std;
+};
+
+static struct scatterlist *sg_get(struct scatterlist *sg_list,
+				  unsigned int nents,
+				  unsigned int index)
+{
+	struct scatterlist *sg = NULL;
+	int i;
+
+	for_each_sg(sg_list, sg, nents, i)
+		if (i == index)
+			break;
+
+	return sg;
+}
+
+static int csky_crypto_crc_init_hw(struct csky_crypto_crc *crc,
+				   struct csky_crypto_crc_ctx *ctx)
+{
+	writel(ctx->sel, &crc->regs->sel);
+	writel(ctx->key, &crc->regs->init);
+
+	return 0;
+}
+
+static int csky_crypto_crc_init(struct ahash_request *req)
+{
+	struct crypto_ahash *tfm = crypto_ahash_reqtfm(req);
+	struct csky_crypto_crc_ctx *crc_ctx = crypto_ahash_ctx(tfm);
+	struct csky_crypto_crc_reqctx *ctx  = ahash_request_ctx(req);
+	struct csky_crypto_crc *crc;
+
+	spin_lock_bh(&crc_list.lock);
+	list_for_each_entry(crc, &crc_list.dev_list, list) {
+		crc_ctx->crc = crc;
+		break;
+	}
+	spin_unlock_bh(&crc_list.lock);
+
+	ctx->crc	 = crc;
+	ctx->bufnext_len = 0;
+	ctx->total	 = 0;
+	ctx->flag	 = 0;
+
+	return csky_crypto_crc_init_hw(crc, crc_ctx);
+}
+
+static int csky_crypto_crc_handle_sg(struct csky_crypto_crc *crc)
+{
+	struct ahash_request *req = crc->req;
+	struct csky_crypto_crc_reqctx *ctx = ahash_request_ctx(req);
+	void  *sg_src;
+	size_t sg_len;
+	struct scatterlist *sg;
+	int nsg, i, j;
+
+	nsg = sg_nents(req->src);
+	for (i = 0; i < nsg; i++) {
+		sg = sg_get(req->src, nsg, i);
+		sg_src = sg_virt(sg);
+		sg_len = sg_dma_len(sg);
+
+		if (ctx->bufnext_len + sg_len <  CHKSUM_DIGEST_SIZE) {
+			memcpy(ctx->bufnext + ctx->bufnext_len,
+				sg_src, sg_len);
+			ctx->bufnext_len += sg_len;
+			continue;
+		}
+
+		memcpy(ctx->bufnext + ctx->bufnext_len, sg_src,
+		       CHKSUM_DIGEST_SIZE - ctx->bufnext_len);
+		writel(*(u32 *)ctx->bufnext, &crc->regs->data);
+
+		sg_src += CHKSUM_DIGEST_SIZE - ctx->bufnext_len;
+		sg_len -= CHKSUM_DIGEST_SIZE - ctx->bufnext_len;
+
+		for (j = 0; j < sg_len / CHKSUM_DIGEST_SIZE; j++) {
+			memcpy(ctx->bufnext, sg_src, CHKSUM_DIGEST_SIZE);
+			writel(*(u32 *)ctx->bufnext, &crc->regs->data);
+			sg_src += CHKSUM_DIGEST_SIZE;
+		}
+
+		ctx->bufnext_len = sg_len % CHKSUM_DIGEST_SIZE;
+		memcpy(ctx->bufnext, sg_src, ctx->bufnext_len);
+	}
+	return 0;
+}
+
+static int csky_crypto_crc_handle(struct csky_crypto_crc *crc)
+{
+	struct ahash_request *req = crc->req;
+	struct csky_crypto_crc_reqctx *ctx = ahash_request_ctx(req);
+
+	if (ctx->flag == CRC_CRYPTO_STATE_FINISH) {
+		memset(ctx->bufnext + ctx->bufnext_len, 0,
+			CHKSUM_DIGEST_SIZE - ctx->bufnext_len);
+		writel(*(u32 *)ctx->bufnext, &crc->regs->data);
+	} else if (ctx->flag == CRC_CRYPTO_STATE_FINALUPDATE) {
+		if (ctx->bufnext_len + req->nbytes < CHKSUM_DIGEST_SIZE) {
+			memcpy(ctx->bufnext + ctx->bufnext_len,
+				sg_virt(req->src), req->nbytes);
+			ctx->bufnext_len += req->nbytes;
+
+			memset(ctx->bufnext + ctx->bufnext_len, 0,
+				CHKSUM_DIGEST_SIZE - ctx->bufnext_len);
+			writel(*(u32 *)ctx->bufnext, &crc->regs->data);
+		} else {
+			csky_crypto_crc_handle_sg(crc);
+			if (ctx->bufnext_len) {
+				memset(ctx->bufnext + ctx->bufnext_len, 0,
+					CHKSUM_DIGEST_SIZE - ctx->bufnext_len);
+				writel(*(u32 *)ctx->bufnext, &crc->regs->data);
+			}
+		}
+	} else if (ctx->flag == CRC_CRYPTO_STATE_UPDATE) {
+		csky_crypto_crc_handle_sg(crc);
+	} else {
+		return -EINVAL;
+	}
+
+	put_unaligned_le32(readl(&crc->regs->data), req->result);
+
+	crc->busy = 0;
+	if (req->base.complete)
+		req->base.complete(&req->base, 0);
+
+	tasklet_schedule(&crc->done_task);
+
+	return 0;
+}
+
+static int csky_crypto_crc_handle_queue(struct csky_crypto_crc *crc,
+					struct ahash_request *req)
+{
+	struct crypto_async_request   *async_req, *backlog;
+	struct csky_crypto_crc_reqctx *ctx;
+	unsigned long flags;
+	int ret = 0;
+
+	spin_lock_irqsave(&crc->lock, flags);
+	if (req)
+		ret = ahash_enqueue_request(&crc->queue, req);
+	if (crc->busy) {
+		spin_unlock_irqrestore(&crc->lock, flags);
+		return ret;
+	}
+	backlog   = crypto_get_backlog(&crc->queue);
+	async_req = crypto_dequeue_request(&crc->queue);
+	if (async_req)
+		crc->busy = 1;
+	spin_unlock_irqrestore(&crc->lock, flags);
+
+	if (!async_req)
+		return ret;
+
+	if (backlog)
+		backlog->complete(backlog, -EINPROGRESS);
+
+	req	  = ahash_request_cast(async_req);
+	crc->req = req;
+	ctx	  = ahash_request_ctx(req);
+
+	dev_dbg(crc->dev, "handling new req, flag=%u, nbytes: %d\n",
+		ctx->flag, req->nbytes);
+
+	if (ctx->flag == CRC_CRYPTO_STATE_FINISH) {
+		if (ctx->bufnext_len == 0) {
+			crc->busy = 0;
+			return 0;
+		}
+	} else if (ctx->flag == CRC_CRYPTO_STATE_UPDATE) {
+		if (ctx->bufnext_len + req->nbytes < CHKSUM_DIGEST_SIZE) {
+			memcpy(ctx->bufnext + ctx->bufnext_len,
+				sg_virt(req->src), req->nbytes);
+			ctx->bufnext_len += req->nbytes;
+
+			crc->busy = 0;
+			return 0;
+		}
+	}
+
+	return csky_crypto_crc_handle(crc);
+}
+
+static int csky_crypto_crc_update(struct ahash_request *req)
+{
+	struct csky_crypto_crc_reqctx *ctx = ahash_request_ctx(req);
+
+	dev_dbg(ctx->crc->dev, "crc_update\n");
+	if (!req->nbytes)
+		return 0;
+
+	ctx->total += req->nbytes;
+	ctx->flag   = CRC_CRYPTO_STATE_UPDATE;
+
+	return csky_crypto_crc_handle_queue(ctx->crc, req);
+}
+
+static int csky_crypto_crc_final(struct ahash_request *req)
+{
+	struct csky_crypto_crc_reqctx *ctx  = ahash_request_ctx(req);
+
+	dev_dbg(ctx->crc->dev, "crc_final\n");
+	ctx->flag = CRC_CRYPTO_STATE_FINISH;
+
+	return csky_crypto_crc_handle_queue(ctx->crc, req);
+}
+
+static int csky_crypto_crc_finup(struct ahash_request *req)
+{
+	struct csky_crypto_crc_reqctx *ctx  = ahash_request_ctx(req);
+
+	dev_dbg(ctx->crc->dev, "crc_finishupdate\n");
+
+	ctx->total += req->nbytes;
+	ctx->flag   = CRC_CRYPTO_STATE_FINALUPDATE;
+
+	return csky_crypto_crc_handle_queue(ctx->crc, req);
+}
+
+static int csky_crypto_crc_digest(struct ahash_request *req)
+{
+	int ret;
+
+	ret = csky_crypto_crc_init(req);
+	if (ret)
+		return ret;
+
+	return csky_crypto_crc_finup(req);
+}
+
+static int csky_crypto_crc_cra_init(struct csky_crypto_crc_ctx *ctx)
+{
+	int ret = 0;
+
+	if (ctx->mod == MOD_CRC16) {
+		switch (ctx->std) {
+		case STD_MODBUS:
+			ctx->sel = 0x0;
+			ctx->key = 0xFFFF;
+			break;
+		case STD_IBM:
+			ctx->sel = 0x0;
+			ctx->key = 0x0;
+			break;
+		case STD_MAXIM:
+			ctx->sel = 0x4;
+			ctx->key = 0x0;
+			break;
+		case STD_USB:
+			ctx->sel = 0x4;
+			ctx->key = 0xFFFF;
+			break;
+		case STD_CCITT:
+			ctx->sel = 0x1;
+			ctx->key = 0x0;
+			break;
+		case STD_X25:
+			ctx->sel = 0x5;
+			ctx->key = 0xFFFF;
+			break;
+		default:
+			ret = -EINVAL;
+		}
+	} else if (ctx->mod == MOD_CRC8) {
+		switch (ctx->std) {
+		case STD_MAXIM:
+			ctx->sel = 0x2;
+			ctx->key = 0x0;
+			break;
+		case STD_ROHC:
+			ctx->sel = 0x3;
+			ctx->key = 0xff;
+			break;
+		default:
+			ret = -EINVAL;
+		}
+	} else
+		ret = -EINVAL;
+
+	return ret;
+}
+
+static int csky_crypto_crc8maxim_cra_init(struct crypto_tfm *tfm)
+{
+	struct csky_crypto_crc_ctx *crc_ctx = crypto_tfm_ctx(tfm);
+	int ret = 0;
+
+	crypto_ahash_set_reqsize(__crypto_ahash_cast(tfm),
+				 sizeof(struct csky_crypto_crc_reqctx));
+
+	crc_ctx->mod = MOD_CRC8;
+	crc_ctx->std = STD_MAXIM;
+	ret = csky_crypto_crc_cra_init(crc_ctx);
+	if (ret)
+		dev_err(crc_ctx->crc->dev, "crc alg argument invalid \n");
+
+	return ret;
+}
+
+static int csky_crypto_crc8rohc_cra_init(struct crypto_tfm *tfm)
+{
+	struct csky_crypto_crc_ctx *crc_ctx = crypto_tfm_ctx(tfm);
+	int ret = 0;
+
+	crypto_ahash_set_reqsize(__crypto_ahash_cast(tfm),
+				 sizeof(struct csky_crypto_crc_reqctx));
+
+	crc_ctx->mod = MOD_CRC8;
+	crc_ctx->std = STD_ROHC;
+	ret = csky_crypto_crc_cra_init(crc_ctx);
+	if (ret)
+		dev_err(crc_ctx->crc->dev, "crc alg argument invalid \n");
+
+	return ret;
+}
+
+static int csky_crypto_crc16ibm_cra_init(struct crypto_tfm *tfm)
+{
+	struct csky_crypto_crc_ctx *crc_ctx = crypto_tfm_ctx(tfm);
+	int ret = 0;
+
+	crypto_ahash_set_reqsize(__crypto_ahash_cast(tfm),
+				 sizeof(struct csky_crypto_crc_reqctx));
+
+	crc_ctx->mod = MOD_CRC16;
+	crc_ctx->std = STD_IBM;
+	ret = csky_crypto_crc_cra_init(crc_ctx);
+	if (ret)
+		dev_err(crc_ctx->crc->dev, "crc alg argument invalid \n");
+
+	return ret;
+}
+
+static int csky_crypto_crc16maxim_cra_init(struct crypto_tfm *tfm)
+{
+	struct csky_crypto_crc_ctx *crc_ctx = crypto_tfm_ctx(tfm);
+	int ret = 0;
+
+	crypto_ahash_set_reqsize(__crypto_ahash_cast(tfm),
+				 sizeof(struct csky_crypto_crc_reqctx));
+
+	crc_ctx->mod = MOD_CRC16;
+	crc_ctx->std = STD_MAXIM;
+	ret = csky_crypto_crc_cra_init(crc_ctx);
+	if (ret)
+		dev_err(crc_ctx->crc->dev, "crc alg argument invalid \n");
+
+	return ret;
+}
+
+static int csky_crypto_crc16modbus_cra_init(struct crypto_tfm *tfm)
+{
+	struct csky_crypto_crc_ctx *crc_ctx = crypto_tfm_ctx(tfm);
+	int ret = 0;
+
+	crypto_ahash_set_reqsize(__crypto_ahash_cast(tfm),
+				 sizeof(struct csky_crypto_crc_reqctx));
+
+	crc_ctx->mod = MOD_CRC16;
+	crc_ctx->std = STD_MODBUS;
+	ret = csky_crypto_crc_cra_init(crc_ctx);
+	if (ret)
+		dev_err(crc_ctx->crc->dev, "crc alg argument invalid \n");
+
+	return ret;
+}
+
+static int csky_crypto_crc16usb_cra_init(struct crypto_tfm *tfm)
+{
+	struct csky_crypto_crc_ctx *crc_ctx = crypto_tfm_ctx(tfm);
+	int ret = 0;
+
+	crypto_ahash_set_reqsize(__crypto_ahash_cast(tfm),
+				 sizeof(struct csky_crypto_crc_reqctx));
+
+	crc_ctx->mod = MOD_CRC16;
+	crc_ctx->std = STD_USB;
+	ret = csky_crypto_crc_cra_init(crc_ctx);
+	if (ret)
+		dev_err(crc_ctx->crc->dev, "crc alg argument invalid \n");
+
+	return ret;
+}
+
+static int csky_crypto_crc16x25_cra_init(struct crypto_tfm *tfm)
+{
+	struct csky_crypto_crc_ctx *crc_ctx = crypto_tfm_ctx(tfm);
+	int ret = 0;
+
+	crypto_ahash_set_reqsize(__crypto_ahash_cast(tfm),
+				 sizeof(struct csky_crypto_crc_reqctx));
+
+	crc_ctx->mod = MOD_CRC16;
+	crc_ctx->std = STD_X25;
+	ret = csky_crypto_crc_cra_init(crc_ctx);
+	if (ret)
+		dev_err(crc_ctx->crc->dev, "crc alg argument invalid \n");
+
+	return ret;
+}
+
+static int csky_crypto_crc16ccitt_cra_init(struct crypto_tfm *tfm)
+{
+	struct csky_crypto_crc_ctx *crc_ctx = crypto_tfm_ctx(tfm);
+	int ret = 0;
+
+	crypto_ahash_set_reqsize(__crypto_ahash_cast(tfm),
+				 sizeof(struct csky_crypto_crc_reqctx));
+
+	crc_ctx->mod = MOD_CRC16;
+	crc_ctx->std = STD_CCITT;
+	ret = csky_crypto_crc_cra_init(crc_ctx);
+	if (ret)
+		dev_err(crc_ctx->crc->dev, "crc alg argument invalid \n");
+
+	return ret;
+}
+
+static struct ahash_alg crc_algs[] = {
+	{
+		.init			= csky_crypto_crc_init,
+		.update			= csky_crypto_crc_update,
+		.final			= csky_crypto_crc_final,
+		.finup			= csky_crypto_crc_finup,
+		.digest			= csky_crypto_crc_digest,
+		.halg.digestsize	= CHKSUM8_DIGEST_SIZE,
+		.halg.statesize		= sizeof(struct csky_crc_reqctx),
+		.halg.base  = {
+			.cra_name	= "crc8_rohc",
+			.cra_driver_name= "csky-crc8-rohc",
+			.cra_priority	= 100,
+			.cra_flags	= CRYPTO_ALG_ASYNC,
+			.cra_blocksize  = CHKSUM_BLOCK_SIZE,
+			.cra_ctxsize	= sizeof(struct csky_crypto_crc_ctx),
+			.cra_alignmask  = 0,
+			.cra_module	= THIS_MODULE,
+			.cra_init	= csky_crypto_crc8rohc_cra_init
+		}
+	},
+
+	{
+		.init			= csky_crypto_crc_init,
+		.update			= csky_crypto_crc_update,
+		.final			= csky_crypto_crc_final,
+		.finup			= csky_crypto_crc_finup,
+		.digest			= csky_crypto_crc_digest,
+		.halg.digestsize	= CHKSUM8_DIGEST_SIZE,
+		.halg.statesize		= sizeof(struct csky_crc_reqctx),
+		.halg.base  = {
+			.cra_name	= "crc8_maxim",
+			.cra_driver_name= "csky-crc8-maxim",
+			.cra_priority	= 100,
+			.cra_flags	= CRYPTO_ALG_ASYNC,
+			.cra_blocksize  = CHKSUM_BLOCK_SIZE,
+			.cra_ctxsize	= sizeof(struct csky_crypto_crc_ctx),
+			.cra_alignmask  = 0,
+			.cra_module	= THIS_MODULE,
+			.cra_init	= csky_crypto_crc8maxim_cra_init
+		}
+	},
+
+	{
+		.init			= csky_crypto_crc_init,
+		.update			= csky_crypto_crc_update,
+		.final			= csky_crypto_crc_final,
+		.finup			= csky_crypto_crc_finup,
+		.digest			= csky_crypto_crc_digest,
+		.halg.digestsize	= CHKSUM16_DIGEST_SIZE,
+		.halg.statesize		= sizeof(struct csky_crc_reqctx),
+		.halg.base  = {
+			.cra_name	= "crc16_ibm",
+			.cra_driver_name= "csky-crc16-ibm",
+			.cra_priority	= 100,
+			.cra_flags	= CRYPTO_ALG_ASYNC,
+			.cra_blocksize  = CHKSUM_BLOCK_SIZE,
+			.cra_ctxsize	= sizeof(struct csky_crypto_crc_ctx),
+			.cra_alignmask  = 0,
+			.cra_module	= THIS_MODULE,
+			.cra_init	= csky_crypto_crc16ibm_cra_init
+		}
+	},
+
+	{
+		.init			= csky_crypto_crc_init,
+		.update			= csky_crypto_crc_update,
+		.final			= csky_crypto_crc_final,
+		.finup			= csky_crypto_crc_finup,
+		.digest			= csky_crypto_crc_digest,
+		.halg.digestsize	= CHKSUM16_DIGEST_SIZE,
+		.halg.statesize		= sizeof(struct csky_crc_reqctx),
+		.halg.base  = {
+			.cra_name	= "crc16_maxim",
+			.cra_driver_name= "csky-crc16-maxim",
+			.cra_priority	= 100,
+			.cra_flags	= CRYPTO_ALG_ASYNC,
+			.cra_blocksize  = CHKSUM_BLOCK_SIZE,
+			.cra_ctxsize	= sizeof(struct csky_crypto_crc_ctx),
+			.cra_alignmask  = 0,
+			.cra_module	= THIS_MODULE,
+			.cra_init	= csky_crypto_crc16maxim_cra_init
+		}
+	},
+
+	{
+		.init			= csky_crypto_crc_init,
+		.update			= csky_crypto_crc_update,
+		.final			= csky_crypto_crc_final,
+		.finup			= csky_crypto_crc_finup,
+		.digest			= csky_crypto_crc_digest,
+		.halg.digestsize	= CHKSUM16_DIGEST_SIZE,
+		.halg.statesize		= sizeof(struct csky_crc_reqctx),
+		.halg.base  = {
+			.cra_name	= "crc16_modbus",
+			.cra_driver_name= "csky-crc16-modbus",
+			.cra_priority	= 100,
+			.cra_flags	= CRYPTO_ALG_ASYNC,
+			.cra_blocksize  = CHKSUM_BLOCK_SIZE,
+			.cra_ctxsize	= sizeof(struct csky_crypto_crc_ctx),
+			.cra_alignmask  = 0,
+			.cra_module	= THIS_MODULE,
+			.cra_init	= csky_crypto_crc16modbus_cra_init
+		}
+	},
+
+	{
+		.init			= csky_crypto_crc_init,
+		.update			= csky_crypto_crc_update,
+		.final			= csky_crypto_crc_final,
+		.finup			= csky_crypto_crc_finup,
+		.digest			= csky_crypto_crc_digest,
+		.halg.digestsize	= CHKSUM16_DIGEST_SIZE,
+		.halg.statesize		= sizeof(struct csky_crc_reqctx),
+		.halg.base  = {
+			.cra_name	= "crc16_usb",
+			.cra_driver_name= "csky-crc16-usb",
+			.cra_priority	= 100,
+			.cra_flags	= CRYPTO_ALG_ASYNC,
+			.cra_blocksize  = CHKSUM_BLOCK_SIZE,
+			.cra_ctxsize	= sizeof(struct csky_crypto_crc_ctx),
+			.cra_alignmask  = 0,
+			.cra_module	= THIS_MODULE,
+			.cra_init	= csky_crypto_crc16usb_cra_init
+		}
+	},
+
+	{
+		.init			= csky_crypto_crc_init,
+		.update			= csky_crypto_crc_update,
+		.final			= csky_crypto_crc_final,
+		.finup			= csky_crypto_crc_finup,
+		.digest			= csky_crypto_crc_digest,
+		.halg.digestsize	= CHKSUM16_DIGEST_SIZE,
+		.halg.statesize		= sizeof(struct csky_crc_reqctx),
+		.halg.base  = {
+			.cra_name	= "crc16_ccitt",
+			.cra_driver_name= "csky-crc16-ccitt",
+			.cra_priority	= 100,
+			.cra_flags	= CRYPTO_ALG_ASYNC,
+			.cra_blocksize  = CHKSUM_BLOCK_SIZE,
+			.cra_ctxsize	= sizeof(struct csky_crypto_crc_ctx),
+			.cra_alignmask  = 0,
+			.cra_module	= THIS_MODULE,
+			.cra_init	= csky_crypto_crc16ccitt_cra_init
+		}
+	},
+
+	{
+		.init			= csky_crypto_crc_init,
+		.update			= csky_crypto_crc_update,
+		.final			= csky_crypto_crc_final,
+		.finup			= csky_crypto_crc_finup,
+		.digest			= csky_crypto_crc_digest,
+		.halg.digestsize	= CHKSUM16_DIGEST_SIZE,
+		.halg.statesize		= sizeof(struct csky_crc_reqctx),
+		.halg.base  = {
+			.cra_name	= "crc16_x25",
+			.cra_driver_name= "csky-crc16-x25",
+			.cra_priority	= 100,
+			.cra_flags	= CRYPTO_ALG_ASYNC,
+			.cra_blocksize  = CHKSUM_BLOCK_SIZE,
+			.cra_ctxsize	= sizeof(struct csky_crypto_crc_ctx),
+			.cra_alignmask  = 0,
+			.cra_module	= THIS_MODULE,
+			.cra_init	= csky_crypto_crc16x25_cra_init
+		}
+	},
+};
+
+static void csky_crypto_crc_done_task(unsigned long data)
+{
+	struct csky_crypto_crc *crc = (struct csky_crypto_crc *)data;
+
+	csky_crypto_crc_handle_queue(crc, NULL);
+}
+
+static int csky_crypto_crc_probe(struct platform_device *pdev)
+{
+	struct device *dev = &pdev->dev;
+	struct resource *res;
+	struct csky_crypto_crc *crc;
+	int ret;
+	int i, j;
+
+	crc = devm_kzalloc(dev, sizeof(*crc), GFP_KERNEL);
+	if (!crc) {
+		dev_err(&pdev->dev, "fail to malloc csky_crypto_crc\n");
+		return -ENOMEM;
+	}
+
+	crc->dev = dev;
+
+	platform_set_drvdata(pdev, crc);
+
+	INIT_LIST_HEAD(&crc->list);
+	spin_lock_init(&crc->lock);
+
+	tasklet_init(&crc->done_task,
+		     csky_crypto_crc_done_task,
+		     (unsigned long)crc);
+	crypto_init_queue(&crc->queue, CRC_CCRYPTO_QUEUE_LENGTH);
+
+	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	crc->regs = devm_ioremap_resource(dev, res);
+	if (IS_ERR((void *)crc->regs)) {
+		ret = PTR_ERR(crc->regs);
+		dev_err(&pdev->dev, "Cannot map CRC IO\n");
+		goto _res_err;
+	}
+
+	spin_lock(&crc_list.lock);
+	list_add(&crc->list, &crc_list.dev_list);
+	spin_unlock(&crc_list.lock);
+
+	if (list_is_singular(&crc_list.dev_list)) {
+		for (i = 0; i < ARRAY_SIZE(crc_algs); i++) {
+			ret = crypto_register_ahash(&crc_algs[i]);
+			if (ret) {
+				for (j = 0; j < i; j++) {
+					crypto_unregister_ahash(&crc_algs[j]);
+				}
+				dev_err(&pdev->dev,
+					"Can't register crypto ahash device\n");
+				goto _reg_err;
+			}
+		}
+	}
+
+	dev_info(&pdev->dev, "CSKY CRC driver initialized\n");
+
+	return 0;
+
+_res_err:
+	tasklet_kill(&crc->done_task);
+_reg_err:
+	spin_lock(&crc_list.lock);
+	list_del(&crc->list);
+	spin_unlock(&crc_list.lock);
+
+	return ret;
+}
+
+static int csky_crypto_crc_remove(struct platform_device *pdev)
+{
+	struct csky_crypto_crc *crc = platform_get_drvdata(pdev);
+	int i;
+
+	if (!crc)
+		return -ENODEV;
+
+	spin_lock(&crc_list.lock);
+	list_del(&crc->list);
+	spin_unlock(&crc_list.lock);
+
+	for (i = 0; i < ARRAY_SIZE(crc_algs); i++)
+		crypto_unregister_ahash(&crc_algs[i]);
+
+	tasklet_kill(&crc->done_task);
+
+	return 0;
+}
+
+static const struct of_device_id csky_crc_dt_ids[] = {
+	{ .compatible = "csky,crc-v1" },
+	{ /* sentinel */ }
+};
+
+MODULE_DEVICE_TABLE(of, csky_crc_dt_ids);
+
+static struct platform_driver csky_crypto_crc_driver = {
+	.probe	= csky_crypto_crc_probe,
+	.remove	= csky_crypto_crc_remove,
+	.driver	= {
+		.name = "csky-crc",
+		.of_match_table = of_match_ptr(csky_crc_dt_ids),
+	},
+};
+
+module_platform_driver(csky_crypto_crc_driver);
+
+MODULE_AUTHOR("Vincent Cui <xiaoxia_cui@c-sky.com>");
+MODULE_DESCRIPTION("CSKY CRC hardware crypto driver");
+MODULE_LICENSE("GPL");
diff --git a/addons/drivers/crypto/csky_crc.h b/addons/drivers/crypto/csky_crc.h
new file mode 100644
index 0000000..7829ebe
--- /dev/null
+++ b/addons/drivers/crypto/csky_crc.h
@@ -0,0 +1,47 @@
+/*
+ * Copyright (C) 2017 C-SKY MicroSystems Co.,Ltd.
+ * Author: Vincent Cui <xiaoxia_cui@c-sky.com>
+ *
+ * This software is licensed under the terms of the GNU General Public
+ * License version 2, as published by the Free Software Foundation, and
+ * may be copied, distributed, and modified under those terms.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ */
+
+#ifndef __CSKY_CRC_H
+#define __CSKY_CRC_H
+
+#include <linux/types.h>
+
+typedef enum {
+	MOD_CRC8	= 0,
+	MOD_CRC16,
+	MOD_CRC32
+} crc_mod_e;
+
+typedef enum {
+	STD_ROHC	= 0,
+	STD_MAXIM,
+	STD_X25,
+	STD_CCITT,
+	STD_USB,
+	STD_IBM,
+	STD_MODBUS
+} crc_std_e;
+
+struct crc_register {
+	u32 data;
+	u32 sel;
+	u32 init;
+};
+
+#define SEL_POLY		0x00000007
+#define SEL_POLARITY	0x00000008
+#define INIT_DATA		0x0000FFFF
+
+#endif /* __CSKY_CRC_H */
\ No newline at end of file
diff --git a/addons/drivers/crypto/csky_rsa.c b/addons/drivers/crypto/csky_rsa.c
new file mode 100644
index 0000000..c2cc093
--- /dev/null
+++ b/addons/drivers/crypto/csky_rsa.c
@@ -0,0 +1,1352 @@
+/*
+ * Copyright (C) 2017 C-SKY MicroSystems Co.,Ltd.
+ * Author: Vincent Cui <xiaoxia_cui@c-sky.com>
+ *
+ * This software is licensed under the terms of the GNU General Public
+ * License version 2, as published by the Free Software Foundation, and
+ * may be copied, distributed, and modified under those terms.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ */
+
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/err.h>
+#include <linux/io.h>
+#include <linux/platform_device.h>
+#include <linux/mpi.h>
+#include <linux/device.h>
+#include <linux/init.h>
+#include <linux/errno.h>
+#include <linux/interrupt.h>
+#include <linux/irq.h>
+#include <linux/of_device.h>
+#include <linux/delay.h>
+#include <linux/crypto.h>
+#include <crypto/akcipher.h>
+#include <crypto/algapi.h>
+#include <crypto/internal/rsa.h>
+#include <crypto/internal/akcipher.h>
+#include "csky_rsa.h"
+
+#define RSA_FLAGS_BUSY		BIT(0)
+
+#define RSA_FLAGS_SIGN		BIT(8)
+#define RSA_FLAGS_VERIFY	BIT(9)
+#define RSA_FLAGS_ENC		BIT(10)
+#define RSA_FLAGS_DEC		BIT(11)
+
+#define RSA_FLAGS_OPR_MASK	(RSA_FLAGS_SIGN | RSA_FLAGS_VERIFY | \
+				 RSA_FLAGS_ENC | RSA_FLAGS_DEC)
+#define CSKY_RSA_QUEUE_LENGTH	10
+
+struct csky_rsa_dev;
+
+struct rsa_key_obj {
+	uint8_t *n;
+	uint8_t *e;
+	uint8_t *d;
+	uint32_t n_len;
+	uint32_t e_len;
+	uint32_t d_len;
+};
+
+struct csky_rsa_base_ctx {
+	struct csky_rsa_dev *dd;
+	struct rsa_key_obj key;
+};
+
+struct csky_rsa_ctx {
+	struct csky_rsa_base_ctx base;
+};
+
+struct csky_rsa_reqctx {
+	unsigned long dummy;
+};
+
+struct csky_rsa_dev {
+	struct list_head		 list;
+	struct crypto_async_request	*areq;
+	struct csky_rsa_base_ctx	*ctx;
+	struct device			*dev;
+	struct rsa_reg __iomem		*reg_base;
+	struct tasklet_struct		done_task;
+
+	struct crypto_queue		queue;
+	unsigned long			flags;
+	spinlock_t			lock;
+
+	void *				buf;
+	uint32_t			buflen;
+	struct scatterlist		*real_dst;
+};
+
+struct csky_rsa_drv {
+	struct list_head dev_list;
+	spinlock_t	 lock;
+};
+
+static struct csky_rsa_drv csky_rsa = {
+	.dev_list = LIST_HEAD_INIT(csky_rsa.dev_list),
+	.lock	  = __SPIN_LOCK_UNLOCKED(csky_rsa.lock),
+};
+
+static inline void csky_rsa_clear_int(struct csky_rsa_dev *dd)
+{
+	writel_relaxed(0xffff, &dd->reg_base->rsa_isr);
+	writel_relaxed(0x0000, &dd->reg_base->rsa_imr);
+}
+
+static inline void csky_rsa_setm_width(struct csky_rsa_dev *dd, uint32_t width)
+{
+	writel_relaxed(width, &dd->reg_base->rsa_mwid);
+}
+
+static inline void csky_rsa_setd_width(struct csky_rsa_dev *dd, uint32_t width)
+{
+	writel_relaxed(width, &dd->reg_base->rsa_dwid);
+}
+
+static inline void csky_rsa_setb_width(struct csky_rsa_dev *dd, uint32_t width)
+{
+	writel_relaxed(width, &dd->reg_base->rsa_bwid);
+}
+
+static inline void csky_rsa_cal_q(struct csky_rsa_dev *dd)
+{
+	writel_relaxed(0x6, &dd->reg_base->rsa_ctrl);
+}
+
+static inline void csky_rsa_opr_start(struct csky_rsa_dev *dd)
+{
+	writel_relaxed(0x3, &dd->reg_base->rsa_ctrl);
+}
+
+static inline void csky_rsa_opr_reset(struct csky_rsa_dev *dd)
+{
+	uint32_t tmp;
+
+	writel_relaxed(0x8, &dd->reg_base->rsa_ctrl);
+	tmp = readl_relaxed(&dd->reg_base->rsa_rst);
+	tmp |= 0x1;
+	writel_relaxed(tmp, &dd->reg_base->rsa_rst);
+	while (readl_relaxed(&dd->reg_base->rsa_rst));
+}
+
+static inline uint32_t csky_rsa_loop_cnt(struct csky_rsa_dev *dd)
+{
+	return readl_relaxed(&dd->reg_base->rsa_lp_cnt);
+}
+
+static inline uint32_t csky_rsa_cal_q_done(struct csky_rsa_dev *dd)
+{
+	return (readl_relaxed(&dd->reg_base->rsa_isr) >> 5) & 0x1;
+}
+
+static inline uint32_t csky_rsa_opr_done(struct csky_rsa_dev *dd)
+{
+	return readl_relaxed(&dd->reg_base->rsa_isr) & 0x1;
+}
+
+static inline uint32_t csky_rsa_raise_exception(struct csky_rsa_dev *dd)
+{
+	return readl_relaxed(&dd->reg_base->rsa_isr) & 0x1E;
+}
+
+static inline uint32_t csky_rsa_loadm(struct csky_rsa_dev *dd, uint32_t *data,
+				      uint32_t length)
+{
+	uint32_t i;
+	uint32_t baseaddr;
+
+	baseaddr = (uint32_t)&dd->reg_base->rsa_rfm;
+	for(i = 0; i < length; i++) {
+		writel_relaxed(data[i], (void *)baseaddr);
+		baseaddr = baseaddr + 4;
+	}
+
+	return 0;
+}
+
+static void csky_rsa_loadd(struct csky_rsa_dev *dd, uint32_t *data,
+			   uint32_t length)
+{
+	uint32_t i;
+	uint32_t baseaddr;
+
+	baseaddr = (uint32_t)&dd->reg_base->rsa_rfd;
+	for(i = 0;  i < length; i++) {
+		writel_relaxed(data[i], (void *)baseaddr);
+		baseaddr = baseaddr + 4;
+	}
+}
+
+static void csky_rsa_loadc(struct csky_rsa_dev *dd, uint32_t *data,
+			   uint32_t length)
+{
+	uint32_t i;
+	uint32_t baseaddr;
+
+	baseaddr = (uint32_t)&dd->reg_base->rsa_rfc;
+	for(i = 1; i < length + 1; i++) {
+		writel_relaxed(data[i-1], (void *)baseaddr);
+		baseaddr = baseaddr + 4;
+	}
+}
+
+static void csky_rsa_loadb(struct csky_rsa_dev *dd, uint32_t *data,
+			   uint32_t length)
+{
+	uint32_t i;
+	uint32_t baseaddr;
+
+	baseaddr = (uint32_t)&dd->reg_base->rsa_rfb;
+	for(i = 0; i < length; i++) {
+		writel_relaxed(data[i], (void *)baseaddr);
+		baseaddr = baseaddr + 4;
+	}
+}
+
+static void csky_rsa_read_r(struct csky_rsa_dev *dd, uint32_t data[],
+			    uint32_t length)
+{
+	uint32_t i;
+	uint32_t baseaddr;
+
+	baseaddr = (uint32_t)&dd->reg_base->rsa_rfr;
+	for(i = 0; i < length; i++) {
+		data[i] = readl_relaxed((void *)baseaddr);
+		baseaddr = baseaddr + 4;
+	}
+}
+
+static uint32_t get_valid_bits(const uint32_t *addr, uint32_t wordsize)
+{
+	uint32_t i = 0;
+	uint32_t j = 0;
+
+	for (i = wordsize; i > 0; i--) {
+		if (addr[i - 1]) {
+			break;
+		}
+	}
+
+	for (j = 32; j > 0; j--) {
+		if (addr[i - 1] & (0x1 << (j - 1))) {
+			break;
+		}
+	}
+
+	return ((i - 1) << 5) + j;
+}
+
+static uint32_t get_first_nonzero_words(uint32_t *a, uint32_t max_words)
+{
+	uint32_t i = 0;
+
+	for (i = max_words; i > 0; i--) {
+		if (a[i - 1]) {
+			return i;
+		}
+	}
+	return 0;
+}
+
+static uint32_t word_array_left_shift(uint32_t *a, uint32_t words,
+				      uint32_t shift_bits, uint32_t *r)
+{
+	uint32_t i = 0;
+	uint32_t w;
+	uint32_t b;
+	uint32_t tmp = 0;
+
+	w = shift_bits >> 5;
+	b = shift_bits - (w << 5);
+
+	for (i = 0; i < w; i++) {
+		r[i] = 0;
+	}
+
+	tmp = 0;
+	for (i = 0; i < words; i++) {
+		r[w + i] = (tmp | ((a[i] << b) & (~((0x1 << b) - 1))));
+		tmp = ((a[i] >> (32 - b)) & ((0x1 << b) - 1));
+	}
+	r[w + i] = tmp;
+
+	return 0;
+}
+
+static uint32_t _word_array_sub(uint32_t *a, uint32_t a_words,
+				uint32_t *b, uint32_t b_words,
+				uint32_t *r)
+{
+	uint32_t i;
+	uint64_t tmp = 0;
+	uint32_t borrow = 0;
+
+	for (i = 0; i < b_words; i++) {
+		tmp = UINT32_TO_UINT64(a[i]) - UINT32_TO_UINT64(b[i]) -
+			  UINT32_TO_UINT64(borrow);
+		r[i] = UINT64L_TO_UINT32(tmp);
+		borrow = ((UINT64H_TO_UINT32(tmp) == 0) ? (0):
+				  (0xffffffff - UINT64H_TO_UINT32(tmp) + 1));
+	}
+
+	for (i = b_words; i < a_words; i++) {
+		tmp = UINT32_TO_UINT64(a[i]) - UINT32_TO_UINT64(borrow);
+		r[i] = UINT64L_TO_UINT32(tmp);
+		borrow = ((UINT64H_TO_UINT32(tmp) == 0) ? (0):
+				  (0xffffffff - UINT64H_TO_UINT32(tmp) + 1));
+	}
+
+	if (borrow) {
+		return -1;
+	}
+
+	return 0;
+}
+
+static uint32_t word_array_mod(uint32_t *a, uint32_t a_words,
+			       uint32_t *b, uint32_t b_words,
+			       uint32_t *r)
+{
+	uint32_t ret;
+	bignum_t tmpa;
+	bignum_t tmpb;
+	uint32_t tmpa_valid_bits, tmpa_words;
+	uint32_t tmpb_words, b_valid_bits;
+
+	memset(&tmpa, 0, sizeof(tmpa));
+	memset(&tmpb, 0, sizeof(tmpa));
+
+	b_valid_bits = get_valid_bits(b, b_words);
+
+	memcpy(tmpa.pdata, a, (a_words << 2));
+
+	do {
+		tmpa_words = get_first_nonzero_words(tmpa.pdata, a_words);
+		tmpa_valid_bits = get_valid_bits(tmpa.pdata, tmpa_words);
+		if (tmpa_valid_bits > b_valid_bits + 1) {
+			memset(tmpb.pdata, 0, (a_words << 2));
+			word_array_left_shift(b, b_words,
+				tmpa_valid_bits - b_valid_bits - 1,
+				tmpb.pdata);
+			tmpb_words = get_first_nonzero_words(tmpb.pdata,
+							     a_words);
+			ret = _word_array_sub(tmpa.pdata, tmpa_words,
+					      tmpb.pdata, tmpb_words,
+					      tmpa.pdata);
+		} else if (tmpa_words == b_words) {
+			memcpy(r, tmpa.pdata, (tmpa_words << 2));
+			ret = _word_array_sub(r, tmpa_words,
+					      b, b_words,
+					      tmpa.pdata);
+		} else {
+			ret = _word_array_sub(tmpa.pdata, tmpa_words,
+					      b, b_words,
+					      tmpa.pdata);
+		}
+	} while (ret == 0);
+
+	return 0;
+}
+
+static void convert_byte_array(uint8_t *in, uint8_t *out, uint32_t len)
+{
+	uint8_t tmp;
+	uint32_t idx, round = len >> 1;
+
+	for (idx = 0; idx < round; idx++) {
+		tmp = *(in + idx);
+		*(out + idx) = *(in + len - 1 - idx);
+		*(out + len - 1 - idx) = tmp;
+	}
+
+	if (len & 0x1) {
+		*(out + round) = *(in + round);
+	}
+}
+
+static void convert_buf_to_bndata(const uint8_t *src, uint32_t src_bytes,
+				  uint32_t *dst, uint32_t dst_words)
+{
+	memset(dst, 0, dst_words << 2);
+	convert_byte_array((uint8_t *)src, (uint8_t *)dst, src_bytes);
+}
+
+static void convert_bndata_to_buf(const uint32_t *src, uint32_t src_words,
+				  uint8_t *dst, uint32_t dst_bytes)
+{
+	memset(dst, 0, dst_bytes);
+	convert_byte_array((uint8_t *)src, (uint8_t *)dst, dst_bytes);
+}
+
+
+static uint32_t sw_exptmod_2_2m(const uint32_t *modulus, uint32_t words,
+				uint32_t *tmp_c)
+{
+	uint32_t ret;
+	uint32_t m_valid_bits;
+	uint32_t data1 = 0;
+	bignum_t tmp;
+
+	memset(&tmp, 0, sizeof(bignum_t));
+
+	m_valid_bits = (words << 5);
+
+	data1 = 0x1;
+	word_array_left_shift(&data1, 1, (m_valid_bits << 1), tmp.pdata);
+	tmp.words = get_first_nonzero_words(tmp.pdata, words*2 + 1);
+
+	ret = word_array_mod(tmp.pdata, tmp.words,
+			     (uint32_t *)modulus, words, tmp_c);
+	if (ret != 0) {
+		return ret;
+	}
+	return 0;
+}
+
+static uint32_t csky_rsa_exptmod_1024(struct csky_rsa_dev *dd,
+				      const uint32_t *modulus,
+				      const uint32_t *exponent,
+				      const uint32_t *base,
+				      uint32_t *out)
+{
+	uint32_t tmp_c[32];
+	uint32_t ret;
+
+	if ((NULL == modulus) || (NULL == exponent) || (NULL == base) ||
+	    (NULL == out)) {
+		return 1;
+	}
+
+	ret = sw_exptmod_2_2m(modulus, 32, tmp_c);
+	if (ret != 0) {
+		return ret;
+	}
+
+	/* reset for safe */
+	csky_rsa_opr_reset(dd);
+	/* clear and disable int */
+	csky_rsa_clear_int(dd);
+	/* set m */
+	csky_rsa_setm_width(dd, 32 >> 1);
+	csky_rsa_loadm(dd, (uint32_t *)modulus, 32);
+	/* set d */
+	csky_rsa_setd_width(dd, get_valid_bits(exponent, 32) - 1);
+	csky_rsa_loadd(dd, (uint32_t *)exponent, 32);
+	/* set b */
+	csky_rsa_setb_width(dd, 32 >> 1);
+	csky_rsa_loadb(dd, (uint32_t *)base, 32);
+	/* set c */
+	csky_rsa_loadc(dd, tmp_c, 32);
+
+	csky_rsa_cal_q(dd);
+	while(!csky_rsa_cal_q_done(dd) && (!csky_rsa_raise_exception(dd)));
+
+	if (!csky_rsa_raise_exception(dd)) {
+		csky_rsa_opr_start(dd);
+		while((!csky_rsa_opr_done(dd)) &&
+			(csky_rsa_loop_cnt(dd) < MAX_RSA_LP_CNT) &&
+			(!csky_rsa_raise_exception(dd)));
+
+		if ((csky_rsa_loop_cnt(dd) >= MAX_RSA_LP_CNT)
+			|| csky_rsa_raise_exception(dd)) {
+			ret = 1;
+		} else {
+			csky_rsa_read_r(dd, out, 32);
+		}
+	} else {
+		ret = 1;
+	}
+
+	csky_rsa_opr_reset(dd);
+
+	return ret;
+}
+
+static const uint8_t der_sha1_t[] = {
+	0x30, 0x21,
+	0x30, 0x09,
+	0x06, 0x05, 0x2b, 0x0e, 0x03, 0x02, 0x1a,
+	0x05, 0x00,
+	0x04, 0x14 };
+
+static const uint8_t der_md5_t[] = {
+	0x30, 0x20, /* type Sequence, length 0x20 (32) */
+	0x30, 0x0c, /* type Sequence, length 0x09 */
+	0x06, 0x08, /* type OID, length 0x05 */
+	0x2a, 0x86, 0x48, 0x86, 0xF7, 0x0D, 0x02, 0x05, /* id-md5 */
+	0x05, 0x00, /* NULL */
+	0x04, 0x10  /* Octet string, length 0x10 (16), followed by md5 hash */
+};
+
+static uint32_t RSA_padding_add_PKCS1_sha1_emsa_1024(const uint8_t *dgst,
+						     uint8_t *out,
+						     uint32_t *outlen,
+						     uint32_t type)
+
+{
+	uint32_t i;
+	uint8_t *p;
+	uint32_t modulus_len;
+	uint8_t *der;
+	uint32_t der_len;
+	uint32_t hashlen;
+	uint32_t pslen;
+
+	if (type == MD5_PADDING) {
+		der	= (uint8_t *)der_md5_t;
+		der_len = sizeof(der_md5_t);
+		hashlen = MD5_HASH_SZ;
+	} else if (type == SHA1_PADDING) {
+		der	= (uint8_t *)der_sha1_t;
+		der_len = sizeof(der_sha1_t);
+		hashlen = SHA1_HASH_SZ;
+	} else {
+		der	= (uint8_t *)der_md5_t;
+		der_len = sizeof(der_md5_t);
+		hashlen = MD5_HASH_SZ;
+	}
+
+	modulus_len = 1024 >> 3;
+
+	if (*outlen < modulus_len) {
+		*outlen = modulus_len;
+		return -1;
+	}
+
+
+	p = (uint8_t *)out;
+
+	*(p++) = 0x00;
+	*(p++) = 0x01;
+
+	/* pad out with 0xff data */
+	pslen = modulus_len - 3 - der_len - hashlen;
+
+	for (i = 0; i < pslen; i++) {
+		p[i] = 0xff; /* PS */
+	}
+
+	p += pslen;
+	*(p++) = 0x0;
+
+	for (i = 0; i < der_len; i++) {
+		p[i] = der[i];
+	}
+	p += der_len;
+
+	for (i = 0; i < hashlen; i++) {
+		p[i] = dgst[i];
+	}
+
+	*outlen = modulus_len;
+	return 0;
+}
+
+static uint32_t RSA_padding_check_PKCS1_type_emsa(const uint8_t *dgst,
+						  const uint8_t *in,
+						  const uint32_t inlen,
+						  uint8_t *is_valid,
+						  uint32_t type)
+{
+	uint32_t i;
+	uint32_t ret;
+	const uint8_t *p;
+	uint8_t *der;
+	uint32_t der_len;
+	uint32_t hashlen;
+	uint32_t pslen;
+	uint32_t modulus_len;
+
+	if (type == MD5_PADDING) {
+		der	= (uint8_t *)der_md5_t;
+		der_len = sizeof(der_md5_t);
+		hashlen = MD5_HASH_SZ;
+	} else if (type == SHA1_PADDING) {
+		der	= (uint8_t *)der_sha1_t;
+		der_len = sizeof(der_sha1_t);
+		hashlen = SHA1_HASH_SZ;
+	} else {
+		der	= (uint8_t *)der_md5_t;
+		der_len = sizeof(der_md5_t);
+		hashlen = MD5_HASH_SZ;
+	}
+
+	modulus_len = RSA_KEY_LEN >> 3;
+
+	if (inlen != modulus_len) {
+		return -1;
+	}
+
+	*is_valid = 0;
+
+	pslen = modulus_len - 3 - der_len - hashlen;
+	p = in;
+	p++;
+
+	if (*(p) != 0x01) {
+		ret = -1;
+		goto _verify_fail;
+	}
+	p++;
+
+	/* scan PS */
+	for (i = 0; i < pslen; i++) {
+		if (*(p + i) != 0xff) {
+			ret = -1;
+			goto _verify_fail;
+		}
+	}
+	p += pslen;
+
+	if ((*p) != 0x00) {
+		ret = -1;
+		goto _verify_fail;
+	}
+	p++;
+
+	/* scan t */
+	for (i = 0; i < der_len; i++) {
+		if (*(p + i) != der[i]) {
+			ret = -1;
+			goto _verify_fail;
+		}
+	}
+	p += der_len;
+
+	for (i = 0; i < hashlen; i++) {
+		if (*(p + i) != dgst[i]) {
+			ret = -1;
+			goto _verify_fail;
+		}
+	}
+
+	*is_valid = 1;
+	ret = 0;
+
+_verify_fail:
+
+	return ret;
+}
+
+static uint32_t RSA_ES_padding_add_PKCS1_emsa_1024(const uint8_t *dgst,
+						   uint32_t dgstlen,
+						   uint8_t *out,
+						   uint32_t *outlen,
+						   uint32_t padding)
+{
+	uint32_t i;
+	uint8_t *p;
+	uint32_t modulus_len;
+	uint32_t pslen;
+
+	modulus_len = RSA_KEY_LEN >> 3;
+
+	if (*outlen < modulus_len) {
+		*outlen = modulus_len;
+		return 1;
+	}
+
+	p = (uint8_t *)out;
+
+	*(p++) = 0x00;
+	*(p++) = 0x02;
+
+	/* pad out with 0xff data */
+	pslen = modulus_len - 3 - dgstlen;
+
+	for (i = 0; i < pslen; i++) {
+		p[i] = 0xff; /* PS */
+	}
+
+	p += pslen;
+	*(p++) = 0x0;
+
+	for (i = 0; i < dgstlen; i++) {
+		p[i] = dgst[i];
+	}
+
+	*outlen = modulus_len;
+
+	return 0;
+}
+
+static uint32_t RSA_ES_padding_check_PKCS1_type_emsa(uint8_t *out,
+						     uint32_t *out_size,
+						     uint8_t *src,
+						     uint32_t src_size,
+						     uint32_t padding)
+{
+	uint32_t i;
+	uint8_t *p;
+	uint32_t modulus_len;
+	uint32_t pslen;
+
+	modulus_len = RSA_KEY_LEN >> 3;
+
+	if (src_size < modulus_len) {
+		return 1;
+	}
+
+	p = (uint8_t *)src;
+	*(p++) = 0x00;
+
+	if (padding == PKCS1_PADDING) {
+		if (*(p++) != 0x02) {
+			return 1;
+		}
+	} else {
+		if (*(p++) != 0x01) {
+			return 1;
+		}
+	}
+
+	pslen = src_size - 2;
+
+	while (pslen--) {
+		if (*(p++) == 0x0) {
+			break;
+		}
+	}
+
+	for (i = 0; i < pslen; i++) {
+		 out[i] = p[i];
+	}
+
+	*out_size = pslen;
+
+	return 0;
+}
+
+int rsa_encrypt(struct csky_rsa_dev *dd, uint8_t *n, uint8_t *e,
+		uint8_t *src, uint32_t src_size,
+		uint8_t *out, uint32_t *out_size,
+		uint32_t padding)
+{
+	uint32_t ret;
+	uint32_t tmp_n[32];
+	uint32_t tmp_e[32];
+	uint32_t tmp_src_padded[32];
+	uint32_t tmp_out[32];
+	uint32_t keywords = 0, keybytes = 0;
+	uint32_t tmp_src_padded_len = 0;
+
+	keywords = RSA_KEY_LEN >> 5;
+	keybytes = (keywords << 2);
+
+	convert_buf_to_bndata(n, keybytes, tmp_n, keywords);
+	convert_buf_to_bndata(e, keybytes, tmp_e, keywords);
+
+	tmp_src_padded_len = keybytes;
+	if (padding == PKCS1_PADDING) {
+		ret = RSA_ES_padding_add_PKCS1_emsa_1024(
+			(const uint8_t *)src, src_size,
+			(uint8_t *)tmp_src_padded,
+			&tmp_src_padded_len, padding);
+		if (ret != 0) {
+			return ret;
+		}
+		convert_byte_array(
+			(uint8_t *)tmp_src_padded,
+			(uint8_t *)tmp_src_padded,
+			tmp_src_padded_len);
+	} else {
+		convert_byte_array(
+			(uint8_t *)src,
+			(uint8_t *)tmp_src_padded,
+			tmp_src_padded_len);
+	}
+
+	ret = csky_rsa_exptmod_1024(dd, tmp_n, tmp_e, tmp_src_padded, tmp_out);
+	if (ret != 0) {
+		return ret;
+	}
+
+	convert_bndata_to_buf(tmp_out, keywords, out, keybytes);
+	*out_size = keybytes;
+
+	return ret;
+}
+
+int rsa_decrypt(struct csky_rsa_dev *dd,
+		uint8_t *n, uint8_t *d,
+		uint8_t *src, uint32_t src_size,
+		uint8_t *out, uint32_t *out_size,
+		uint32_t padding)
+{
+	uint32_t ret;
+	uint32_t tmp_n[32];
+	uint32_t tmp_d[32];
+	uint32_t tmp_dst_padded[32];
+	uint32_t tmp_sig[32];
+	uint32_t keywords = 0, keybytes = 0;
+
+	keywords = RSA_KEY_LEN >> 5;
+	keybytes = (keywords << 2);
+
+	convert_buf_to_bndata(n, keybytes, tmp_n, keywords);
+	convert_buf_to_bndata(d, keybytes, tmp_d, keywords);
+	convert_buf_to_bndata(src, src_size, tmp_sig, keywords);
+
+	ret = csky_rsa_exptmod_1024(dd, tmp_n, tmp_d, tmp_sig, tmp_dst_padded);
+	if (ret != 0) {
+		return ret;
+	}
+
+	convert_byte_array((uint8_t *)tmp_dst_padded,
+			   (uint8_t *)tmp_dst_padded, keybytes);
+
+	ret = RSA_ES_padding_check_PKCS1_type_emsa(out, out_size,
+						   (uint8_t *)tmp_dst_padded,
+						   keybytes, padding);
+
+	return ret;
+}
+
+int rsa_sign(struct csky_rsa_dev *dd,
+	     uint8_t *n, uint8_t *d,
+	     uint8_t *src, uint32_t src_size,
+	     uint8_t *signature, uint32_t *sig_size, uint32_t type)
+{
+	uint32_t ret;
+	uint32_t tmp_n[32];
+	uint32_t tmp_d[32];
+	uint32_t tmp_src_padded[32];
+	uint32_t tmp_sig[32];
+	uint32_t keywords = 0, keybytes = 0;
+	uint32_t tmp_src_padded_len = 0;
+
+	keywords = RSA_KEY_LEN >> 5;
+	keybytes = (keywords << 2);
+
+	convert_buf_to_bndata(n, keybytes, tmp_n, keywords);
+	convert_buf_to_bndata(d, keybytes, tmp_d, keywords);
+
+	tmp_src_padded_len = keybytes;
+	ret = RSA_padding_add_PKCS1_sha1_emsa_1024((const uint8_t *)src,
+						   (uint8_t *)tmp_src_padded,
+						   &tmp_src_padded_len, type);
+	if (ret != 0) {
+		return ret;
+	}
+
+	convert_byte_array((uint8_t *)tmp_src_padded,
+			   (uint8_t *)tmp_src_padded,
+			   keybytes);
+
+	ret = csky_rsa_exptmod_1024(dd, tmp_n, tmp_d, tmp_src_padded, tmp_sig);
+	if (ret != 0) {
+		return ret;
+	}
+
+	convert_bndata_to_buf(tmp_sig, keywords, signature, keybytes);
+	*sig_size = keybytes;
+
+	return 0;
+}
+
+int rsa_verify(struct csky_rsa_dev *dd,
+	       uint8_t *n, uint8_t *e,
+	       uint8_t *src, uint32_t src_size,
+	       uint8_t *signature, uint32_t sig_size,
+	       uint8_t *result, uint32_t type)
+{
+	uint32_t ret;
+	uint32_t tmp_n[32];
+	uint32_t tmp_e[32];
+	uint32_t tmp_dst_padded[32];
+	uint32_t tmp_sig[32];
+	uint32_t keywords = 0, keybytes = 0;
+
+	*result = 0;
+
+	keywords = RSA_KEY_LEN >> 5;
+	keybytes = (keywords << 2);
+
+	convert_buf_to_bndata(n, keybytes, tmp_n, keywords);
+	convert_buf_to_bndata(e, keybytes, tmp_e, keywords);
+	convert_buf_to_bndata(signature, sig_size, tmp_sig, keywords);
+
+	ret = csky_rsa_exptmod_1024(dd, tmp_n, tmp_e, tmp_sig, tmp_dst_padded);
+	if (ret != 0) {
+		return ret;
+	}
+
+	convert_byte_array((uint8_t *)tmp_dst_padded,
+			   (uint8_t *)tmp_dst_padded, keybytes);
+	ret = RSA_padding_check_PKCS1_type_emsa(
+		src,
+		(const uint8_t *)tmp_dst_padded,
+		keybytes,
+		result,
+		type);
+
+	return ret;
+}
+
+static struct csky_rsa_dev *csky_rsa_find_dev(struct csky_rsa_base_ctx *ctx)
+{
+	struct csky_rsa_dev *rsa_dd = NULL;
+	struct csky_rsa_dev *tmp;
+
+	spin_lock_bh(&csky_rsa.lock);
+	if (!ctx->dd) {
+		list_for_each_entry(tmp, &csky_rsa.dev_list, list) {
+			rsa_dd = tmp;
+			break;
+		}
+		ctx->dd = rsa_dd;
+	} else {
+		rsa_dd = ctx->dd;
+	}
+	spin_unlock_bh(&csky_rsa.lock);
+
+	return rsa_dd;
+}
+
+static inline struct akcipher_request *akcipher_request_cast(
+	struct crypto_async_request *req)
+{
+	return container_of(req, struct akcipher_request, base);
+}
+
+static inline int csky_rsa_complete(struct csky_rsa_dev *dd, int err)
+{
+	dd->flags &= ~RSA_FLAGS_BUSY;
+	dd->flags &= ~RSA_FLAGS_OPR_MASK;
+	dd->areq->complete(dd->areq, err);
+
+	tasklet_schedule(&dd->done_task);
+
+	return err;
+}
+
+static int csky_rsa_handle(struct csky_rsa_dev *dd)
+{
+	struct csky_rsa_base_ctx *ctx = dd->ctx;
+	struct rsa_key_obj *pkey = &ctx->key;
+	int err = 0;
+	uint8_t tmpdata[128];
+	uint32_t tmplen = 0;
+	uint8_t sign = 0;
+
+	if (dd->flags & RSA_FLAGS_ENC) {
+		rsa_encrypt(dd, pkey->n, pkey->e, dd->buf, dd->buflen, dd->buf,
+			    &dd->buflen, PKCS1_PADDING);
+		if (!sg_copy_from_buffer(dd->real_dst, sg_nents(dd->real_dst),
+					 dd->buf, dd->buflen))
+			err = -EINVAL;
+
+	} else if (dd->flags && RSA_FLAGS_DEC) {
+		rsa_decrypt(dd, pkey->n, pkey->d, dd->buf, dd->buflen,
+			    (uint8_t *)tmpdata, &tmplen, PKCS1_PADDING);
+		memset(dd->buf, 0, pkey->n_len);
+		memcpy(dd->buf+pkey->n_len-tmplen, tmpdata, tmplen);
+		if (!sg_copy_from_buffer(dd->real_dst, sg_nents(dd->real_dst),
+					 dd->buf, pkey->n_len))
+			err = -EINVAL;
+
+	} else if (dd->flags && RSA_FLAGS_SIGN) {
+		rsa_sign(dd, pkey->n, pkey->d, dd->buf, dd->buflen, dd->buf,
+				&pkey->n_len,MD5_PADDING);
+		if (!sg_copy_from_buffer(dd->real_dst, sg_nents(dd->real_dst),
+					 dd->buf, pkey->n_len))
+			err = -EINVAL;
+	} else if (dd->flags && RSA_FLAGS_VERIFY) {
+		sg_copy_to_buffer(dd->real_dst, sg_nents(dd->real_dst),
+				  (void *)tmpdata, pkey->n_len);
+		rsa_verify(dd, pkey->n, pkey->e, dd->buf, dd->buflen,
+			   (uint8_t *)&tmpdata, pkey->n_len,
+			   &sign, MD5_PADDING);
+		if (!sg_copy_from_buffer(dd->real_dst, sg_nents(dd->real_dst),
+		    (void *)&sign, 1))
+			err = -EINVAL;
+	} else
+		err = -EINVAL;
+
+	csky_rsa_complete(dd, err);
+
+	return err;
+}
+
+static int csky_rsa_handle_queue(struct csky_rsa_dev *dd,
+				 struct crypto_async_request *new_areq)
+{
+	struct crypto_async_request *areq, *backlog;
+	struct csky_rsa_base_ctx	*ctx;
+	unsigned long flags;
+	int ret = 0;
+
+	spin_lock_irqsave(&dd->lock, flags);
+	if (new_areq)
+		ret = crypto_enqueue_request(&dd->queue, new_areq);
+	if (dd->flags & RSA_FLAGS_BUSY) {
+		spin_unlock_irqrestore(&dd->lock, flags);
+		return ret;
+	}
+	backlog = crypto_get_backlog(&dd->queue);
+	areq = crypto_dequeue_request(&dd->queue);
+	if (areq)
+		dd->flags |= RSA_FLAGS_BUSY;
+	spin_unlock_irqrestore(&dd->lock, flags);
+
+	if (!areq)
+		return ret;
+
+	if (backlog)
+		backlog->complete(backlog, -EINPROGRESS);
+
+	ctx	 = crypto_tfm_ctx(areq->tfm);
+	dd->areq = areq;
+	dd->ctx  = ctx;
+
+	return csky_rsa_handle(dd);
+}
+
+static int csky_rsa_check_key_length(unsigned int len)
+{
+	switch (len) {
+	case 1024:
+		return 0;
+	}
+
+	return -EINVAL;
+}
+
+static int csky_rsa_enc(struct akcipher_request *req)
+{
+	struct csky_rsa_base_ctx *ctx;
+	struct csky_rsa_dev	 *dd;
+
+	ctx = akcipher_tfm_ctx(crypto_akcipher_reqtfm(req));
+	dd  = csky_rsa_find_dev(ctx);
+	if (!dd)
+		return -ENODEV;
+
+	dd->flags |= RSA_FLAGS_ENC;
+	dd->buflen = req->src_len;
+	dd->real_dst = req->dst;
+	sg_copy_to_buffer(req->src, sg_nents(req->src), dd->buf, req->src_len);
+
+	return csky_rsa_handle_queue(dd, &req->base);
+}
+
+static int csky_rsa_dec(struct akcipher_request *req)
+{
+	struct csky_rsa_base_ctx *ctx;
+	struct csky_rsa_dev	 *dd;
+
+	ctx = akcipher_tfm_ctx(crypto_akcipher_reqtfm(req));
+	dd  = csky_rsa_find_dev(ctx);
+	if (!dd)
+		return -ENODEV;
+
+	dd->flags |= RSA_FLAGS_DEC;
+	dd->buflen = req->src_len;
+	dd->real_dst = req->dst;
+	sg_copy_to_buffer(req->src, sg_nents(req->src), dd->buf, req->src_len);
+
+	return csky_rsa_handle_queue(dd, &req->base);
+}
+
+static int csky_rsa_sign(struct akcipher_request *req)
+{
+	struct csky_rsa_base_ctx *ctx;
+	struct csky_rsa_dev	 *dd;
+
+	ctx = akcipher_tfm_ctx(crypto_akcipher_reqtfm(req));
+	dd  = csky_rsa_find_dev(ctx);
+	if (!dd)
+		return -ENODEV;
+
+	dd->flags |= RSA_FLAGS_SIGN;
+	dd->buflen = req->src_len;
+	dd->real_dst = req->dst;
+	sg_copy_to_buffer(req->src, sg_nents(req->src), dd->buf, req->src_len);
+
+	return csky_rsa_handle_queue(dd, &req->base);
+}
+
+static int csky_rsa_verify(struct akcipher_request *req)
+{
+	struct csky_rsa_base_ctx *ctx;
+	struct csky_rsa_dev	 *dd;
+
+	ctx = akcipher_tfm_ctx(crypto_akcipher_reqtfm(req));
+	dd  = csky_rsa_find_dev(ctx);
+	if (!dd)
+		return -ENODEV;
+
+	dd->flags |= RSA_FLAGS_VERIFY;
+	dd->buflen = req->src_len;
+	dd->real_dst = req->dst;
+	sg_copy_to_buffer(req->src, sg_nents(req->src), dd->buf, req->src_len);
+
+	return csky_rsa_handle_queue(dd, &req->base);
+}
+
+static int csky_rsa_set_priv_key(struct crypto_akcipher *tfm, const void *key,
+				 unsigned int keylen)
+{
+	struct csky_rsa_ctx *ctx = akcipher_tfm_ctx(tfm);
+	struct rsa_key_obj *pkey = &ctx->base.key;
+	struct rsa_key raw_key = {0};
+	int ret;
+
+	ret = rsa_parse_priv_key(&raw_key, key, keylen);
+	if (ret)
+		return ret;
+
+	pkey->n_len = raw_key.n_sz;
+	memset(pkey->n, 0, pkey->n_len);
+	memcpy(pkey->n, raw_key.n, raw_key.n_sz);
+
+	pkey->d_len = raw_key.d_sz;
+	memset(pkey->d, 0, pkey->n_len);
+	memcpy(pkey->d, raw_key.d, raw_key.d_sz);
+
+	pkey->e_len = raw_key.e_sz;
+	memset(pkey->e, 0, pkey->n_len);
+	memcpy(&pkey->e[pkey->n_len - raw_key.e_sz], raw_key.e, raw_key.e_sz);
+
+	if (csky_rsa_check_key_length(pkey->n_len << 3)) {
+		return -EINVAL;
+	}
+
+	return 0;
+}
+
+static int csky_rsa_set_pub_key(struct crypto_akcipher *tfm, const void *key,
+				unsigned int keylen)
+{
+	struct csky_rsa_ctx *ctx = akcipher_tfm_ctx(tfm);
+	struct rsa_key_obj *pkey = &ctx->base.key;
+	struct rsa_key raw_key = {0};
+	int ret;
+
+	ret = rsa_parse_pub_key(&raw_key, key, keylen);
+	if (ret)
+		return ret;
+
+	pkey->n_len = raw_key.n_sz;
+	memset(pkey->n, 0, pkey->n_len);
+	memcpy(pkey->n, raw_key.n, raw_key.n_sz);
+
+	pkey->e_len = raw_key.e_sz;
+	memset(pkey->e, 0, pkey->n_len);
+	memcpy(&pkey->e[pkey->n_len - raw_key.e_sz], raw_key.e, raw_key.e_sz);
+
+	if (csky_rsa_check_key_length(pkey->n_len << 3)) {
+		return -EINVAL;
+	}
+
+	return 0;
+}
+
+static int csky_rsa_max_size(struct crypto_akcipher *tfm)
+{
+	struct csky_rsa_ctx *ctx = akcipher_tfm_ctx(tfm);
+	struct rsa_key_obj *pkey = &ctx->base.key;
+
+	return pkey->n_len;
+}
+
+static int csky_rsa_init(struct crypto_akcipher *tfm)
+{
+	struct csky_rsa_ctx *ctx = akcipher_tfm_ctx(tfm);
+	struct rsa_key_obj *pkey = &ctx->base.key;
+
+	pkey->n = (void *)__get_free_pages(GFP_KERNEL, 1);
+	if (!pkey->n)
+		goto _out_n;
+	pkey->e = (void *)__get_free_pages(GFP_KERNEL, 1);
+	if (!pkey->e)
+		goto _out_e;
+	pkey->d = (void *)__get_free_pages(GFP_KERNEL, 1);
+	if (!pkey->d)
+		goto _out_d;
+
+	return 0;
+
+_out_d:
+	free_page((unsigned long)pkey->e);
+_out_e:
+	free_page((unsigned long)pkey->n);
+_out_n:
+	return -ENOMEM;
+}
+
+static void csky_rsa_exit(struct crypto_akcipher *tfm)
+{
+	struct csky_rsa_ctx *ctx = akcipher_tfm_ctx(tfm);
+	struct rsa_key_obj *pkey = &ctx->base.key;
+
+	free_page((unsigned long)pkey->n);
+	free_page((unsigned long)pkey->d);
+	free_page((unsigned long)pkey->e);
+}
+
+static struct akcipher_alg rsa_algs[] = {
+	{
+		.encrypt	= csky_rsa_enc,
+		.decrypt	= csky_rsa_dec,
+		.sign		= csky_rsa_sign,
+		.verify		= csky_rsa_verify,
+		.set_priv_key	= csky_rsa_set_priv_key,
+		.set_pub_key	= csky_rsa_set_pub_key,
+		.max_size	= csky_rsa_max_size,
+		.init		= csky_rsa_init,
+		.exit		= csky_rsa_exit,
+		.reqsize	= sizeof(struct csky_rsa_reqctx),
+		.base = {
+			.cra_name	 = "rsa-c",
+			.cra_driver_name = "csky-rsa",
+			.cra_priority	 = 100,
+			.cra_module	 = THIS_MODULE,
+			.cra_ctxsize	 = sizeof(struct csky_rsa_ctx),
+		},
+	},
+};
+
+static void csky_rsa_done_task(unsigned long data)
+{
+	struct csky_rsa_dev *dd = (struct csky_rsa_dev *)data;
+
+	csky_rsa_handle_queue(dd, NULL);
+}
+
+static void csky_rsa_unregister_algs(struct csky_rsa_dev *dd)
+{
+	int i;
+
+	for (i = 0; i < ARRAY_SIZE(rsa_algs); i++)
+		crypto_unregister_akcipher(&rsa_algs[i]);
+}
+
+static int csky_rsa_register_algs(struct csky_rsa_dev *dd)
+{
+	int err, i, j;
+
+	for (i = 0; i < ARRAY_SIZE(rsa_algs); i++) {
+		err = crypto_register_akcipher(&rsa_algs[i]);
+		if (err) {
+			for (j = 0; j < i; j++)
+				crypto_unregister_akcipher(&rsa_algs[j]);
+			return err;
+		}
+	}
+
+	return 0;
+}
+
+static int csky_rsa_probe(struct platform_device *pdev)
+{
+	struct csky_rsa_dev *rsa_dd;
+	struct device	    *dev = &pdev->dev;
+	struct resource	    *rsa_res;
+	int err;
+
+	rsa_dd = devm_kzalloc(&pdev->dev, sizeof(*rsa_dd), GFP_KERNEL);
+	if (rsa_dd == NULL) {
+		dev_err(dev, "unable to alloc data struct.\n");
+		err = -ENOMEM;
+		goto rsa_dd_err;
+	}
+
+	rsa_dd->dev = dev;
+
+	platform_set_drvdata(pdev, rsa_dd);
+
+	INIT_LIST_HEAD(&rsa_dd->list);
+	spin_lock_init(&rsa_dd->lock);
+
+	tasklet_init(&rsa_dd->done_task,
+		     csky_rsa_done_task, (unsigned long)rsa_dd);
+
+	crypto_init_queue(&rsa_dd->queue, CSKY_RSA_QUEUE_LENGTH);
+
+	rsa_res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	if (!rsa_res) {
+		err = -ENODEV;
+		goto res_err;
+	}
+
+	rsa_dd->reg_base = devm_ioremap_resource(dev, rsa_res);
+	if (IS_ERR(rsa_dd->reg_base)) {
+		err = PTR_ERR(rsa_dd->reg_base);
+		goto res_err;
+	}
+
+	spin_lock(&csky_rsa.lock);
+	list_add_tail(&rsa_dd->list, &csky_rsa.dev_list);
+	spin_unlock(&csky_rsa.lock);
+
+	rsa_dd->buf = (void *)__get_free_pages(GFP_KERNEL, 1);
+	if (!rsa_dd->buf)
+		goto err_algs;
+
+	err = csky_rsa_register_algs(rsa_dd);
+	if (err)
+		goto err_algs;
+
+	dev_info(dev, "CSKY RSA Driver Initialized\n");
+
+	return 0;
+
+err_algs:
+	spin_lock(&csky_rsa.lock);
+	list_del(&rsa_dd->list);
+	spin_unlock(&csky_rsa.lock);
+res_err:
+	tasklet_kill(&rsa_dd->done_task);
+rsa_dd_err:
+
+	return err;
+}
+
+static int csky_rsa_remove(struct platform_device *pdev)
+{
+	static struct csky_rsa_dev *rsa_dd;
+
+	rsa_dd = platform_get_drvdata(pdev);
+	if (!rsa_dd)
+		return -ENODEV;
+
+	spin_lock(&csky_rsa.lock);
+	list_del(&rsa_dd->list);
+	spin_unlock(&csky_rsa.lock);
+
+	tasklet_kill(&rsa_dd->done_task);
+	csky_rsa_unregister_algs(rsa_dd);
+	free_page((unsigned long)rsa_dd->buf);
+
+	return 0;
+}
+
+static const struct of_device_id csky_rsa_dt_ids[] = {
+	{ .compatible = "csky,rsa-v1" },
+	{ /* sentinel */ }
+};
+MODULE_DEVICE_TABLE(of, csky_rsa_dt_ids);
+
+static struct platform_driver csky_rsa_driver = {
+	.probe	 = csky_rsa_probe,
+	.remove	 = csky_rsa_remove,
+	.driver	 = {
+		.name   = "csky_rsa",
+		.of_match_table = of_match_ptr(csky_rsa_dt_ids),
+	},
+};
+
+module_platform_driver(csky_rsa_driver);
+
+MODULE_DESCRIPTION("CSKY RSA hw acceleration support.");
+MODULE_LICENSE("GPL v2");
+MODULE_AUTHOR("Vincent Cui <xiaoxia_cui@c-sky.com>");
diff --git a/addons/drivers/crypto/csky_rsa.h b/addons/drivers/crypto/csky_rsa.h
new file mode 100644
index 0000000..336a4e3
--- /dev/null
+++ b/addons/drivers/crypto/csky_rsa.h
@@ -0,0 +1,71 @@
+/*
+ * Copyright (C) 2017 C-SKY MicroSystems Co.,Ltd.
+ * Author: Vincent Cui <xiaoxia_cui@c-sky.com>
+ *
+ * This software is licensed under the terms of the GNU General Public
+ * License version 2, as published by the Free Software Foundation, and
+ * may be copied, distributed, and modified under those terms.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ */
+
+#ifndef __CSKY_RSA_H
+#define __CSKY_RSA_H
+
+struct rsa_reg {
+	uint32_t rsa_mwid;
+	uint32_t rsa_dwid;
+	uint32_t rsa_bwid;
+	uint32_t rsa_ctrl;
+	uint32_t rsa_rst;
+	uint32_t rsa_lp_cnt;
+	uint32_t rsa_q0;
+	uint32_t rsa_q1;
+	uint32_t rsa_isr;
+	uint32_t rsa_imr;
+	uint32_t rev1[54];
+	uint32_t rsa_rfm;
+	uint32_t rev2[63];
+	uint32_t rsa_rfd;
+	uint32_t rev3[63];
+	uint32_t rsa_rfc;
+	uint32_t rev4[63];
+	uint32_t rsa_rfb;
+	uint32_t rev5[63];
+	uint32_t rsa_rfr;
+};
+
+#define RSA_KEY_LEN	1024
+
+#define BN_MAX_BITS	((RSA_KEY_LEN << 1) + 32)
+#define BN_MAX_BYTES	((BN_MAX_BITS + 7) >> 3)
+#define BN_MAX_WORDS	((BN_MAX_BYTES + 3) >> 2)
+
+#define MAX_RSA_LP_CNT	10000
+
+#define UINT32_TO_UINT64(data)	\
+	((uint64_t)(((uint64_t)(data)) & 0x00000000ffffffffU))
+#define UINT64L_TO_UINT32(data)	\
+	((uint32_t)(((uint64_t)(data)) & 0x00000000ffffffffU))
+#define UINT64H_TO_UINT32(data)	\
+	((uint32_t)((((uint64_t)(data)) >> 32) & 0x00000000ffffffffU))
+
+#define PKCS1_PADDING	0x01
+#define NO_PADDING	0x02
+
+#define MD5_PADDING	0x00
+#define SHA1_PADDING	0x01
+
+#define MD5_HASH_SZ	16
+#define SHA1_HASH_SZ	20
+
+typedef struct bignum {
+	uint32_t pdata[BN_MAX_WORDS];
+	uint32_t words;
+} bignum_t;
+
+#endif /* __CSKY_RSA_H */
diff --git a/addons/drivers/crypto/csky_sha.c b/addons/drivers/crypto/csky_sha.c
new file mode 100644
index 0000000..7111764
--- /dev/null
+++ b/addons/drivers/crypto/csky_sha.c
@@ -0,0 +1,1000 @@
+/*
+ * Copyright (C) 2017 C-SKY MicroSystems Co.,Ltd.
+ * Author: Vincent Cui <xiaoxia_cui@c-sky.com>
+ *
+ * This software is licensed under the terms of the GNU General Public
+ * License version 2, as published by the Free Software Foundation, and
+ * may be copied, distributed, and modified under those terms.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ */
+
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/err.h>
+#include <linux/io.h>
+#include <linux/platform_device.h>
+#include <linux/device.h>
+#include <linux/init.h>
+#include <linux/errno.h>
+#include <linux/interrupt.h>
+#include <linux/irq.h>
+#include <linux/of_device.h>
+#include <linux/delay.h>
+#include <linux/crypto.h>
+#include <linux/cryptohash.h>
+#include <crypto/scatterwalk.h>
+#include <crypto/algapi.h>
+#include <crypto/sha.h>
+#include <crypto/hash.h>
+#include <crypto/internal/hash.h>
+#include "csky_sha.h"
+
+/* SHA flags */
+#define SHA_FLAGS_BUSY		BIT(0)
+#define SHA_FLAGS_OUTPUT_READY  BIT(1)
+#define SHA_FLAGS_INIT		BIT(2)
+#define SHA_FLAGS_CPU		BIT(3)
+
+#define SHA_FLAGS_FINUP		BIT(16)
+#define SHA_FLAGS_FINAL		BIT(17)
+#define SHA_FLAGS_ALGO_MASK	GENMASK(22, 18)
+#define SHA_FLAGS_SHA1		BIT(18)
+#define SHA_FLAGS_SHA224	BIT(19)
+#define SHA_FLAGS_SHA256	BIT(20)
+#define SHA_FLAGS_SHA384	BIT(21)
+#define SHA_FLAGS_SHA512	BIT(22)
+#define SHA_FLAGS_ERROR		BIT(23)
+#define SHA_FLAGS_PAD		BIT(24)
+
+#define SHA_OP_UPDATE		1
+#define SHA_OP_FINAL		2
+
+#define SHA_BUFFER_LEN		(PAGE_SIZE / 16)
+
+#define CSKY_SHA_QUEUE_LENGTH	10
+
+struct csky_sha_dev;
+
+struct csky_sha_reqctx {
+	struct csky_sha_dev *dd;
+	unsigned long	     flags;
+	unsigned long	     op;
+
+	uint8_t	 digest[SHA512_DIGEST_SIZE] __aligned(sizeof(u32));
+	uint64_t digcnt;
+	size_t	 bufcnt;
+	size_t	 buflen;
+	size_t	 block_size;
+
+	uint32_t endian_flag;
+	size_t	 last_left;
+
+	struct scatterlist *sg;
+	unsigned int	    offset;
+	unsigned int	    total;
+
+	uint8_t  buffer[SHA_BUFFER_LEN+SHA512_BLOCK_SIZE] __aligned(sizeof(u32));
+
+};
+
+struct csky_sha_ctx {
+	struct csky_sha_dev *dd;
+};
+
+struct csky_sha_dev {
+	struct list_head	 list;
+	struct device		*dev;
+	struct sha_reg __iomem  *io_base;
+	spinlock_t		 lock;
+	struct tasklet_struct	 done_task;
+
+	unsigned long		 flags;
+	struct crypto_queue	 queue;
+	struct ahash_request	 *req;
+};
+
+struct csky_sha_drv {
+	struct list_head dev_list;
+	spinlock_t	 lock;
+};
+
+static struct csky_sha_drv csky_sha = {
+	.dev_list = LIST_HEAD_INIT(csky_sha.dev_list),
+	.lock 	  = __SPIN_LOCK_UNLOCKED(csky_sha.lock),
+};
+
+static inline void csky_sha_set_mode(struct csky_sha_dev *dd, sha_mode_t mode)
+{
+	uint32_t tmp;
+
+	tmp  = readl_relaxed(&dd->io_base->SHA_CON);
+	tmp  = mode;
+	writel_relaxed(tmp, &dd->io_base->SHA_CON);
+}
+
+static inline void csky_sha_enable_init(struct csky_sha_dev *dd)
+{
+	uint32_t tmp;
+
+	tmp  = readl_relaxed(&dd->io_base->SHA_CON);
+	tmp |= 1 << CSKY_SHA_INIT;
+	writel_relaxed(tmp, &dd->io_base->SHA_CON);
+}
+
+static inline void csky_sha_enable_calc(struct csky_sha_dev *dd)
+{
+	uint32_t tmp;
+
+	tmp  = readl_relaxed(&dd->io_base->SHA_CON);
+	tmp |= 1 << CSKY_SHA_CALC;
+	writel_relaxed(tmp, &dd->io_base->SHA_CON);
+}
+
+static inline void csky_sha_enable_int(struct csky_sha_dev *dd)
+{
+	uint32_t tmp;
+
+	tmp  = readl_relaxed(&dd->io_base->SHA_CON);
+	tmp |= 1 << CSKY_SHA_INT;
+	writel_relaxed(tmp, &dd->io_base->SHA_CON);
+}
+
+static inline void csky_sha_message_done(struct csky_sha_dev *dd)
+{
+	while((readl_relaxed(&dd->io_base->SHA_CON) & CSKY_SHA_DONE) != 0);
+}
+
+static inline void csky_sha_set_endian(struct csky_sha_dev *dd,
+					sha_endian_t mode)
+{
+	uint32_t tmp;
+
+	tmp  = readl_relaxed(&dd->io_base->SHA_CON);
+	tmp |= mode << CSKY_SHA_ENDIAN;
+	writel_relaxed(tmp, &dd->io_base->SHA_CON);
+}
+
+static inline void csky_sha_input_data(struct csky_sha_dev *dd,
+					uint32_t *data, uint32_t length)
+{
+	uint32_t i;
+	uint32_t input_data = (uint32_t)&dd->io_base->SHA_DATA1;
+	uint32_t tmp;
+	for (i=0; i<length; i++) {
+	#ifdef __LITTLE_ENDIAN
+		tmp = *(uint32_t *)(data + i);
+		*(uint32_t *)(data + i) = (((tmp & 0xff000000) >> 24) | \
+					   ((tmp & 0x00ff0000) >> 8)  | \
+					   ((tmp & 0x0000ff00) << 8)  | \
+					   ((tmp & 0x000000ff) << 24));
+	#endif
+		writel_relaxed(*(data + i), (void *)input_data);
+		input_data += 4;
+	}
+}
+
+static inline void csky_sha_reverse_order(uint8_t *pdata, int length)
+{
+	uint32_t wlen = length >> 2;
+	uint32_t result = 0;
+	uint32_t tmp_data[SHA512_DIGEST_SIZE>>2];
+	int i = 0;
+
+	memcpy((void *)tmp_data, (void *)pdata, length);
+	for (i = 0; i < wlen; i++) {
+		result = (((tmp_data[i] & 0xff000000) >> 24) | \
+			  ((tmp_data[i] & 0x00ff0000) >> 8)  | \
+			  ((tmp_data[i] & 0x0000ff00) << 8)  | \
+			  ((tmp_data[i] & 0x000000ff) << 24));
+
+		tmp_data[i] = result;
+	}
+	memcpy((void *)pdata, (void *)tmp_data, length);
+}
+
+static inline void csky_sha_get_data(struct csky_sha_dev *dd,
+				     uint32_t *data, uint32_t size)
+{
+	uint32_t result_l = (uint32_t)&dd->io_base->SHA_H0L;
+	uint32_t result_h = (uint32_t)&dd->io_base->SHA_H0H;
+	uint32_t i;
+
+	if (size >= (SHA384_DIGEST_SIZE/4)) {
+		for (i = 0; i < size/2; i++) {
+		    data[i << 1]       = readl_relaxed((void *)result_h);
+		    data[(i << 1) + 1] = readl_relaxed((void *)result_l);
+		    result_l += 4;
+		    result_h += 4;
+		}
+	} else {
+		for (i = 0; i < size; i++) {
+			data[i] = readl_relaxed((void *)result_l);
+			result_l += 4;
+		}
+	}
+
+	csky_sha_reverse_order((uint8_t *)data, size  << 2);
+}
+
+static void csky_sha_start(struct csky_sha_reqctx *ctx, sha_mode_t mode)
+{
+	struct csky_sha_dev *dd = ctx->dd;
+
+	csky_sha_set_mode(dd, mode);
+#ifdef __LITTLE_ENDIAN
+	csky_sha_set_endian(dd, SHA_LITTLE_ENDIAN);
+#else
+	csky_sha_set_endian(dd, SHA_BIG_ENDIAN);
+#endif
+	csky_sha_enable_init(dd);
+}
+
+static size_t csky_sha_append_sg(struct csky_sha_reqctx *ctx)
+{
+	size_t count;
+
+	while ((ctx->bufcnt < ctx->buflen) && ctx->total) {
+		count = min(ctx->sg->length - ctx->offset, ctx->total);
+		count = min(count, ctx->buflen - ctx->bufcnt);
+
+		if (count <= 0) {
+			if ((ctx->sg->length == 0) && !sg_is_last(ctx->sg)) {
+				ctx->sg = sg_next(ctx->sg);
+				continue;
+			} else
+				break;
+		}
+
+		scatterwalk_map_and_copy(ctx->buffer + ctx->bufcnt, ctx->sg,
+					 ctx->offset, count, 0);
+
+		ctx->bufcnt += count;
+		ctx->offset += count;
+		ctx->total  -= count;
+
+		if (ctx->offset == ctx->sg->length) {
+			ctx->sg = sg_next(ctx->sg);
+			if (ctx->sg)
+				ctx->offset = 0;
+			else
+				ctx->total = 0;
+		}
+	}
+
+	return 0;
+}
+
+static void csky_sha_flush_padding(struct csky_sha_reqctx *ctx,
+				   uint8_t *pad_buf, uint32_t pad_size)
+{
+	uint32_t block_size = ctx->block_size;
+	uint32_t left_len;
+	uint32_t left = ctx->digcnt & (block_size - 1);
+	uint32_t fill = block_size - left;
+	uint32_t len  = pad_size;
+	uint32_t i;
+
+	if ((block_size == SHA512_BLOCK_SIZE) ||
+		(block_size == SHA384_BLOCK_SIZE))
+		left_len = len & 0x7F;
+	else
+		left_len = len & 0x3F;
+
+	ctx->bufcnt += len;
+
+	if (len >= fill) {
+		memcpy((void *)(ctx->buffer + left), pad_buf, fill);
+		if ((len - fill) >= block_size)
+			memcpy((void *)(ctx->buffer + left + fill),
+				&pad_buf[fill], len - fill);
+	}
+}
+
+static void csky_sha_fill_padding(struct csky_sha_reqctx *ctx)
+{
+	uint32_t block_size = ctx->block_size;
+	uint32_t total_length = ctx->digcnt << 3;
+	uint32_t last = ctx->digcnt & (block_size - 1);
+	uint32_t pad_rsvr = (ctx->block_size >= SHA384_BLOCK_SIZE) ? 16 : 8;
+	uint32_t padn = (last < block_size - pad_rsvr) ?
+			(block_size - last) : (block_size * 2 - last);
+	uint32_t left = ctx->digcnt & 0x3;
+	uint8_t  temp[4];
+	uint8_t  sha_padding[SHA512_BLOCK_SIZE*2] = {0};
+	uint32_t i;
+
+	for (i = 0;  i < 4; i++)
+		temp[i] = (total_length >> (8 * i)) & 0xff;
+
+	memset(sha_padding, 0x0, SHA512_BLOCK_SIZE*2);
+
+	sha_padding[0] = 0x80;
+
+	for (i = 0; i < 4; i++)
+		sha_padding[padn - 4 + i] = temp[3 - i];
+
+	csky_sha_flush_padding(ctx, sha_padding, padn);
+
+	ctx->flags |= SHA_FLAGS_PAD;
+
+}
+
+static int csky_sha_init(struct ahash_request *req)
+{
+	struct crypto_ahash *tfm = crypto_ahash_reqtfm(req);
+	struct csky_sha_ctx *tctx = crypto_ahash_ctx(tfm);
+	struct csky_sha_reqctx *ctx = ahash_request_ctx(req);
+	struct csky_sha_dev *dd = NULL;
+	struct csky_sha_dev *tmp;
+	sha_mode_t mode;
+
+	spin_lock_bh(&csky_sha.lock);
+	if (!tctx->dd) {
+		list_for_each_entry(tmp, &csky_sha.dev_list, list) {
+			dd = tmp;
+			break;
+		}
+		tctx->dd = dd;
+	} else
+		dd = tctx->dd;
+	spin_unlock_bh(&csky_sha.lock);
+
+	ctx->dd = dd;
+	ctx->flags = 0;
+
+	dev_dbg(dd->dev, "digest size: %d\n", crypto_ahash_digestsize(tfm));
+
+	switch (crypto_ahash_digestsize(tfm)) {
+	case SHA1_DIGEST_SIZE:
+		ctx->flags 	|= SHA_FLAGS_SHA1;
+		ctx->block_size  = SHA1_BLOCK_SIZE;
+		mode 		 = SHA_1;
+		break;
+	case SHA224_DIGEST_SIZE:
+		ctx->flags 	|= SHA_FLAGS_SHA224;
+		ctx->block_size  = SHA224_BLOCK_SIZE;
+		mode 		 = SHA_224;
+		break;
+	case SHA256_DIGEST_SIZE:
+		ctx->flags 	|= SHA_FLAGS_SHA256;
+		ctx->block_size  = SHA256_BLOCK_SIZE;
+		mode 		 = SHA_256;
+		break;
+	case SHA384_DIGEST_SIZE:
+		ctx->flags 	|= SHA_FLAGS_SHA384;
+		ctx->block_size  = SHA384_BLOCK_SIZE;
+		mode 		 = SHA_384;
+		break;
+	case SHA512_DIGEST_SIZE:
+		ctx->flags 	|= SHA_FLAGS_SHA512;
+		ctx->block_size  = SHA512_BLOCK_SIZE;
+		mode 		 = SHA_512;
+		break;
+	default:
+		return -EINVAL;
+		break;
+	}
+
+	ctx->bufcnt = 0;
+	ctx->digcnt = 0;
+	ctx->buflen = ctx->block_size;
+	ctx->last_left = 0;
+	ctx->total  = 0;
+
+	csky_sha_start(ctx, mode);
+
+	return 0;
+}
+
+static int csky_sha_xmit_cpu(struct csky_sha_dev *dd, const uint8_t *buf,
+			     size_t length, int final)
+{
+	struct csky_sha_reqctx *ctx = ahash_request_ctx(dd->req);
+	int count, len32;
+
+	dev_dbg(dd->dev, "xmit_cpu: digcnt: 0x%llx, length: %d, final: %d\n",
+		 ctx->digcnt, length, final);
+
+	if (final)
+		dd->flags |= SHA_FLAGS_FINAL;
+
+	len32 = DIV_ROUND_UP(length, sizeof(u32));
+
+	dd->flags |= SHA_FLAGS_CPU;
+
+	for (count = 0; count < length; count += ctx->block_size) {
+		csky_sha_input_data(dd, (uint32_t *)&ctx->buffer[count],
+				    ctx->block_size >> 2);
+		csky_sha_enable_calc(dd);
+		csky_sha_message_done(dd);
+	}
+
+	return 0;
+}
+
+static int csky_sha_update_req(struct csky_sha_dev *dd)
+{
+	struct ahash_request   *req = dd->req;
+	struct csky_sha_reqctx *ctx = ahash_request_ctx(req);
+	int err = 0;
+	int bufcnt;
+	uint32_t last_total = 0;
+
+	if (ctx->flags & SHA_FLAGS_FINUP) {
+		ctx->digcnt += ctx->total;
+		while (ctx->total >= ctx->buflen) {
+			csky_sha_append_sg(ctx);
+			bufcnt = ctx->bufcnt;
+			ctx->bufcnt = 0;
+			err = csky_sha_xmit_cpu(dd, ctx->buffer, bufcnt, 0);
+			if (err != 0)
+				return err;
+		}
+	} else {
+		while ((ctx->total + ctx->bufcnt) >= ctx->buflen) {
+			last_total = ctx->total;
+			csky_sha_append_sg(ctx);
+			bufcnt = ctx->bufcnt;
+			ctx->bufcnt = 0;
+			ctx->digcnt += bufcnt?(last_total-ctx->total):bufcnt;
+			last_total = ctx->total;
+			err = csky_sha_xmit_cpu(dd, ctx->buffer, bufcnt, 0);
+			if (err != 0)
+				return err;
+		}
+
+		if (ctx->total > 0) {
+			ctx->digcnt += ctx->total;
+			csky_sha_append_sg(ctx);
+		}
+	}
+
+	return err;
+}
+
+static int csky_sha_final_req(struct csky_sha_dev *dd)
+{
+	struct ahash_request   *req = dd->req;
+	struct csky_sha_reqctx *ctx = ahash_request_ctx(req);
+	int err = 0;
+	int bufcnt;
+
+	if (ctx->total != 0)
+		csky_sha_append_sg(ctx);
+
+	csky_sha_fill_padding(ctx);
+
+	bufcnt = ctx->bufcnt;
+	ctx->bufcnt = 0;
+	err = csky_sha_xmit_cpu(dd, ctx->buffer, bufcnt, 1);
+
+	dd->flags |= SHA_FLAGS_OUTPUT_READY;
+
+	tasklet_schedule(&dd->done_task);
+
+	return err;
+}
+
+static void csky_sha_copy_hash(struct ahash_request *req)
+{
+	struct csky_sha_reqctx *ctx = ahash_request_ctx(req);
+	uint32_t *hash = (uint32_t *)ctx->digest;
+	uint32_t hashsize;
+
+	switch (ctx->flags & SHA_FLAGS_ALGO_MASK) {
+	case SHA_FLAGS_SHA1:
+		hashsize = SHA1_DIGEST_SIZE;
+		break;
+	case SHA_FLAGS_SHA224:
+		hashsize = SHA224_DIGEST_SIZE;
+		break;
+	case SHA_FLAGS_SHA256:
+		hashsize = SHA256_DIGEST_SIZE;
+		break;
+	case SHA_FLAGS_SHA384:
+		hashsize = SHA384_DIGEST_SIZE;
+		break;
+	case SHA_FLAGS_SHA512:
+		hashsize = SHA512_DIGEST_SIZE;
+		break;
+	default:
+		hashsize = SHA1_DIGEST_SIZE;
+		break;
+	}
+
+	csky_sha_get_data(ctx->dd, hash, hashsize >> 2);
+}
+
+static void csky_sha_copy_ready_hash(struct ahash_request *req)
+{
+	struct csky_sha_reqctx *ctx = ahash_request_ctx(req);
+
+	if (!req->result)
+		return;
+
+	if (ctx->flags & SHA_FLAGS_SHA1)
+		memcpy(req->result, ctx->digest, SHA1_DIGEST_SIZE);
+	else if (ctx->flags & SHA_FLAGS_SHA224)
+		memcpy(req->result, ctx->digest, SHA224_DIGEST_SIZE);
+	else if (ctx->flags & SHA_FLAGS_SHA256)
+		memcpy(req->result, ctx->digest, SHA256_DIGEST_SIZE);
+	else if (ctx->flags & SHA_FLAGS_SHA384)
+		memcpy(req->result, ctx->digest, SHA384_DIGEST_SIZE);
+	else
+		memcpy(req->result, ctx->digest, SHA512_DIGEST_SIZE);
+}
+
+static int csky_sha_finish(struct ahash_request *req)
+{
+	struct csky_sha_reqctx *ctx = ahash_request_ctx(req);
+	struct csky_sha_dev 	*dd = ctx->dd;
+
+	csky_sha_copy_ready_hash(req);
+
+	dev_dbg(dd->dev, "digcnt: 0x%llx, bufcnt: %d\n", ctx->digcnt, ctx->bufcnt);
+
+	return 0;
+}
+
+static void csky_sha_finish_req(struct ahash_request *req, int err)
+{
+	struct csky_sha_reqctx *ctx = ahash_request_ctx(req);
+	struct csky_sha_dev 	*dd = ctx->dd;
+
+	if (!err) {
+		csky_sha_copy_hash(req);
+		if (SHA_FLAGS_FINAL & dd->flags)
+			err = csky_sha_finish(req);
+	} else
+		ctx->flags |= SHA_FLAGS_ERROR;
+
+	dd->flags &= ~(SHA_FLAGS_BUSY | SHA_FLAGS_FINAL | SHA_FLAGS_CPU |
+		       SHA_FLAGS_OUTPUT_READY);
+
+	if (req->base.complete)
+		req->base.complete(&req->base, err);
+}
+
+static int csky_sha_handle_queue(struct csky_sha_dev *dd,
+				 struct ahash_request *req)
+{
+	struct crypto_async_request *async_req, *backlog;
+	struct csky_sha_reqctx *ctx;
+	unsigned long flags;
+	int err = 0, ret = 0;
+
+	spin_lock_irqsave(&dd->lock, flags);
+	if (req)
+		ret = ahash_enqueue_request(&dd->queue, req);
+
+	if (SHA_FLAGS_BUSY & dd->flags) {
+		spin_unlock_irqrestore(&dd->lock, flags);
+		return ret;
+	}
+
+	backlog = crypto_get_backlog(&dd->queue);
+	async_req = crypto_dequeue_request(&dd->queue);
+	if (async_req)
+		dd->flags |= SHA_FLAGS_BUSY;
+	spin_unlock_irqrestore(&dd->lock, flags);
+
+	if (!async_req)
+		return ret;
+
+	if (backlog)
+		backlog->complete(backlog, -EINPROGRESS);
+
+	req = ahash_request_cast(async_req);
+	dd->req = req;
+	ctx = ahash_request_ctx(req);
+
+	dev_dbg(dd->dev, "handling new req, op: %lu, nbytes: %d\n",
+						ctx->op, req->nbytes);
+
+	if (ctx->op == SHA_OP_UPDATE) {
+		err = csky_sha_update_req(dd);
+		if (err != -EINPROGRESS && (ctx->flags & SHA_FLAGS_FINUP))
+			err = csky_sha_final_req(dd);
+		else {
+			dd->flags &= ~SHA_FLAGS_BUSY;
+			return 0;
+		}
+	} else if (ctx->op == SHA_OP_FINAL)
+		err = csky_sha_final_req(dd);
+
+	if (err != -EINPROGRESS)
+		csky_sha_finish_req(req, err);
+
+	dev_dbg(dd->dev, "exit, err: %d\n", err);
+
+	return ret;
+}
+
+static int csky_sha_enqueue(struct ahash_request *req, unsigned int op)
+{
+	struct csky_sha_reqctx *ctx = ahash_request_ctx(req);
+	struct csky_sha_ctx   *tctx = crypto_tfm_ctx(req->base.tfm);
+	struct csky_sha_dev     *dd = tctx->dd;
+
+	ctx->op = op;
+
+	return csky_sha_handle_queue(dd, req);
+}
+
+static int csky_sha_update(struct ahash_request *req)
+{
+	struct csky_sha_reqctx *ctx = ahash_request_ctx(req);
+
+	if (!req->nbytes)
+		return 0;
+
+	ctx->total  = req->nbytes;
+	ctx->sg	    = req->src;
+	ctx->offset = 0;
+
+	if (ctx->flags & SHA_FLAGS_FINUP)
+		ctx->flags |= SHA_FLAGS_CPU;
+	else if (ctx->bufcnt + ctx->total < ctx->buflen) {
+		ctx->digcnt += ctx->total;
+		csky_sha_append_sg(ctx);
+		return 0;
+	}
+
+	return csky_sha_enqueue(req, SHA_OP_UPDATE);
+}
+
+static int csky_sha_final(struct ahash_request *req)
+{
+	struct csky_sha_reqctx *ctx = ahash_request_ctx(req);
+
+	ctx->flags |= SHA_FLAGS_FINUP;
+
+	if (ctx->flags & SHA_FLAGS_ERROR)
+		return 0;
+
+	return csky_sha_enqueue(req, SHA_OP_FINAL);
+}
+
+static int csky_sha_finup(struct ahash_request *req)
+{
+	struct csky_sha_reqctx *ctx = ahash_request_ctx(req);
+	int err1, err2;
+
+	ctx->flags |= SHA_FLAGS_FINUP;
+
+	err1 = csky_sha_update(req);
+	if (err1 == -EINPROGRESS || err1 == -EBUSY)
+		return err1;
+
+	err2 = csky_sha_final(req);
+
+	return err1 ?: err2;
+}
+
+static int csky_sha_digest(struct ahash_request *req)
+{
+	return csky_sha_init(req) ?: csky_sha_finup(req);
+}
+
+static int csky_sha_export(struct ahash_request *req, void *out)
+{
+	const struct csky_sha_reqctx *ctx = ahash_request_ctx(req);
+
+	memcpy(out, ctx, sizeof(*ctx));
+	return 0;
+}
+
+static int csky_sha_import(struct ahash_request *req, const void *in)
+{
+	struct csky_sha_reqctx *ctx = ahash_request_ctx(req);
+
+	memcpy(ctx, in, sizeof(*ctx));
+	return 0;
+}
+
+static int csky_sha_cra_init(struct crypto_tfm *tfm)
+{
+	crypto_ahash_set_reqsize(__crypto_ahash_cast(tfm),
+				 sizeof(struct csky_sha_reqctx));
+
+	return 0;
+}
+
+static struct ahash_alg sha_1_256_algs[] = {
+	{
+		.init	= csky_sha_init,
+		.update	= csky_sha_update,
+		.final	= csky_sha_final,
+		.finup	= csky_sha_finup,
+		.digest = csky_sha_digest,
+		.export = csky_sha_export,
+		.import = csky_sha_import,
+		.halg = {
+			.digestsize = SHA1_DIGEST_SIZE,
+			.statesize  = sizeof(struct csky_sha_reqctx),
+			.base = {
+				.cra_name	 = "sha1",
+				.cra_driver_name = "csky-sha1",
+				.cra_priority	 = 100,
+				.cra_flags	 = CRYPTO_ALG_ASYNC,
+				.cra_blocksize	 = SHA1_BLOCK_SIZE,
+				.cra_ctxsize	 = sizeof(struct csky_sha_ctx),
+				.cra_alignmask	 = 0,
+				.cra_module	 = THIS_MODULE,
+				.cra_init	 = csky_sha_cra_init,
+			}
+		}
+	},
+	{
+		.init	= csky_sha_init,
+		.update	= csky_sha_update,
+		.final	= csky_sha_final,
+		.finup	= csky_sha_finup,
+		.digest	= csky_sha_digest,
+		.export	= csky_sha_export,
+		.import	= csky_sha_import,
+		.halg = {
+			.digestsize = SHA256_DIGEST_SIZE,
+			.statesize  = sizeof(struct csky_sha_reqctx),
+			.base = {
+				.cra_name	 = "sha256",
+				.cra_driver_name = "csky-sha256",
+				.cra_priority	 = 100,
+				.cra_flags	 = CRYPTO_ALG_ASYNC,
+				.cra_blocksize	 = SHA256_BLOCK_SIZE,
+				.cra_ctxsize	 = sizeof(struct csky_sha_ctx),
+				.cra_alignmask	 = 0,
+				.cra_module	 = THIS_MODULE,
+				.cra_init	 = csky_sha_cra_init,
+			}
+		}
+	},
+};
+
+static struct ahash_alg sha_224_alg = {
+	.init   = csky_sha_init,
+	.update	= csky_sha_update,
+	.final	= csky_sha_final,
+	.finup	= csky_sha_finup,
+	.digest	= csky_sha_digest,
+	.export	= csky_sha_export,
+	.import	= csky_sha_import,
+	.halg = {
+		.digestsize = SHA224_DIGEST_SIZE,
+		.statesize  = sizeof(struct csky_sha_reqctx),
+		.base   = {
+			.cra_name	 = "sha224",
+			.cra_driver_name = "csky-sha224",
+			.cra_priority	 = 100,
+			.cra_flags	 = CRYPTO_ALG_ASYNC,
+			.cra_blocksize	 = SHA224_BLOCK_SIZE,
+			.cra_ctxsize     = sizeof(struct csky_sha_ctx),
+			.cra_alignmask	 = 0,
+			.cra_module	 = THIS_MODULE,
+			.cra_init	 = csky_sha_cra_init,
+		}
+	}
+};
+
+static struct ahash_alg sha_384_512_algs[] = {
+	{
+		.init	= csky_sha_init,
+		.update	= csky_sha_update,
+		.final  = csky_sha_final,
+		.finup	= csky_sha_finup,
+		.digest	= csky_sha_digest,
+		.export	= csky_sha_export,
+		.import	= csky_sha_import,
+		.halg = {
+			.digestsize = SHA384_DIGEST_SIZE,
+			.statesize  = sizeof(struct csky_sha_reqctx),
+			.base = {
+				.cra_name	 = "sha384",
+				.cra_driver_name = "csky-sha384",
+				.cra_priority	 = 100,
+				.cra_flags	 = CRYPTO_ALG_ASYNC,
+				.cra_blocksize	 = SHA384_BLOCK_SIZE,
+				.cra_ctxsize	 = sizeof(struct csky_sha_ctx),
+				.cra_alignmask	 = 0x3,
+				.cra_module	 = THIS_MODULE,
+				.cra_init	 = csky_sha_cra_init,
+			}
+		}
+	},
+	{
+		.init   = csky_sha_init,
+		.update	= csky_sha_update,
+		.final	= csky_sha_final,
+		.finup  = csky_sha_finup,
+		.digest	= csky_sha_digest,
+		.export	= csky_sha_export,
+		.import	= csky_sha_import,
+		.halg = {
+			.digestsize = SHA512_DIGEST_SIZE,
+			.statesize  = sizeof(struct csky_sha_reqctx),
+			.base = {
+				.cra_name	 = "sha512",
+				.cra_driver_name = "csky-sha512",
+				.cra_priority	 = 100,
+				.cra_flags	 = CRYPTO_ALG_ASYNC,
+				.cra_blocksize	 = SHA512_BLOCK_SIZE,
+				.cra_ctxsize	 = sizeof(struct csky_sha_ctx),
+				.cra_alignmask	 = 0x3,
+				.cra_module	 = THIS_MODULE,
+				.cra_init	 = csky_sha_cra_init,
+			}
+		}
+	},
+};
+
+static void csky_sha_done_task(unsigned long data)
+{
+	struct csky_sha_dev *dd = (struct csky_sha_dev *)data;
+
+	if (SHA_FLAGS_CPU & dd->flags) {
+		if (SHA_FLAGS_OUTPUT_READY & dd->flags)
+			dd->flags &= ~SHA_FLAGS_OUTPUT_READY;
+	}
+
+	return;
+}
+
+static void csky_sha_unregister_algs(struct csky_sha_dev *dd)
+{
+	int i;
+
+	for (i = 0; i < ARRAY_SIZE(sha_1_256_algs); i++)
+		crypto_unregister_ahash(&sha_1_256_algs[i]);
+
+	crypto_unregister_ahash(&sha_224_alg);
+
+	for (i = 0; i < ARRAY_SIZE(sha_384_512_algs); i++)
+		crypto_unregister_ahash(&sha_384_512_algs[i]);
+}
+
+static int csky_sha_register_algs(struct csky_sha_dev *dd)
+{
+	int err, i, j;
+
+	for (i = 0; i < ARRAY_SIZE(sha_1_256_algs); i++) {
+		err = crypto_register_ahash(&sha_1_256_algs[i]);
+		if (err)
+			goto err_sha_1_256_algs;
+	}
+
+	err = crypto_register_ahash(&sha_224_alg);
+	if (err)
+		goto err_sha_224_algs;
+
+	for (i = 0; i < ARRAY_SIZE(sha_384_512_algs); i++) {
+		err = crypto_register_ahash(&sha_384_512_algs[i]);
+		if (err)
+			goto err_sha_384_512_algs;
+	}
+
+	return 0;
+
+err_sha_384_512_algs:
+	for (j = 0; j < i; j++)
+		crypto_unregister_ahash(&sha_384_512_algs[j]);
+	crypto_unregister_ahash(&sha_224_alg);
+
+err_sha_224_algs:
+	i = ARRAY_SIZE(sha_1_256_algs);
+err_sha_1_256_algs:
+	for (j = 0; j < i; j++)
+		crypto_unregister_ahash(&sha_1_256_algs[j]);
+
+	return err;
+}
+
+static int csky_sha_probe(struct platform_device *pdev)
+{
+	struct csky_sha_dev *sha_dd;
+	struct device *dev = &pdev->dev;
+	struct resource *sha_res;
+	int err;
+
+	sha_dd = devm_kzalloc(&pdev->dev, sizeof(*sha_dd), GFP_KERNEL);
+	if (sha_dd == NULL) {
+		dev_err(dev, "unable to alloc data struct.\n");
+		err = -ENOMEM;
+		goto sha_dd_err;
+	}
+
+	sha_dd->dev = dev;
+
+	platform_set_drvdata(pdev, sha_dd);
+
+	INIT_LIST_HEAD(&sha_dd->list);
+	spin_lock_init(&sha_dd->lock);
+
+	tasklet_init(&sha_dd->done_task, csky_sha_done_task,
+					(unsigned long)sha_dd);
+
+	crypto_init_queue(&sha_dd->queue, CSKY_SHA_QUEUE_LENGTH);
+
+	sha_res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	if (!sha_res) {
+		dev_err(dev, "no MEM resource info\n");
+		err = -ENODEV;
+		goto res_err;
+	}
+
+	sha_dd->io_base = devm_ioremap_resource(&pdev->dev, sha_res);
+	if (IS_ERR(sha_dd->io_base)) {
+		dev_err(dev, "can't ioremap\n");
+		err = PTR_ERR(sha_dd->io_base);
+		goto res_err;
+	}
+
+	spin_lock(&csky_sha.lock);
+	list_add_tail(&sha_dd->list, &csky_sha.dev_list);
+	spin_unlock(&csky_sha.lock);
+
+	err = csky_sha_register_algs(sha_dd);
+	if (err)
+		goto err_algs;
+
+	dev_info(dev, "CSKY SHA Driver Initialized\n");
+
+	return 0;
+
+err_algs:
+	spin_lock(&csky_sha.lock);
+	list_del(&sha_dd->list);
+	spin_unlock(&csky_sha.lock);
+
+res_err:
+	tasklet_kill(&sha_dd->done_task);
+sha_dd_err:
+	dev_err(dev, "initialization failed.\n");
+
+	return err;
+}
+
+static int csky_sha_remove(struct platform_device *pdev)
+{
+	static struct csky_sha_dev *sha_dd;
+
+	sha_dd = platform_get_drvdata(pdev);
+	if (!sha_dd)
+		return -ENODEV;
+
+	spin_lock(&csky_sha.lock);
+	list_del(&sha_dd->list);
+	spin_unlock(&csky_sha.lock);
+
+	csky_sha_unregister_algs(sha_dd);
+
+	tasklet_kill(&sha_dd->done_task);
+
+	return 0;
+}
+
+static const struct of_device_id csky_sha_dt_ids[] = {
+	{ .compatible = "csky,sha-v2" },
+	{ /* sentinel */ }
+};
+
+MODULE_DEVICE_TABLE(of, csky_sha_dt_ids);
+
+static struct platform_driver csky_sha_driver = {
+	.probe	  = csky_sha_probe,
+	.remove	 = csky_sha_remove,
+	.driver	 = {
+		.name = "csky-sha",
+		.of_match_table = of_match_ptr(csky_sha_dt_ids),
+	},
+};
+
+module_platform_driver(csky_sha_driver);
+
+MODULE_DESCRIPTION("CSKY SHA (1/256/224/384/512) hw acceleration support.");
+MODULE_LICENSE("GPL v2");
+MODULE_AUTHOR("Vincent Cui <xiaoxia_cui@c-sky.com>");
diff --git a/addons/drivers/crypto/csky_sha.h b/addons/drivers/crypto/csky_sha.h
new file mode 100644
index 0000000..9f57d72
--- /dev/null
+++ b/addons/drivers/crypto/csky_sha.h
@@ -0,0 +1,71 @@
+/*
+ * Copyright (C) 2017 C-SKY MicroSystems Co.,Ltd.
+ * Author: Vincent Cui <xiaoxia_cui@c-sky.com>
+ *
+ * This software is licensed under the terms of the GNU General Public
+ * License version 2, as published by the Free Software Foundation, and
+ * may be copied, distributed, and modified under those terms.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ */
+
+#ifndef __CSKY_SHA_H__
+#define __CSKY_SHA_H__
+
+
+#define CSKY_SHA_INIT	3
+#define CSKY_SHA_INT	4
+#define CSKY_SHA_ENDIAN	5
+#define CSKY_SHA_CALC	6
+#define CSKY_SHA_DONE	0x40
+
+typedef struct sha_reg {
+	uint32_t SHA_CON;
+	uint32_t SHA_INTSTATE;
+	uint32_t SHA_H0L;
+	uint32_t SHA_H1L;
+	uint32_t SHA_H2L;
+	uint32_t SHA_H3L;
+	uint32_t SHA_H4L;
+	uint32_t SHA_H5L;
+	uint32_t SHA_H6L;
+	uint32_t SHA_H7L;
+	uint32_t SHA_H0H;
+	uint32_t SHA_H1H;
+	uint32_t SHA_H2H;
+	uint32_t SHA_H3H;
+	uint32_t SHA_H4H;
+	uint32_t SHA_H5H;
+	uint32_t SHA_H6H;
+	uint32_t SHA_H7H;
+	uint32_t SHA_DATA1;
+	uint32_t REV[15];
+	uint32_t SHA_DATA2;
+} sha_reg_t;
+
+typedef enum{
+	SHA_1       = 1,
+	SHA_256     = 2,
+	SHA_224     = 3,
+	SHA_512     = 4,
+	SHA_384     = 5,
+}sha_mode_t;
+
+typedef enum{
+	SHA_STATUS_HASH      = 0,
+	SHA_STATUS_START     = 1,
+	SHA_STATUS_UPDATE    = 2,
+	SHA_STATUS_END       = 3
+}sha_status_t;
+
+typedef enum{
+	SHA_BIG_ENDIAN    = 0,
+	SHA_LITTLE_ENDIAN = 1
+}sha_endian_t;
+
+#endif
+
diff --git a/addons/drivers/crypto/csky_tdes.c b/addons/drivers/crypto/csky_tdes.c
new file mode 100644
index 0000000..665218b
--- /dev/null
+++ b/addons/drivers/crypto/csky_tdes.c
@@ -0,0 +1,639 @@
+/*
+ * Copyright (C) 2017 C-SKY MicroSystems Co.,Ltd.
+ * Author: Vincent Cui <xiaoxia_cui@c-sky.com>
+ *
+ * This software is licensed under the terms of the GNU General Public
+ * License version 2, as published by the Free Software Foundation, and
+ * may be copied, distributed, and modified under those terms.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ */
+
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/err.h>
+#include <linux/io.h>
+#include <linux/platform_device.h>
+#include <linux/device.h>
+#include <linux/init.h>
+#include <linux/errno.h>
+#include <linux/interrupt.h>
+#include <linux/irq.h>
+#include <linux/of_device.h>
+#include <linux/delay.h>
+#include <linux/crypto.h>
+#include <crypto/algapi.h>
+#include <crypto/des.h>
+#include "csky_tdes.h"
+
+#define CSKY_TDES_BUFFER_ORDER	2
+#define CSKY_TDES_BUFFER_SIZE	(PAGE_SIZE << CSKY_TDES_BUFFER_ORDER)
+
+#define TDES_FLAGS_ENC		BIT(0)
+#define TDES_FLAGS_DEC		BIT(1)
+#define TDES_FLAGS_ECB		BIT(2)
+#define TDES_FLAGS_CBC		BIT(3)
+
+#define TDES_FLAGS_INIT		BIT(8)
+#define TDES_FLAGS_BUSY		BIT(9)
+
+#define CSKY_TDES_QUEUE_LENGTH	10
+
+#define SIZE_IN_WORDS(x) 	(x>>2)
+
+#define HTOL(x) ((x & 0xff) << 24 | (x & 0xff00) << 8 | \
+		 (x & 0xff0000) >> 8 | (x & 0xff000000) >> 24)
+
+struct csky_tdes_dev;
+
+struct csky_tdes_base_ctx {
+	struct csky_tdes_dev *dd;
+	int keylen;
+	u32 key[3*DES_KEY_SIZE / sizeof(u32)];
+	u32 block_size;
+};
+
+struct csky_tdes_ctx {
+	struct csky_tdes_base_ctx base;
+};
+
+struct csky_tdes_ctr_ctx {
+	struct csky_tdes_base_ctx base;
+	u32 iv[DES_BLOCK_SIZE / sizeof(u32)];
+};
+
+struct csky_tdes_reqctx {
+	unsigned long mode;
+};
+
+struct csky_tdes_dev {
+	struct list_head		list;
+	struct crypto_async_request	*areq;
+	struct csky_tdes_base_ctx	*ctx;
+	struct device			*dev;
+	struct tdes_reg __iomem		*reg_base;
+	struct tasklet_struct		done_task;
+
+	struct crypto_queue 		queue;
+	struct scatterlist 		*real_dst;
+	unsigned long			flags;
+	spinlock_t			lock;
+	size_t				total;
+	size_t				datalen;
+	u32				*data;
+	size_t				buflen;
+	void				*buf;
+};
+
+struct csky_tdes_drv {
+	struct list_head dev_list;
+	spinlock_t	 lock;
+};
+
+static struct csky_tdes_drv csky_tdes = {
+	.dev_list = LIST_HEAD_INIT(csky_tdes.dev_list),
+	.lock	  = __SPIN_LOCK_UNLOCKED(csky_tdes.lock),
+};
+
+static struct csky_tdes_dev *csky_tdes_find_dev(struct csky_tdes_base_ctx *ctx)
+{
+	struct csky_tdes_dev *tdes_dd = NULL;
+	struct csky_tdes_dev *tmp;
+
+	spin_lock_bh(&csky_tdes.lock);
+	if (!ctx->dd) {
+		list_for_each_entry(tmp, &csky_tdes.dev_list, list) {
+			tdes_dd = tmp;
+			break;
+		}
+		ctx->dd = tdes_dd;
+	} else {
+		tdes_dd = ctx->dd;
+	}
+	spin_unlock_bh(&csky_tdes.lock);
+
+	return tdes_dd;
+}
+
+static inline void csky_tdes_setopcode(struct csky_tdes_dev *dd)
+{
+	uint32_t tmp;
+
+	tmp  = readl_relaxed(&dd->reg_base->ctrl);
+	tmp &= ~0x0002;
+	if (dd->flags & TDES_FLAGS_ENC)
+		tmp |= TDES_OPC_ENC;
+	else if (dd->flags & TDES_FLAGS_DEC)
+		tmp |= TDES_OPC_DEC;
+
+	tmp &= ~0x0010;
+	if (dd->flags & TDES_FLAGS_CBC)
+		tmp |= TDES_MOD_CBC;
+	else
+		tmp |= TDES_MOD_ECB;
+
+	tmp |= TDES_OPR_DES3;
+	writel_relaxed(tmp, &dd->reg_base->ctrl);
+}
+
+static inline void csky_tdes_enable(struct csky_tdes_dev *dd)
+{
+	uint32_t tmp;
+
+	tmp  = readl_relaxed(&dd->reg_base->ctrl);
+	tmp |= 1;
+	writel_relaxed(tmp, &dd->reg_base->ctrl);
+}
+
+static inline void csky_tdes_disable(struct csky_tdes_dev *dd)
+{
+	uint32_t tmp;
+
+	tmp  = readl_relaxed(&dd->reg_base->ctrl);
+	tmp &= ~1;
+	writel_relaxed(tmp, &dd->reg_base->ctrl);
+}
+
+static inline void csky_tdes_set_endian(struct csky_tdes_dev *dd,
+					uint32_t endian)
+{
+	uint32_t tmp;
+
+	tmp  = readl_relaxed(&dd->reg_base->ctrl);
+	if (endian == TDES_ENDIAN_LT)
+		tmp &= ~TDES_ENDIAN;
+	else
+		tmp |= TDES_ENDIAN;
+	writel_relaxed(tmp, &dd->reg_base->ctrl);
+}
+
+static inline void csky_tdes_init(struct csky_tdes_dev *dd)
+{
+#ifndef USING_BIG_ENDIAN
+	csky_tdes_set_endian(dd, TDES_ENDIAN_LT);
+#endif
+	if (!(dd->flags & TDES_FLAGS_INIT))
+		dd->flags |= TDES_FLAGS_INIT;
+}
+
+static inline int csky_tdes_check_int_status(struct csky_tdes_dev *dd,
+					     uint32_t flag)
+{
+	return (readl_relaxed(&dd->reg_base->state) & flag) ? 1 : 0;
+}
+
+static inline size_t csky_tdes_padlen(size_t len, size_t block_size)
+{
+	len &= block_size - 1;
+	return len ? block_size - len : 0;
+}
+
+static inline void csky_tdes_in_block(struct csky_tdes_dev *dd,
+				      uint32_t *data)
+{
+	int i;
+
+	for (i = 0; i < SIZE_IN_WORDS(DES_BLOCK_SIZE); i ++) {
+		writel_relaxed(
+			HTOL(data[i]),
+			&dd->reg_base->datain[SIZE_IN_WORDS(DES_BLOCK_SIZE)
+					      - 1 - i]);
+	}
+}
+
+static inline void csky_tdes_out_block(struct csky_tdes_dev *dd,
+				       uint32_t *data)
+{
+	int i;
+
+	for (i = 0; i < SIZE_IN_WORDS(DES_BLOCK_SIZE); i ++) {
+		data[i] = HTOL(readl_relaxed(
+			&dd->reg_base->dataout[SIZE_IN_WORDS(DES_BLOCK_SIZE)
+						- 1 - i]));
+	}
+}
+
+static inline int csky_tdes_complete(struct csky_tdes_dev *dd, int err)
+{
+	dd->flags &= ~TDES_FLAGS_BUSY;
+	dd->areq->complete(dd->areq, err);
+
+	tasklet_schedule(&dd->done_task);
+
+	return err;
+}
+
+static int csky_tdes_engine_op(struct csky_tdes_dev *dd)
+{
+	int i;
+	int err = 0;
+	int len;
+
+	for (i = 0; i < dd->datalen; i += DES_BLOCK_SIZE) {
+		csky_tdes_in_block(dd, dd->data);
+
+		csky_tdes_enable(dd);
+		csky_tdes_check_int_status(dd, TDES_IT_BUSY);
+		csky_tdes_disable(dd);
+
+		csky_tdes_out_block(dd, dd->data);
+		dd->data += SIZE_IN_WORDS(DES_BLOCK_SIZE);
+	}
+
+	if (dd->flags & TDES_FLAGS_ENC)
+		len = dd->datalen;
+	else if (dd->flags & TDES_FLAGS_DEC)
+		len = dd->total;
+	else
+		return csky_tdes_complete(dd, -EINVAL);
+
+	if (!sg_copy_from_buffer(dd->real_dst, sg_nents(dd->real_dst),
+				 dd->buf, len))
+		err = -EINVAL;
+
+	return csky_tdes_complete(dd, err);
+}
+
+static int csky_tdes_start(struct csky_tdes_dev *dd,
+			   struct scatterlist *src,
+			   struct scatterlist *dst,
+			   size_t len)
+{
+	size_t padlen = csky_tdes_padlen(len, DES_BLOCK_SIZE);
+
+	if (!(dd->flags & TDES_FLAGS_INIT)) {
+		return -EACCES;
+	}
+
+	if (unlikely(len == 0))
+		return -EINVAL;
+
+	sg_copy_to_buffer(src, sg_nents(src), dd->buf, len);
+
+	dd->real_dst = dst;
+	dd->total    = len;
+	dd->datalen  = len + padlen;
+	dd->data     = (u32 *)dd->buf;
+
+	return 0;
+}
+
+static int csky_tdes_set_key(struct csky_tdes_dev *dd, const uint32_t *iv)
+{
+	int i;
+	uint32_t *key = dd->ctx->key;
+
+	for (i = 0; i < SIZE_IN_WORDS(dd->ctx->keylen); i++) {
+		if (i < 2)
+			writel_relaxed(HTOL(key[i]), &dd->reg_base->key[1-i%2]);
+		else if (i < 4)
+			writel_relaxed(HTOL(key[i]), &dd->reg_base->key[3-i%2]);
+		else
+			writel_relaxed(HTOL(key[i]), &dd->reg_base->key[5-i%2]);
+	}
+
+	if (dd->flags & TDES_FLAGS_CBC) {
+		for (i = 0; i < SIZE_IN_WORDS(DES_BLOCK_SIZE); i++) {
+			writel_relaxed(HTOL(
+				iv[i]),
+				&dd->reg_base->iv[SIZE_IN_WORDS(DES_BLOCK_SIZE)
+						  -1-i]);
+		}
+	}
+
+	csky_tdes_setopcode(dd);
+
+	return 0;
+}
+
+static int csky_tdes_handle(struct csky_tdes_dev *dd)
+{
+	struct ablkcipher_request *req  = ablkcipher_request_cast(dd->areq);
+	struct csky_tdes_reqctx   *rctx = ablkcipher_request_ctx(req);
+	int ret;
+
+	dd->flags &= ~(TDES_FLAGS_ECB | TDES_FLAGS_CBC | \
+				   TDES_FLAGS_ENC | TDES_FLAGS_DEC);
+	dd->flags |= rctx->mode;
+
+	csky_tdes_init(dd);
+	ret = csky_tdes_start(dd, req->src, req->dst, req->nbytes);
+	if (ret)
+		return ret;
+
+	ret = csky_tdes_set_key(dd, req->info);
+	if (ret)
+		return ret;
+
+	ret = csky_tdes_engine_op(dd);
+	return ret;
+}
+
+static int csky_tdes_handle_queue(struct csky_tdes_dev *dd,
+				  struct crypto_async_request *new_areq)
+{
+	struct crypto_async_request *areq, *backlog;
+	struct csky_tdes_base_ctx	*ctx;
+	unsigned long flags;
+	int ret = 0;
+
+	spin_lock_irqsave(&dd->lock, flags);
+	if (new_areq)
+		ret = crypto_enqueue_request(&dd->queue, new_areq);
+	if (dd->flags & TDES_FLAGS_BUSY) {
+		spin_unlock_irqrestore(&dd->lock, flags);
+		return ret;
+	}
+	backlog = crypto_get_backlog(&dd->queue);
+	areq = crypto_dequeue_request(&dd->queue);
+	if (areq)
+		dd->flags |= TDES_FLAGS_BUSY;
+	spin_unlock_irqrestore(&dd->lock, flags);
+
+	if (!areq)
+		return ret;
+
+	if (backlog)
+		backlog->complete(backlog, -EINPROGRESS);
+
+	ctx	 = crypto_tfm_ctx(areq->tfm);
+	dd->areq = areq;
+	dd->ctx  = ctx;
+
+	return csky_tdes_handle(dd);
+}
+
+static int csky_tdes_crypt(struct ablkcipher_request *req, unsigned long mode)
+{
+	struct csky_tdes_base_ctx *ctx;
+	struct csky_tdes_reqctx   *rctx;
+	struct csky_tdes_dev	  *dd;
+
+	ctx = crypto_ablkcipher_ctx(crypto_ablkcipher_reqtfm(req));
+	if (!ctx)
+		return -ENOMEM;
+
+	dd  = csky_tdes_find_dev(ctx);
+	if (!dd)
+		return -ENODEV;
+
+	rctx	   = ablkcipher_request_ctx(req);
+	rctx->mode = mode;
+
+	if ((mode & TDES_FLAGS_ECB) || (mode & TDES_FLAGS_CBC))
+		ctx->block_size = DES_BLOCK_SIZE;
+
+	return csky_tdes_handle_queue(dd, &req->base);
+}
+
+static int csky_tdes_setkey(struct crypto_ablkcipher *tfm, const u8 *key,
+			    unsigned int keylen)
+{
+	struct csky_tdes_base_ctx *ctx = crypto_ablkcipher_ctx(tfm);
+
+	if ((keylen != 2*DES_KEY_SIZE) && (keylen != 3*DES_KEY_SIZE)) {
+		crypto_ablkcipher_set_flags(tfm, CRYPTO_TFM_RES_BAD_KEY_LEN);
+		return -EINVAL;
+	}
+	memcpy(ctx->key, key, keylen);
+	ctx->keylen = keylen;
+
+	return 0;
+}
+
+static int csky_tdes_ecb_encrypt(struct ablkcipher_request *req)
+{
+	return csky_tdes_crypt(req, TDES_FLAGS_ECB | TDES_FLAGS_ENC);
+}
+
+static int csky_tdes_ecb_decrypt(struct ablkcipher_request *req)
+{
+	return csky_tdes_crypt(req, TDES_FLAGS_ECB | TDES_FLAGS_DEC);
+}
+
+static int csky_tdes_cbc_encrypt(struct ablkcipher_request *req)
+{
+	return csky_tdes_crypt(req, TDES_FLAGS_CBC | TDES_FLAGS_ENC);
+}
+
+static int csky_tdes_cbc_decrypt(struct ablkcipher_request *req)
+{
+	return csky_tdes_crypt(req, TDES_FLAGS_CBC | TDES_FLAGS_DEC);
+}
+
+static int csky_tdes_cra_init(struct crypto_tfm *tfm)
+{
+	tfm->crt_ablkcipher.reqsize = sizeof(struct csky_tdes_reqctx);
+
+	return 0;
+}
+
+static void csky_tdes_cra_exit(struct crypto_tfm *tfm)
+{
+
+}
+
+static struct crypto_alg tdes_algs[] = {
+	{
+		.cra_name	= "ecb(des3_ede)",
+		.cra_driver_name= "csky-ecb-tdes",
+		.cra_priority	= 200,
+		.cra_flags	= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,
+		.cra_blocksize	= DES_BLOCK_SIZE,
+		.cra_ctxsize	= sizeof(struct csky_tdes_ctx),
+		.cra_alignmask	= 0xf,
+		.cra_type	= &crypto_ablkcipher_type,
+		.cra_module	= THIS_MODULE,
+		.cra_init	= csky_tdes_cra_init,
+		.cra_exit	= csky_tdes_cra_exit,
+		.cra_u.ablkcipher = {
+			.min_keysize	= 2 * DES_KEY_SIZE,
+			.max_keysize	= 3 * DES_KEY_SIZE,
+			.setkey		= csky_tdes_setkey,
+			.encrypt	= csky_tdes_ecb_encrypt,
+			.decrypt	= csky_tdes_ecb_decrypt,
+		}
+	},
+	{
+		.cra_name	= "cbc(des3_ede)",
+		.cra_driver_name= "csky-cbc-tdes",
+		.cra_priority	= 200,
+		.cra_flags	= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,
+		.cra_blocksize  = DES_BLOCK_SIZE,
+		.cra_ctxsize	= sizeof(struct csky_tdes_ctx),
+		.cra_alignmask  = 0xf,
+		.cra_type	= &crypto_ablkcipher_type,
+		.cra_module	= THIS_MODULE,
+		.cra_init	= csky_tdes_cra_init,
+		.cra_exit	= csky_tdes_cra_exit,
+		.cra_u.ablkcipher = {
+			.min_keysize	= 2 * DES_KEY_SIZE,
+			.max_keysize	= 3 * DES_KEY_SIZE,
+			.ivsize		= DES_BLOCK_SIZE,
+			.setkey		= csky_tdes_setkey,
+			.encrypt	= csky_tdes_cbc_encrypt,
+			.decrypt	= csky_tdes_cbc_decrypt,
+		}
+	},
+};
+
+static int csky_tdes_buff_init(struct csky_tdes_dev *dd)
+{
+	dd->buf = (void *)__get_free_pages(GFP_KERNEL, CSKY_TDES_BUFFER_ORDER);
+	dd->buflen = CSKY_TDES_BUFFER_SIZE;
+	dd->buflen &= ~(DES_BLOCK_SIZE - 1);
+
+	if (!dd->buf) {
+		dev_err(dd->dev, "unable to alloc pages.\n");
+		return -ENOMEM;
+	}
+
+	return 0;
+}
+
+static void csky_tdes_buff_cleanup(struct csky_tdes_dev *dd)
+{
+	if ((unsigned long)dd->buf)
+		free_pages((unsigned long)dd->buf, CSKY_TDES_BUFFER_ORDER);
+}
+
+static void csky_tdes_done_task(unsigned long data)
+{
+	struct csky_tdes_dev *dd = (struct csky_tdes_dev *)data;
+
+	csky_tdes_handle_queue(dd, NULL);
+}
+
+static void csky_tdes_unregister_algs(struct csky_tdes_dev *dd)
+{
+	int i;
+
+	for (i = 0; i < ARRAY_SIZE(tdes_algs); i++)
+		crypto_unregister_alg(&tdes_algs[i]);
+}
+
+static int csky_tdes_register_algs(struct csky_tdes_dev *dd)
+{
+	int err, i, j;
+
+	for (i = 0; i < ARRAY_SIZE(tdes_algs); i++) {
+		err = crypto_register_alg(&tdes_algs[i]);
+		if (err) {
+			for (j = 0; j < i; j++)
+				crypto_unregister_alg(&tdes_algs[j]);
+			return err;
+		}
+	}
+
+	return 0;
+}
+
+static int csky_tdes_probe(struct platform_device *pdev)
+{
+	struct csky_tdes_dev *tdes_dd;
+	struct device	   *dev = &pdev->dev;
+	struct resource	 *tdes_res;
+	int err;
+
+	tdes_dd = devm_kzalloc(&pdev->dev, sizeof(*tdes_dd), GFP_KERNEL);
+	if (tdes_dd == NULL) {
+		dev_err(dev, "unable to alloc data struct.\n");
+		err = -ENOMEM;
+		goto tdes_dd_err;
+	}
+
+	tdes_dd->dev = dev;
+
+	platform_set_drvdata(pdev, tdes_dd);
+
+	INIT_LIST_HEAD(&tdes_dd->list);
+	spin_lock_init(&tdes_dd->lock);
+
+	tasklet_init(&tdes_dd->done_task, csky_tdes_done_task,
+		     (unsigned long)tdes_dd);
+
+	crypto_init_queue(&tdes_dd->queue, CSKY_TDES_QUEUE_LENGTH);
+
+	tdes_res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	if (!tdes_res) {
+		err = -ENODEV;
+		goto res_err;
+	}
+
+	tdes_dd->reg_base = devm_ioremap_resource(dev, tdes_res);
+	if (IS_ERR(tdes_dd->reg_base)) {
+		err = PTR_ERR(tdes_dd->reg_base);
+		goto res_err;
+	}
+
+	err = csky_tdes_buff_init(tdes_dd);
+	if (err)
+		goto res_err;
+
+	spin_lock(&csky_tdes.lock);
+	list_add_tail(&tdes_dd->list, &csky_tdes.dev_list);
+	spin_unlock(&csky_tdes.lock);
+
+	err = csky_tdes_register_algs(tdes_dd);
+	if (err)
+		goto err_algs;
+
+	dev_info(dev, "CSKY TDES Driver Initialized\n");
+
+	return 0;
+
+err_algs:
+	spin_lock(&csky_tdes.lock);
+	list_del(&tdes_dd->list);
+	spin_unlock(&csky_tdes.lock);
+res_err:
+	tasklet_kill(&tdes_dd->done_task);
+tdes_dd_err:
+
+	return err;
+}
+
+static int csky_tdes_remove(struct platform_device *pdev)
+{
+	static struct csky_tdes_dev *tdes_dd;
+
+	tdes_dd = platform_get_drvdata(pdev);
+	if (!tdes_dd)
+		return -ENODEV;
+
+	spin_lock(&csky_tdes.lock);
+	list_del(&tdes_dd->list);
+	spin_unlock(&csky_tdes.lock);
+
+	csky_tdes_buff_cleanup(tdes_dd);
+
+	tasklet_kill(&tdes_dd->done_task);
+	csky_tdes_unregister_algs(tdes_dd);
+
+	return 0;
+}
+
+static const struct of_device_id csky_tdes_dt_ids[] = {
+	{ .compatible = "csky,tdes-v1" },
+	{ /* sentinel */ }
+};
+MODULE_DEVICE_TABLE(of, csky_tdes_dt_ids);
+
+static struct platform_driver csky_tdes_driver = {
+	.probe	= csky_tdes_probe,
+	.remove	= csky_tdes_remove,
+	.driver	= {
+		.name = "csky_tdes",
+		.of_match_table = of_match_ptr(csky_tdes_dt_ids),
+	},
+};
+
+module_platform_driver(csky_tdes_driver);
+
+MODULE_DESCRIPTION("CSKY TDES hw acceleration support.");
+MODULE_LICENSE("GPL v2");
+MODULE_AUTHOR("Vincent Cui <xiaoxia_cui@c-sky.com>");
diff --git a/addons/drivers/crypto/csky_tdes.h b/addons/drivers/crypto/csky_tdes.h
new file mode 100644
index 0000000..06afdaf
--- /dev/null
+++ b/addons/drivers/crypto/csky_tdes.h
@@ -0,0 +1,50 @@
+/*
+ * Copyright (C) 2017 C-SKY MicroSystems Co.,Ltd.
+ * Author: Vincent Cui <xiaoxia_cui@c-sky.com>
+ *
+ * This software is licensed under the terms of the GNU General Public
+ * License version 2, as published by the Free Software Foundation, and
+ * may be copied, distributed, and modified under those terms.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ */
+
+#ifndef __CSKY_TDES_H
+#define __CSKY_TDES_H
+
+
+#define TDES_ENDIAN	0x00000008
+#define TDES_ENDIAN_LT	0
+#define TDES_ENDIAN_BG	1
+
+#define TDES_IT_DATAINT	0x4
+#define TDES_IT_PAERR	0x2
+#define TDES_IT_BUSY	0x1
+#define TDES_IT_ALL	0x7
+
+#define TDES_OPC_ENC	0x0000
+#define TDES_OPC_DEC	0x0002
+
+#define TDES_MOD_ECB	0x0000
+#define TDES_MOD_CBC	0x0010
+
+#define TDES_OPR_DES3	0x0040
+
+#define TDES_KL_128	0
+#define TDES_KL_192	1
+#define TDES_KL_256	2
+
+struct tdes_reg {
+	uint32_t datain[2];	/* Data input 0~15 */
+	uint32_t key[6];	/* Key 0~191 */
+	uint32_t iv[2];		/* Initial Vector: 0~31 */
+	uint32_t ctrl;		/* DES Control Register */
+	uint32_t state;		/* DES State Register */
+	uint32_t dataout[2];	/* Data Output 0~15 */
+};
+
+#endif /* __CSKY_TDES_H */
diff --git a/addons/drivers/gpu/drm/csky/Kconfig b/addons/drivers/gpu/drm/csky/Kconfig
new file mode 100644
index 0000000..d009e84
--- /dev/null
+++ b/addons/drivers/gpu/drm/csky/Kconfig
@@ -0,0 +1,11 @@
+#
+# C-SKY DRM  driver configuration
+#
+
+config CSKY_HDMI
+	bool "C-SKY HDMI Driver"
+	depends on OF
+	select HDMI
+	help
+	  This enables the HDMI driver for C-SKY.
+
diff --git a/addons/drivers/gpu/drm/csky/Makefile b/addons/drivers/gpu/drm/csky/Makefile
new file mode 100644
index 0000000..8fb0eee
--- /dev/null
+++ b/addons/drivers/gpu/drm/csky/Makefile
@@ -0,0 +1,6 @@
+#
+# This enables the HDMI driver for C-SKY.
+# Makefile for the drm device driver.  This driver provides support for the
+# Direct Rendering Infrastructure (DRI) in XFree86 4.1.0 and higher.
+
+obj-$(CONFIG_CSKY_HDMI) += csky_hdmi.o
\ No newline at end of file
diff --git a/addons/drivers/gpu/drm/csky/csky_hdmi.c b/addons/drivers/gpu/drm/csky/csky_hdmi.c
new file mode 100644
index 0000000..045b794
--- /dev/null
+++ b/addons/drivers/gpu/drm/csky/csky_hdmi.c
@@ -0,0 +1,740 @@
+/*
+ * HDMI driver for C-SKY's SoCs.
+ *
+ * Copyright (C) 2017 C-SKY MicroSystems Co.,Ltd.
+ * Author: Huoqing Cai <huoqing_cai@c-sky.com>
+ *
+ * This software is licensed under the terms of the GNU General Public
+ * License version 2, as published by the Free Software Foundation, and
+ * may be copied, distributed, and modified under those terms.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ */
+
+#include <linux/clk.h>
+#include <linux/interrupt.h>
+#include <linux/delay.h>
+#include <linux/err.h>
+#include <linux/io.h>
+#include <linux/hdmi.h>
+#include <linux/module.h>
+#include <linux/of_device.h>
+#include <linux/workqueue.h>
+#include <linux/spinlock.h>
+#include <video/of_videomode.h>
+#include <video/videomode.h>
+#include <linux/i2c.h>
+#include <sound/soc.h>
+
+#include "csky_hdmi.h"
+
+struct hdmi_data_info {
+	unsigned int vid;
+	unsigned int deep_color;
+	unsigned int out_format;
+	unsigned int dvi_mode;
+	unsigned int hdcp_mode;
+};
+
+struct cksy_edid_info {
+	unsigned int edid_current;
+	unsigned int edid_retry;
+	unsigned int edid_size;
+	unsigned int ex_flag;
+	unsigned int edid_done;
+	unsigned char edid_data[HDMI_EDID_BLK_SIZE * 2];
+};
+
+struct csky_hdmi {
+	struct device *dev;
+
+	int irq;
+	spinlock_t edid_lock;
+	void __iomem *regs;
+
+	struct videomode vm;
+	struct i2c_adapter *i2c_adap;
+	struct hdmi_data_info	hdmi_data;
+	struct cksy_edid_info	edid_info;
+	struct workqueue_struct *edid_workq;
+	struct work_struct edid_work;
+};
+
+static struct csky_hdmi *hdmi_p;
+
+static const char phy_dat[][PHY_DATA_SIZE] = {
+	/* PHY setting for TMDS clock 27 (480i, 480p) */
+	{
+		0x11, 0x00, 0x00, 0x44, 0x32,
+		0x4b, 0x0e, 0x70, 0x00, 0x22,
+	},
+	/* PHY setting for TMDS clock 33.75 (480i, 480p 10 bit) */
+	{
+		0x15, 0x00, 0x00, 0x48, 0x32,
+		0x46, 0x0e, 0x70, 0x00, 0x62,
+	},
+	/* PHY setting for TMDS clock 40 (480i, 480p 12 bit) */
+	{
+		0x15, 0x00, 0x00, 0x48, 0x32,
+		0x48, 0x0e, 0x70, 0x00, 0xa2,
+	},
+	/* PHY setting for TMDS clock 54 & 74.25 (720p, 1080i) */
+	{
+		0x19, 0x00, 0x00, 0x44, 0x32,
+		0x48, 0x0e, 0x70, 0x00, 0x22,
+	},
+	/* PHY setting for TMDS clock 98.8125 (720p, 1080i 10 bit) */
+	{
+		0x19, 0x00, 0x00, 0x44, 0x32,
+		0x48, 0x0e, 0x70, 0x00, 0x62,
+	},
+	/* PHY setting for TMDS clock 111.375 (720p, 1080i 12 bit) */
+	{
+		0x19, 0x00, 0x00, 0x44, 0x32,
+		0x4b, 0x0e, 0x70, 0x00, 0xa2,
+	},
+	/* PHY setting for TMDS clock 148.5 (1080p) */
+	{
+		0x1d, 0x00, 0x00, 0x4c, 0x1e,
+		0x47, 0x0e, 0x70, 0x00, 0x22,
+	},
+	/* PHY setting for TMDS clock 185.6 (1080p deep color 10 bit) */
+	{
+		0x1d, 0x00, 0x00, 0x4c, 0x1e,
+		0x48, 0x0e, 0x70, 0x00, 0x62,
+	},
+	/* PHY setting for TMDS clock 222.75 (1080p deep color 12 bit) */
+	{
+		0x1d, 0x00, 0x00, 0x4c, 0x1e,
+		0x48, 0x0e, 0x70, 0x00, 0xa2,
+	},
+};
+
+static u8 hdmi_readb(struct csky_hdmi *hdmi, u8 offset)
+{
+	return ioread32(hdmi->regs + (offset));
+}
+
+static void hdmi_writeb(struct csky_hdmi *hdmi, u8 offset, u8 val)
+{
+	iowrite32(val, hdmi->regs + (offset));
+}
+
+static int csky_hdmi_modeb_reset(struct csky_hdmi *hdmi)
+{
+	u8 stat;
+
+	stat = hdmi_readb(hdmi, X00_SYSTEM_CONTROL);
+	if (stat & PWR_MOD_A_X00) {
+		hdmi_writeb(hdmi, X00_SYSTEM_CONTROL, PWR_MODB_RST_X00);
+		hdmi_writeb(hdmi, X00_SYSTEM_CONTROL, PWR_MODB_RSTB_X00);
+	} else if (stat & PWR_MOD_E_X00) {
+		/* PS mode e -> d ->b ->a */
+		hdmi_writeb(hdmi, X00_SYSTEM_CONTROL, PWR_MOD_D_X00);
+		hdmi_writeb(hdmi, X00_SYSTEM_CONTROL, PWR_MOD_B_X00);
+		hdmi_writeb(hdmi, X00_SYSTEM_CONTROL, PWR_MOD_A_X00);
+		/* mode a -> mode b */
+		hdmi_writeb(hdmi, X00_SYSTEM_CONTROL, PWR_MODB_RST_X00);
+		hdmi_writeb(hdmi, X00_SYSTEM_CONTROL, PWR_MODB_RSTB_X00);
+	}
+
+	return 0;
+}
+
+static int csky_hdmi_edid_checksum(struct csky_hdmi *hdmi)
+{
+	int index;
+	int base = 0;
+	int sum = 0;
+	unsigned char *edid_dat;
+
+	edid_dat = hdmi->edid_info.edid_data;
+	if (hdmi->edid_info.ex_flag == 1)
+		base += HDMI_EDID_BLK_SIZE;
+	for (index = base; index < HDMI_EDID_BLK_SIZE; ++index) {
+		sum += *(edid_dat + index);
+	}
+
+	return sum & 0xff;
+}
+
+static int csky_hdmi_tx_start(struct csky_hdmi *hdmi)
+{
+	u8 vidset;
+	u8 int_mask;
+
+	/* enable hotplug interupt */
+	int_mask = HPG_MSK_X92 | MSENS_MSK_X92;
+	hdmi_writeb(hdmi, X92_INT_MASK1, int_mask);
+	/* enable video output */
+	hdmi_writeb(hdmi, X00_SYSTEM_CONTROL, PWR_MOD_E_X00);
+	vidset = hdmi_readb(hdmi, X45_VIDEO2) & ENVIDEO_X45;
+	hdmi_writeb(hdmi, X45_VIDEO2, vidset);
+
+	return 0;
+}
+
+static int csky_hdmi_edid_start(struct csky_hdmi *hdmi)
+{
+	u8 edid_word;
+	u8 int_mask;
+	unsigned int flag;
+
+	spin_lock_irq(&hdmi->edid_lock);
+	flag = hdmi->edid_info.ex_flag;
+	/* enable EDID interrupt */
+	int_mask = hdmi_readb(hdmi, X92_INT_MASK1);
+	hdmi_writeb(hdmi, X92_INT_MASK1, int_mask | EDID_MSK_X92);
+	/* set EDID word address */
+	edid_word = (flag ? EDID_ADDR_80_XC5 : EDID_ADDR_00_XC5);
+	hdmi_writeb(hdmi, XC5_EDID_WD_ADDR, edid_word);
+	/* set EDID segment pointer */
+	hdmi_writeb(hdmi, XC4_SEG_PTR, 0x00);
+	spin_unlock_irq(&hdmi->edid_lock);
+
+	return 0;
+}
+
+static int csky_hdmi_phy_setting(struct csky_hdmi *hdmi, int type)
+{
+	int index;
+	int size;
+
+	size = PHY_DATA_SIZE - 1;
+	hdmi_writeb(hdmi, X17_DC_REG, phy_dat[type][size]);
+	for (index = 0; index < size; ++index)
+		hdmi_writeb(hdmi, X56_PHY_CTRL + index, phy_dat[type][index]);
+
+	return 0;
+}
+
+static int csky_hdmi_phy_setup(struct csky_hdmi *hdmi)
+{
+	unsigned int vid;
+	unsigned int color;
+
+	color = hdmi->hdmi_data.deep_color;
+	vid = hdmi->hdmi_data.vid;
+	switch (vid & 0x7f) {
+	case VID_04_1280X720P:
+	case VID_19_1280X720P:
+	case VID_05_1920X1080I:
+	case VID_20_1920X1080I:
+	case VID_32_1920X1080P:
+	case VID_33_1920X1080P:
+	case VID_34_1920X1080P:
+	case VID_39_1920X1080I:
+		if (color == DEEP_COLOR_8BIT)
+			csky_hdmi_phy_setting(hdmi, PHY_TMDS_CLOCK_54);
+		else if (color == DEEP_COLOR_12BIT)
+			csky_hdmi_phy_setting(hdmi, PHY_TMDS_CLOCK_98);
+		else
+			csky_hdmi_phy_setting(hdmi, PHY_TMDS_CLOCK_111);
+		break;
+	case VID_16_1920X1080P:
+	case VID_31_1920X1080P:
+	case VID_40_1920X1080I:
+		if (color == DEEP_COLOR_8BIT)
+			csky_hdmi_phy_setting(hdmi, PHY_TMDS_CLOCK_148);
+		else if (color == DEEP_COLOR_12BIT)
+			csky_hdmi_phy_setting(hdmi, PHY_TMDS_CLOCK_185);
+		else
+			csky_hdmi_phy_setting(hdmi, PHY_TMDS_CLOCK_222);
+		break;
+	default:
+		if (color == DEEP_COLOR_8BIT)
+			csky_hdmi_phy_setting(hdmi, PHY_TMDS_CLOCK_27);
+		else if (color == DEEP_COLOR_12BIT)
+			csky_hdmi_phy_setting(hdmi, PHY_TMDS_CLOCK_33);
+		else
+			csky_hdmi_phy_setting(hdmi, PHY_TMDS_CLOCK_40);
+		break;
+	}
+
+
+	return 0;
+}
+
+static int csky_hdmi_video_set_output(struct csky_hdmi *hdmi)
+{
+	u8 vid_tmp;
+	u8 dc_tmp;
+	u8 pb_tmp;
+	unsigned int out_fmt;
+	unsigned int color_depth;
+
+	/* set color mode */
+	out_fmt = hdmi->hdmi_data.out_format;
+	vid_tmp = hdmi_readb(hdmi, X16_VIDEO1);
+	pb_tmp = hdmi_readb(hdmi, X64_PKT_PB1);
+	switch (out_fmt) {
+	case HDMI_COLORSPACE_RGB:
+		vid_tmp = vid_tmp & VID_MASK_X16;
+		hdmi_writeb(hdmi, X16_VIDEO1, vid_tmp | VID_RGB_X16);
+		hdmi_writeb(hdmi, X64_PKT_PB1, pb_tmp & PB1_MASK_X64);
+		break;
+	case HDMI_COLORSPACE_YUV444:
+		vid_tmp = vid_tmp & VID_MASK_X16;
+		hdmi_writeb(hdmi, X16_VIDEO1, vid_tmp | VID_YCC444_X16);
+		pb_tmp = pb_tmp & PB1_MASK_X64;
+		hdmi_writeb(hdmi, X64_PKT_PB1, pb_tmp | PB1_YCC444_X64);
+		break;
+	default:
+		/* default to YCC 422 */
+		vid_tmp = vid_tmp & VID_MASK_X16;
+		hdmi_writeb(hdmi, X16_VIDEO1, vid_tmp | VID_YCC422_X16);
+		pb_tmp = pb_tmp & PB1_MASK_X64;
+		hdmi_writeb(hdmi, X64_PKT_PB1, pb_tmp | PB1_YCC422_X64);
+		break;
+	}
+
+	/* set color depth */
+	color_depth = hdmi->hdmi_data.deep_color;
+	vid_tmp = hdmi_readb(hdmi, X16_VIDEO1);
+	dc_tmp = hdmi_readb(hdmi, X17_DC_REG);
+	switch (color_depth) {
+	case DEEP_COLOR_10BIT:
+		dc_tmp = (dc_tmp & SPEED_MASK_X17) | SPEED_12BIT_X17;
+		vid_tmp = (vid_tmp & DAT_WIDTH_MASK_X16) | WIDTH_10BITS_X16;
+		break;
+	case DEEP_COLOR_12BIT:
+		dc_tmp = (dc_tmp & SPEED_MASK_X17) | SPEED_10BIT_X17;
+		vid_tmp = (vid_tmp & DAT_WIDTH_MASK_X16) | WIDTH_12BITS_X16;
+		break;
+	default:
+		/* default: set to 8 bit */
+		dc_tmp = (dc_tmp & SPEED_MASK_X17) | SPEED_8BIT_X17;
+		vid_tmp = (vid_tmp & DAT_WIDTH_MASK_X16) | WIDTH_8BITS_X16;
+		break;
+	}
+
+	hdmi_writeb(hdmi, X17_DC_REG, dc_tmp);
+	hdmi_writeb(hdmi, X16_VIDEO1, vid_tmp);
+
+	return 0;
+}
+
+static int csky_hdmi_video_set_format(struct csky_hdmi *hdmi)
+{
+	u8 val;
+
+	/* set HDCP control mode */
+	if (hdmi->hdmi_data.dvi_mode == 1) {
+		/* set RGB and DVI */
+		hdmi->hdmi_data.out_format = HDMI_COLORSPACE_RGB;
+		val = hdmi_readb(hdmi, XAF_HDCP_CTRL) & (~HDMI_MODE_CTRL_XAF);
+	}
+	else
+		val = hdmi_readb(hdmi, XAF_HDCP_CTRL) | HDMI_MODE_CTRL_XAF;
+
+	if (hdmi->hdmi_data.hdcp_mode == 1)
+		val |= FRAME_ENC_XAF;
+	else
+		val &= (~FRAME_ENC_XAF);
+
+	hdmi_writeb(hdmi,XAF_HDCP_CTRL, val);
+
+	/* set AUDIO_INFO_FRAME */
+	hdmi_writeb(hdmi,X42_AUTO_CHECKSUM,
+		    hdmi_readb(hdmi, X42_AUTO_CHECKSUM) & AUTO_CHECKSUM_X42);
+	hdmi_writeb(hdmi,X5F_PACKET_INDEX, AUDIO_INFO_PKT_X5F);
+	hdmi_writeb(hdmi,X60_PKT_HB0, HB0_AUD_TYPE_X60);
+	hdmi_writeb(hdmi,X61_PKT_HB1, HB1_AUD_VERSION_X61);
+	hdmi_writeb(hdmi,X62_PKT_HB2, HB2_AUD_LENTH_X62);
+	hdmi_writeb(hdmi,X63_PKT_PB0, PB0_AUD_CHECKSUM_X63);
+	hdmi_writeb(hdmi,X64_PKT_PB1, PB1_AUD_2CH_X64);
+
+	/* set AVI InfoFrame */
+	hdmi_writeb(hdmi, X5F_PACKET_INDEX, AVI_INFO_PKT_X5F);
+	hdmi_writeb(hdmi, X60_PKT_HB0, HB0_AVI_TYPE_X60);
+	hdmi_writeb(hdmi, X61_PKT_HB1, HB1_VERSION_X61);
+	hdmi_writeb(hdmi, X62_PKT_HB2, HB2_LENTH_X62);
+	hdmi_writeb(hdmi, X67_PKT_PB4, hdmi->hdmi_data.vid & 0x7f);
+	hdmi_writeb(hdmi, X63_PKT_PB0,
+		    PB0_AVI_CHECKSUM_X63 - hdmi_readb(hdmi, X67_PKT_PB4));
+
+	return 0;
+}
+
+/* i.e. non-preprogrammed VID used. */
+static int csky_hdmi_set_external_timing(struct csky_hdmi *hdmi)
+{
+	int val;
+	struct videomode *vm;
+
+	vm = &hdmi->vm;
+	/* Set detail external video timing polarity and interlace mode */
+	val = BIT(0);
+	val |= vm->flags & DISPLAY_FLAGS_HSYNC_HIGH ?
+		 HSYNC_POLARITY_X30 : 0x0;
+	val |= vm->flags & DISPLAY_FLAGS_VSYNC_HIGH ?
+		 VSYNC_POLARITY_X30 : 0x0;
+	val |= vm->flags & DISPLAY_FLAGS_INTERLACED ?
+		 INETLACE_X30 : 0x0;
+	hdmi_writeb(hdmi, X30_EXT_VPARAMS, val);
+
+	/* Set detail external video timing */
+	val = vm->hactive + vm->hfront_porch + vm->hsync_len + vm->hback_porch;
+	hdmi_writeb(hdmi, X31_EXT_HTOTAL, val & 0xff);
+	hdmi_writeb(hdmi, X32_EXT_HTOTAL, (val >> 8) & 0xff);
+
+	val = vm->hfront_porch + vm->hsync_len + vm->hback_porch;
+	hdmi_writeb(hdmi, X33_EXT_HBLANK, val & 0xff);
+	hdmi_writeb(hdmi, X34_EXT_HBLANK, (val >> 8) & 0xff);
+
+	val = vm->hback_porch + vm->hsync_len;
+	hdmi_writeb(hdmi, X35_EXT_HDLY, val & 0xff);
+	hdmi_writeb(hdmi, X36_EXT_HDLY, (val >> 8) & 0xff);
+
+	val = vm->hsync_len;
+	hdmi_writeb(hdmi, X37_EXT_HS_DUR, val & 0xff);
+	hdmi_writeb(hdmi, X38_EXT_HS_DUR, (val >> 8) & 0xff);
+
+	val = vm->vactive + vm->vfront_porch + vm->vsync_len + vm->vback_porch;
+	hdmi_writeb(hdmi, X39_EXT_VTOTAL, val & 0xff);
+	hdmi_writeb(hdmi, X3A_EXT_VTOTAL, (val >> 8) & 0xff);
+
+	val = vm->vfront_porch + vm->vsync_len + vm->vback_porch;
+	hdmi_writeb(hdmi, X3D_EXT_VBLANK, val & 0xff);
+
+	val = vm->vback_porch + vm->vsync_len;
+	hdmi_writeb(hdmi, X3E_EXT_VDLY, val & 0xff);
+
+	val = vm->vsync_len;
+	hdmi_writeb(hdmi, X3F_EXT_VS_DUR, val & 0xff);
+
+	return 0;
+}
+
+static int csky_hdmi_apply_setting(struct csky_hdmi *hdmi)
+{
+	csky_hdmi_video_set_format(hdmi);
+	/*
+	 * The pre-programed timing 720p vid4 is not
+	 * standard for CEA-861-D. so set external
+	 * timing again.
+	*/
+	csky_hdmi_set_external_timing(hdmi);
+
+	csky_hdmi_video_set_output(hdmi);
+	csky_hdmi_phy_setup(hdmi);
+
+	return 0;
+}
+
+/* read one block EDID fifo for 128 byte */
+static int csky_hdmi_edid_read_block(struct csky_hdmi *hdmi)
+{
+	int chk_sum;
+	unsigned char *edid_dat;
+	unsigned int edid_cur;
+
+	edid_dat = hdmi->edid_info.edid_data;
+	edid_cur = hdmi->edid_info.edid_current;
+	if (hdmi->edid_info.ex_flag == 0) {
+		/* read first block */
+		*(edid_dat) = 0x00;
+		ioread8_rep(hdmi->regs + X80_EDID_FIFO,
+			    edid_dat + 1, HDMI_EDID_BLK_SIZE - 1);
+		hdmi->edid_info.ex_flag = *(edid_dat + HDMI_EDID_BLK_SIZE -2);
+	} else {
+		/* read extension block */
+		*(edid_dat + HDMI_EDID_BLK_SIZE) = 0x02;
+		ioread8_rep(hdmi->regs + X80_EDID_FIFO,
+			    edid_dat + HDMI_EDID_BLK_SIZE + 1,
+			    HDMI_EDID_BLK_SIZE - 1);
+		hdmi->edid_info.ex_flag = 0;
+	}
+
+	chk_sum = csky_hdmi_edid_checksum(hdmi);
+
+	return chk_sum;
+}
+
+static irqreturn_t csky_hdmi_edid_irq(struct csky_hdmi *hdmi, u8 int_stat)
+{
+	irqreturn_t ret = IRQ_HANDLED;
+
+	if (int_stat & EDID_ERR_INT_X94) {
+		hdmi->edid_info.edid_retry --;
+		if (hdmi->edid_info.edid_retry == 0)
+			dev_err(hdmi->dev, "Cannot read EDID data\n");
+		else
+			csky_hdmi_edid_start(hdmi);
+	}
+	else if (int_stat & EDID_RDY_INT_X94)
+		ret = IRQ_WAKE_THREAD;
+
+	return ret;
+}
+
+static int csky_hdmi_unplug_irq(struct csky_hdmi *hdmi)
+{
+	u8 vidset;
+
+	/* disable video output */
+	vidset = hdmi_readb(hdmi, X45_VIDEO2);
+	vidset |= (NOVIDEO_X45 | NOAUDIO_X45);
+	hdmi_writeb(hdmi, X45_VIDEO2, vidset);
+	/* enable hotplug int */
+	hdmi_writeb(hdmi, X92_INT_MASK1, HPG_MSK_X92 | MSENS_MSK_X92);
+	if (hdmi->edid_workq)
+		flush_workqueue(hdmi->edid_workq);
+
+	return 0;
+}
+
+static int csky_hdmi_hotplug_irq(struct csky_hdmi *hdmi)
+{
+	hdmi->edid_info.edid_retry = HDMI_EDID_RETRY_TIMES;
+	hdmi->edid_info.ex_flag = 0;
+	csky_hdmi_edid_start(hdmi);
+
+	return 0;
+}
+
+static irqreturn_t csky_hdmi_irq(int irq, void *dev_id)
+{
+	u8 int_stat;
+	irqreturn_t ret = IRQ_HANDLED;
+	struct csky_hdmi *hdmi = dev_id;
+
+	csky_hdmi_modeb_reset(hdmi);
+	/* clear all interrupt */
+	int_stat = hdmi_readb(hdmi, X94_INT_STATUS1);
+	hdmi_writeb(hdmi, X94_INT_STATUS1, INT_CLR_X94);
+	hdmi_writeb(hdmi, X95_INT_STATUS2, INT_CLR_X95);
+
+	if (int_stat & EDID_INT_X94)
+		ret = csky_hdmi_edid_irq(hdmi, int_stat);
+	else if (int_stat & HPG_MSENS_INT_X94) {
+		int_stat = hdmi_readb(hdmi, XDF_HPG_STATUS);
+		if (int_stat & HPG_MSENS_PRT_XDF)
+			csky_hdmi_hotplug_irq(hdmi);
+		else
+			csky_hdmi_unplug_irq(hdmi);
+	}
+	else
+		printk("debug other interupt\n");
+
+	return ret;
+}
+
+static void csky_hdmi_main_work(struct work_struct *work)
+{
+	int chk_sum;
+	unsigned int int_mask;
+	unsigned int flag;
+	struct csky_hdmi *hdmi;
+
+	hdmi = container_of(work, struct csky_hdmi, edid_work);
+	chk_sum = csky_hdmi_edid_read_block(hdmi);
+	if (chk_sum == 0)
+		dev_err(hdmi->dev, "EDID info is right\n");
+	flag = hdmi->edid_info.ex_flag;
+
+	if (flag == 0) {
+		/* disable EDID interrupt */
+		int_mask = hdmi_readb(hdmi, X92_INT_MASK1);
+		int_mask = int_mask & (~EDID_MSK_X92);
+		hdmi_writeb(hdmi, X92_INT_MASK1, int_mask);
+
+		csky_hdmi_apply_setting(hdmi);
+		csky_hdmi_tx_start(hdmi);
+	}
+	else
+		csky_hdmi_edid_start(hdmi);
+}
+
+static int csky_timing_data_init(struct csky_hdmi *hdmi)
+{
+	/* get timing from dts */
+	int ret;
+	struct device *dev = hdmi->dev;
+	struct videomode vm;
+	struct of_phandle_args args;
+
+	ret = of_parse_phandle_with_args(dev->of_node, "screen-timings",
+				   "#screen-timings-cells", 0, &args);
+	if (ret) {
+		dev_err(dev, "Failed to get timing from DT\n");
+		return ret;
+	}
+	ret = of_get_videomode(args.np, &vm, args.args[0]);
+	if (ret) {
+		dev_err(dev, "Failed to get videomode from DT\n");
+		return ret;
+	}
+
+	memcpy(&hdmi->vm, &vm, sizeof(vm));
+	hdmi->hdmi_data.vid = args.args[1];
+
+	return ret;
+}
+
+/* to config init format, hope the data comes from fb */
+static int csky_hdmi_data_init(struct csky_hdmi *hdmi)
+{
+	/* hdmi edid data set */
+	hdmi->edid_info.edid_current = 0;
+	hdmi->edid_info.ex_flag = 0;
+	hdmi->edid_info.edid_retry = HDMI_EDID_RETRY_TIMES;
+	/* video data set */
+	hdmi->hdmi_data.dvi_mode = 0;
+	hdmi->hdmi_data.hdcp_mode = 0;
+	hdmi->hdmi_data.deep_color = DEEP_COLOR_8BIT;
+	hdmi->hdmi_data.out_format = HDMI_COLORSPACE_RGB;
+
+	return 0;
+}
+
+static int csky_hdmi_init(struct csky_hdmi *hdmi)
+{
+	int ret;
+
+	csky_hdmi_data_init(hdmi);
+	ret = csky_timing_data_init(hdmi);
+	if (ret) {
+		dev_err(hdmi->dev, "Failed to get timing data\n");
+		return ret;
+	}
+	csky_hdmi_modeb_reset(hdmi);
+	INIT_WORK(&hdmi->edid_work, csky_hdmi_main_work);
+	hdmi->edid_workq= create_singlethread_workqueue("hdmi-csky");
+
+	return ret;
+}
+
+static irqreturn_t csky_hdmi_work_irq(int irq, void *dev_id)
+{
+	struct csky_hdmi *hdmi = dev_id;
+
+	/* Process EDID work: */
+	queue_work(hdmi->edid_workq, &hdmi->edid_work);
+
+	return IRQ_HANDLED;
+}
+
+static int csky_hdmi_probe(struct platform_device *pdev)
+{
+	int ret;
+	struct csky_hdmi *hdmi;
+	struct resource *iores;
+	struct device *dev = &pdev->dev;
+
+	hdmi = devm_kzalloc(dev, sizeof(struct csky_hdmi), GFP_KERNEL);
+	if (!hdmi)
+		return -ENOMEM;
+
+	hdmi->dev = dev;
+
+	iores = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	if (!iores)
+		return -ENXIO;
+
+	hdmi->regs = devm_ioremap_resource(dev, iores);
+	if (IS_ERR(hdmi->regs))
+		return PTR_ERR(hdmi->regs);
+
+	hdmi_p = hdmi;
+
+	hdmi->irq = platform_get_irq(pdev, 0);
+	if (hdmi->irq < 0)
+		return hdmi->irq;
+
+	dev_set_drvdata(dev, hdmi);
+	ret = csky_hdmi_init(hdmi);
+	if (ret)
+		return ERR_PTR(ret);
+
+	ret = devm_request_threaded_irq(dev, hdmi->irq, csky_hdmi_irq,
+					csky_hdmi_work_irq,
+					IRQF_SHARED, dev_name(dev),
+					hdmi);
+
+	return ret;
+}
+
+void csky_hdmi_audio_config(unsigned int sample_rate, unsigned int audio_fmt)
+{
+	unsigned int param_n;
+
+	hdmi_writeb(hdmi_p, X45_VIDEO2, AUDIORST_X45 | NOAUDIO_X45);
+	switch (sample_rate) {
+	case 44100:
+		param_n = HDMI_44100_PARAM_N;
+		hdmi_writeb(hdmi_p, X15_AVSET1, CUR_SMP_44100_X15);
+		hdmi_writeb(hdmi_p, X11_ASTATUS1, ORI_SMP_44100_X11);
+		hdmi_writeb(hdmi_p, X01_N19_16, (param_n >> 0) & HDMI_REG_MSK);
+		hdmi_writeb(hdmi_p, X02_N15_8, (param_n >> 8) & HDMI_REG_MSK);
+		hdmi_writeb(hdmi_p, X03_N7_03, (param_n >> 16) & HDMI_REG_MSK);
+		break;
+	case 48000:
+		param_n = HDMI_48000_PARAM_N;
+		hdmi_writeb(hdmi_p, X15_AVSET1, CUR_SMP_48000_X15);
+		hdmi_writeb(hdmi_p, X11_ASTATUS1, ORI_SMP_48000_X11);
+		hdmi_writeb(hdmi_p, X01_N19_16, (param_n >> 0) & HDMI_REG_MSK);
+		hdmi_writeb(hdmi_p, X02_N15_8, (param_n >> 8) & HDMI_REG_MSK);
+		hdmi_writeb(hdmi_p, X03_N7_03, (param_n >> 16) & HDMI_REG_MSK);
+		break;
+	default:
+		break;
+	}
+
+	switch (audio_fmt) {
+	case SND_SOC_DAIFMT_I2S:
+		hdmi_writeb(hdmi_p, X0C_I2S_MODE, I2S_MOD_X0C);
+		break;
+	case SND_SOC_DAIFMT_LEFT_J:
+		hdmi_writeb(hdmi_p, X0C_I2S_MODE, LEFT_J_MOD_X0C);
+		break;
+	case SND_SOC_DAIFMT_RIGHT_J:
+		hdmi_writeb(hdmi_p, X0C_I2S_MODE, RIGHT_J_MOD_X0C);
+		break;
+	default:
+		break;
+	}
+
+	hdmi_writeb(hdmi_p, X45_VIDEO2,
+		    hdmi_readb(hdmi_p, X45_VIDEO2)
+		    & (~(AUDIORST_X45 | NOAUDIO_X45)));
+}
+EXPORT_SYMBOL(csky_hdmi_audio_config);
+
+static int csky_hdmi_remove(struct platform_device *pdev)
+{
+	struct csky_hdmi *hdmi = dev_get_drvdata(&pdev->dev);
+
+	if (hdmi->edid_workq) {
+		flush_workqueue(hdmi->edid_workq);
+		destroy_workqueue(hdmi->edid_workq);
+	}
+
+	return 0;
+}
+
+static const struct of_device_id csky_hdmi_dt_ids[] = {
+	{ .compatible = "csky,hdmi-v1",
+	},
+	{},
+};
+MODULE_DEVICE_TABLE(of, csky_hdmi_dt_ids);
+
+static struct platform_driver csky_hdmi_driver = {
+	.probe  = csky_hdmi_probe,
+	.remove = csky_hdmi_remove,
+	.driver = {
+		.name = "hdmi-csky",
+		.of_match_table = csky_hdmi_dt_ids,
+	},
+};
+
+module_platform_driver(csky_hdmi_driver);
+
+MODULE_AUTHOR("Huoqing Cai <huoqing_cai@c-sky.com>");
+MODULE_DESCRIPTION("CSKY HDMI");
+MODULE_LICENSE("GPL v2");
diff --git a/addons/drivers/gpu/drm/csky/csky_hdmi.h b/addons/drivers/gpu/drm/csky/csky_hdmi.h
new file mode 100644
index 0000000..015f1ff
--- /dev/null
+++ b/addons/drivers/gpu/drm/csky/csky_hdmi.h
@@ -0,0 +1,432 @@
+/*
+ * HDMI driver for C-SKY's SoCs.
+ *
+ * Copyright (C) 2017 C-SKY MicroSystems Co.,Ltd.
+ * Author: Huoqing Cai <huoqing_cai@c-sky.com>
+ *
+ * This software is licensed under the terms of the GNU General Public
+ * License version 2, as published by the Free Software Foundation, and
+ * may be copied, distributed, and modified under those terms.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ */
+
+#ifndef __CSKY_HDMI_H__
+#define __CSKY_HDMI_H__
+
+/* HDMI control registers */
+#define X00_SYSTEM_CONTROL	0x00	/*Power save and interrupt control */
+#define X01_N19_16		0x01	/* 20-bit N used for cycle stamp */
+#define X02_N15_8		0x02
+#define X03_N7_03		0x03
+#define X04_SPDIF_FS4		0x04	/* SPDIF sampling frequency/CTS */
+#define X05_CTS_INT		0x05	/* CTS[15:8] internal */
+#define X06_CTS_INT		0x06	/* CTS[7:0] internal */
+#define X07_CTS_EXT		0x07	/* CTS[19:16] external */
+#define X08_CTS_EXT		0x08	/* CTS[15:8] external */
+#define X09_CTS_EXT		0x09	/* CTS[7:0] external */
+#define X0A_AUDIO_SOURCE	0x0a	/* Audio setting.1 */
+#define X0B_AUDIO_SET2		0x0b	/* Audio setting.2 */
+#define X0C_I2S_MODE		0x0c	/* I2S audio setting */
+#define X0D_DSD_MODE		0x0d	/* DSD audio setting */
+#define X0E_DEBUG_MONITOR1	0x0e	/* Reserved */
+#define X0F_DEBUG_MONITOR2	0x0f	/* Reserved */
+#define X10_I2S_PINMODE		0x10	/* I2S input pin swap */
+#define X11_ASTATUS1		0x11	/* Audio status bits setting1 */
+#define X12_ASTATUS2		0x12	/* Audio status bits setting2 */
+#define X13_CAT_CODE		0x13	/* Category code */
+#define X14_A_SOURCE		0x14	/* Source number/ Audio word length */
+#define X15_AVSET1		0x15	/* Audio/Video setting.1 */
+#define X16_VIDEO1		0x16
+#define X17_DC_REG		0x17	/* init 20h Deep color setting */
+#define X18_CSC_C0_HI		0x18	/* Color Space Conversion Parameters */
+#define X19_CSC_C0_LO		0x19
+#define X1A_CSC_C1_HI		0x1a	/* Color Space Conversion Parameters */
+#define X1B_CSC_C1_LO		0x1b
+#define X1C_CSC_C2_HI		0x1c
+#define X1D_CSC_C2_LO		0x1d
+#define X1E_CSC_C3_HI		0x1e
+#define X1F_CSC_C3_LO		0x1f
+#define X20_CSC_C4_HI		0x20
+#define X21_CSC_C4_LO		0x21
+#define X22_CSC_C5_HI		0x22
+#define X23_CSC_C5_LO		0x23
+#define X24_CSC_C6_HI		0x24
+#define X25_CSC_C6_LO		0x25
+#define X26_CSC_C7_HI		0x26
+#define X27_CSC_C7_LO		0x27
+#define X28_CSC_C8_HI		0x28
+#define X29_CSC_C8_LO		0x29
+#define X2A_CSC_C9_HI		0x2a
+#define X2B_CSC_C9_LO		0x2b
+#define X2C_CSC_C10_HI		0x2c
+#define X2D_CSC_C10_LO		0x2d
+#define X2E_CSC_C11_HI		0x2e
+#define X2F_CSC_C11_LO		0x2f
+#define X30_EXT_VPARAMS		0x30	/* External video parameter settings */
+#define X31_EXT_HTOTAL		0x31	/* External horizontal total */
+#define X32_EXT_HTOTAL		0x32
+#define X33_EXT_HBLANK		0x33	/* External horizontal blank */
+#define X34_EXT_HBLANK		0x34
+#define X35_EXT_HDLY		0x35	/* External horizontal delay */
+#define X36_EXT_HDLY		0x36
+#define X37_EXT_HS_DUR		0x37	/* External horizontal duration */
+#define X38_EXT_HS_DUR		0x38
+#define X39_EXT_VTOTAL		0x39	/* External vertical total */
+#define X3A_EXT_VTOTAL		0x3a
+#define X3B_AVSET2		0x3b	/* Audio/Video setting.2 */
+#define X3C_EX_VID		0x3c	/* External input Video ID(VID) */
+#define X3D_EXT_VBLANK		0x3d	/* External virtical blank */
+#define X3E_EXT_VDLY		0x3e	/* External virtical delay */
+#define X3F_EXT_VS_DUR		0x3f	/* External virtical durationv */
+#define X40_CTRL_PKT_EN		0x40	/* Control packet enable */
+#define X41_SEND_CPKT_AUTO	0x41	/* HB0 for generic control packet */
+#define X42_AUTO_CHECKSUM	0x42	/* Auto checksum option */
+#define X45_VIDEO2		0x45	/* Video setting.2 */
+#define X46_OUT_OPTION		0x46	/* Ouput Option*/
+#define X51_PHY_CTRL		0x51	/* Revervd[7:4],PHY_OPTION[3:0] */
+#define X52_HSYNC_PLACE_656	0x52	/* HSYNC placement at ITU656 */
+#define X53_HSYNC_PLACE_656	0x53
+#define X54_VSYNC_PLACE_656	0x54	/* VSYNC placement at ITU656 */
+#define X55_VSYNC_PLACE_656	0x55
+#define X56_PHY_CTRL		0x56	/* SLIPHDMIT parameter settings */
+#define X57_PHY_CTRL		0x57
+#define X58_PHY_CTRL		0x58
+#define X59_PHY_CTRL		0x59
+#define X5A_PHY_CTRL		0x5a
+#define X5B_PHY_CTRL		0x5b
+#define X5C_PHY_CTRL		0x5c
+#define X5D_PHY_CTRL		0x5d
+#define X5E_PHY_CTRL		0x5e
+#define X5F_PACKET_INDEX	0x5f
+#define X60_PKT_HB0		0x60
+#define X61_PKT_HB1		0x61
+#define X62_PKT_HB2		0x62
+#define X63_PKT_PB0		0x63
+#define X64_PKT_PB1		0x64
+#define X65_PKT_PB2		0x65
+#define X66_PKT_PB3		0x66
+#define X67_PKT_PB4		0x67
+#define X68_PKT_PB5		0x68
+#define X69_PKT_PB6		0x69
+#define X6A_PKT_PB7		0x6a
+#define X6B_PKT_PB8		0x6b
+#define X6C_PKT_PB9		0x6c
+#define X6D_PKT_PB10		0x6d
+#define X6E_PKT_PB11		0x6e
+#define X6F_PKT_PB12		0x6f
+#define X70_PKT_PB13		0x70
+#define X71_PKT_PB14		0x71
+#define X72_PKT_PB15		0x72
+#define X73_PKT_PB16		0x73
+#define X74_PKT_PB17		0x74
+#define X75_PKT_PB18		0x75
+#define X76_PKT_PB19		0x76
+#define X77_PKT_PB20		0x77
+#define X78_PKT_PB21		0x78
+#define X79_PKT_PB22		0x79
+#define X7A_PKT_PB23		0x7a
+#define X7B_PKT_PB24		0x7b
+#define X7C_PKT_PB25		0x7c
+#define X7D_PKT_PB26		0x7d
+#define X7E_PKT_PB27		0x7e
+#define X80_EDID_FIFO		0x80	/* Access window for EDID buffer */
+#define X81_DDC_LSB		0x81	/* DDC frequency control LSB */
+#define X82_DDC_MSB		0x82	/* DDC frequency control MSB */
+#define X92_INT_MASK1		0x92	/* Mask for Interrupt Group1 */
+#define X93_INT_MASK2		0x93	/* Mask for Interrupt Group2 */
+#define X94_INT_STATUS1		0x94	/* Status for Interrupt Group1 */
+#define X95_INT_STATUS2		0x95	/* Status for Interrupt Group2 */
+#define X96_INT_MASK3		0x96	/* Mask for Interrupt Group3 */
+#define X97_INT_MASK4		0x97	/* Mask for Interrupt Group4 */
+#define X98_INT_STATUS3		0x98	/* Status for Interrupt Group3 */
+#define X99_INT_STATUS4		0x99	/* Status for Interrupt Group4 */
+#define XAF_HDCP_CTRL		0xaf	/* R/W 12h HDCP Control Register */
+#define XB8_HDCP_STATUS		0xb8	/* HDCP Status Register */
+#define XBE_BCAPS		0xbe	/* BCAPS value */
+#define XBF_KSV7_0		0xbf	/* KSV[7:0] - AKSV/BKSV monitor */
+#define XC0_KSV15_8		0xc0	/* KSV[15:8] - AKSV/BKSV monitor */
+#define XC1_KSV23_16		0xc1	/* KSV[23:16] - AKSV/BKSV monitor */
+#define XC2_KSV31_24		0xc2	/* KSV[31:24] - AKSV/BKSV monitor */
+#define XC3_KSV39_32		0xc3	/* KSV[39:32] - AKSV/BKSV monitor */
+#define XC4_SEG_PTR		0xc4	/* EDID segment pointer */
+#define XC5_EDID_WD_ADDR	0xc5	/* EDID word address */
+#define XC6_GEN_PB26		0xc6	/* Generic control packet (PB26) */
+#define XC8_HDCP_ERR		0xc8	/* HDCP error */
+#define XC9_TIMER		0xc0	/*  Timer value for 100ms */
+#define XCA_TIMER		0xca	/* init 2ch Timer value for 5sec */
+#define XCB_READ_RI_CNT		0xcb	/* Ri read count */
+#define XCC_AN_SEED		0xcc	/* An Seed */
+#define XCD_MAX_REC_NUM		0xcd	/* maxi number of receivers allowed */
+#define XCF_HDCP_MEM_CTRL2	0xcf	/* [1:0] ID_FAX_KEY, ID_HDCP_KEY */
+#define XD0_HDCP_CTRL2		0xd0	/* R/W 08h HDCP Control 2 */
+#define XD2_HDCP_KEY_CTRL	0xd2	/* HDCP KEY memory control */
+#define XD3_CSC_CONFIG1		0xd3	/* CSC/Video Config.1 */
+#define XD4_VIDEO3		0xd4	/* Video setting 3 */
+#define XD9_GEN_PB27		0xd9	/* Generic InfoFrame PB27 */
+#define XDF_HPG_STATUS		0xdf	/* Hot plug/MSENS status */
+#define XE0_GAMUT_HB1		0xe0	/* gamut metadata HB1 */
+#define XE1_GAMUT_HB2		0xe1	/* gamut metadata HB2 */
+#define XE8_AN0			0xe8	/* An[7:0] */
+
+/* Bitfields in HDMI */
+#define PLLA_RST_X00		BIT(2)	/* reset PLL_A */
+#define PLLB_RST_X00		BIT(3)	/* reset PLL_B */
+#define PWR_MOD_A_X00		BIT(4)	/* power mode A */
+#define PWR_MOD_B_X00		BIT(5)	/* power mode B */
+#define PWR_MOD_D_X00		BIT(6)	/* power mode D */
+#define PWR_MOD_E_X00		BIT(7)	/* power mode E */
+#define PLL_MASK_X00		GENMASK(7, 4)
+#define PLL_RST_X00		(PLLA_RST_X00 | PLLB_RST_X00)
+#define PWR_MODB_RST_X00	(PWR_MOD_B_X00 | PLL_RST_X00)
+#define PWR_MODB_RSTB_X00	(PWR_MOD_B_X00 | PLLB_RST_X00)
+
+#define I2S_MOD_X0C		0x04
+#define LEFT_J_MOD_X0C		0x06
+#define RIGHT_J_MOD_X0C		0x05
+
+#define FMT_YCC422_X15		BIT(1)
+#define CUR_SMP_44100_X15	0x0
+#define CUR_SMP_48000_X15	BIT(5)
+#define ORI_SMP_44100_X11	(0xf << 0)
+#define ORI_SMP_48000_X11	(0xd << 0)
+#define FMT_MASK_X15		GENMASK(3, 0)
+
+#define SPACE_YCC_X16		BIT(0)
+#define SAV_CHANNEL1_x16	BIT(2)	/* SAV EAV location channel1 */
+#define SAV_CHANNEL2_x16	BIT(3)	/* SAV EAV location channel2 */
+#define WIDTH_10BITS_X16	BIT(4)
+#define VID_YCC422_X16		BIT(7)
+#define VID_YCC444_X16		BIT(6)
+#define WIDTH_12BITS_X16	0x0
+#define VID_RGB_X16		0x0
+#define WIDTH_8BITS_X16		(BIT(4) | BIT(5))
+#define VID_MASK_X16		GENMASK(7, 6)
+#define DAT_WIDTH_MASK_X16	GENMASK(5, 4)
+
+#define SPEED_8BIT_X17		0x0
+#define SPEED_10BIT_X17		BIT(6)
+#define SPEED_12BIT_X17		BIT(7)
+#define SPEED_MASK_X17		GENMASK(7, 6)
+
+#define EXTERANL_VIDEO_X30	BIT(0)
+#define INETLACE_X30		BIT(1)
+#define HSYNC_POLARITY_X30	BIT(2)
+#define VSYNC_POLARITY_X30	BIT(3)
+#define HIGH_POLARITY_X30	(HSYNC_POLARITY_X30 | VSYNC_POLARITY_X30)
+
+#define CSC_EN_X3B		BIT(0)	/* Color Space Conversion enable */
+#define SEL_FULL_RANGE_X3B	BIT(1)	/* range for Send black video mode */
+#define EN_M0_LOAD_X3B		BIT(2)	/* Load M0 into Akey area */
+#define EXT_DE_CNT_X3B		BIT(5)	/* External DE control */
+#define CD_ZERO_X3B		BIT(6)	/* CD all zero override */
+#define CTS_DEBUG_X3B		BIT(7)	/* Debug bit for CTS timing */
+#define CD_MASK_X3B		GENMASK(6, 6)
+
+#define AUTO_CHECKSUM_X42	GENMASK(0, 0)
+
+#define NOVIDEO_X45		BIT(0)	/* Send black video */
+#define NOAUDIO_X45		BIT(1)	/* Send no audio */
+#define AUDIORST_X45		BIT(2)	/* audio capture logic reset */
+#define SET_AV_MUTE_X40		BIT(6)	/* Send ?gSet AV mute*/
+#define CLEAR_AV_MUTE_X40	BIT(7)	/* Clear AV mute?h */
+#define ENVIDEO_X45		GENMASK(0, 0)
+
+#define GENERIC_PKT_X5F		0x0	/* Generic packet */
+#define ACP_PKT_X5F		BIT(0)	/* ACP packet */
+#define ISRC1_PKT_X5F		BIT(1)	/* ISRC1 packet */
+#define ISRC2_PKT_X5F		(BIT(0) | BIT(1))
+#define GAMUT_PKT_X5F		BIT(2)	/* Gamut metadata packet */
+#define VENDOR_INFO_PKT_X5F	(BIT(0) | BIT(2))
+#define AVI_INFO_PKT_X5F	(BIT(1) | BIT(2))
+#define PRODUCT_INFO_PKT_X5F	(BIT(0) | BIT(1) | BIT(2))
+#define AUDIO_INFO_PKT_X5F	BIT(3)	/* Audio InfoFrame packet */
+#define MPEG_SRC_INFO_PKT_X5F	(BIT(0) | BIT(3))
+
+#define HB0_AVI_TYPE_X60	0x82
+#define HB0_AUD_TYPE_X60	0x84
+#define HB1_VERSION_X61		0x02
+#define HB1_AUD_VERSION_X61	0x01
+#define HB2_LENTH_X62		0x0d
+#define HB2_AUD_LENTH_X62	0x0a
+
+#define PB0_AVI_CHECKSUM_X63	0x6f
+#define PB0_AUD_CHECKSUM_X63	0x70
+
+#define PB1_YCC422_X64		BIT(5)	/* set PB1 ycc422*/
+#define PB1_YCC444_X64		BIT(6)	/* set PB1 ycc444 */
+#define PB1_MASK_X64		GENMASK(7, 5)
+#define PB1_AUD_2CH_X64		BIT(0) /* two channel audio */
+
+#define EDID_ERR_MSK_X92	BIT(1)	/* EDID error detect interrupt mask */
+#define EDID_RDY_MSK_X92	BIT(2)	/* EDID ready interrupt mask */
+#define AFIFO_FULL_MSK_X92	BIT(4)	/* Audio FIFO detect interrupt mask */
+#define VSYNC_MSK_X92		BIT(5)	/* VSYNC detect interrupt mask */
+#define MSENS_MSK_X92		BIT(6)	/* MSENS detect interrupt mask */
+#define HPG_MSK_X92		BIT(7)	/* Hot plug detect interrupt mask */
+#define EDID_MSK_X92		(EDID_ERR_MSK_X92 | EDID_RDY_MSK_X92)
+
+#define RDY_AUTH_MSK_X93	BIT(3)	/* Authen ready interrupt mask */
+#define AUTH_DONE_MSK_X93	BIT(4)	/* Authen done interrupt mask */
+#define BKSV_RCRDY_MSK_X93	BIT(5)	/* BKSV from receiver interrupt mask */
+#define BKSV_RPRDY_MSK_X93	BIT(6)	/* BKSV from repeater interrupt mask */
+#define HDCP_ERR_MSK_X93	BIT(7)	/* HDCP error detect interrupt mask */
+
+#define EDID_ERR_INT_X94	BIT(1)	/* EDID error detect interrupt */
+#define EDID_RDY_INT_X94	BIT(2)	/* EDID ready interrupt */
+#define AFIFO_FULL_INT_X94	BIT(4)	/* Audio FIFO full detect interrupt */
+#define VSYNC_INT_X94		BIT(5)	/* VSYNC detect interrupt */
+#define MSENS_INT_X94		BIT(6)	/* MSENS detect interrupt */
+#define HPG_INT_X94		BIT(7)	/* Hot plug detect interrupt */
+#define HPG_MSENS_INT_X94	(HPG_INT_X94 | MSENS_INT_X94)
+#define EDID_INT_X94		(EDID_RDY_INT_X94 | EDID_ERR_INT_X94)
+#define INT_CLR_X94		0xff
+
+
+#define RDY_AUTH_INT_X95	BIT(3)	/* Authentication ready interrupt */
+#define AUTH_DONE_INT_X95	BIT(4)	/* HDCP authen done interrupt */
+#define BKSV_RCRDY_INT_X95	BIT(5)	/* BKSV ready  receiver interrupt */
+#define BKSV_RPRDY_INT_X95	BIT(6)	/* BKSVs ready  repeater interrupt */
+#define HDCP_ERR_INT_X95	BIT(7)	/* HDCP error detect interrupt */
+#define INT_CLR_X95		0xff
+
+#define HDCP_RESET_XAF		BIT(0)	/* Reset HDCP */
+#define HDMI_MODE_CTRL_XAF	BIT(1)	/* HDMI/DVI mode */
+#define ADV_CIPHER_XAF		BIT(2)	/* Advanced cipher mode */
+#define STOP_AUTH_XAF		BIT(3)	/* Stop HDCP authentication */
+#define FRAME_ENC_XAF		BIT(4)	/* Frame encrypt */
+#define BKSV_FAIL_XAF		BIT(5)	/* BKSV check result (FAIL) */
+#define BKSV_PASS_XAF		BIT(6)	/* BKSV check result (PASS) */
+#define HDCP_REQ_XAF		BIT(7)	/* HDCP authentication start*/
+#define HDMI_MODE_MASK_XAF	GENMASK(1, 1)
+
+#define ADV_CIPHERI_STATUS_XB8	BIT(3)	/* Advanced cipher status */
+#define HDCP_IDLE_XB8		BIT(4)	/* HDCP state machine status */
+#define HDMI_STATUS_XB8		BIT(5)	/* HDMI/DVI status */
+#define ENC_XB8			BIT(6)	/* Encryption status */
+#define AUTH_XB8		BIT(7)	/* HDCP authentication status*/
+
+#define BAD_BKSV_XC8		BIT(0)	/* BKSV not contain 20 0's 20 1's */
+
+#define LD_HDCP_KEY_XCF		BIT(0)	/* Trigger for loading HDCP key */
+#define LD_FAX_KEY_XCF		BIT(1)	/* Trigger for loading fax HDCP key */
+
+#define DELAY_RI_CHK_XD0	BIT(3)
+#define DIS_0LEN_HASH_XD0	BIT(4)
+#define EN_PJ_CALC_XD0		BIT(5)
+#define DIS_127_CHK_XD0		BIT(7)
+
+#define KEY_READY_XD2		BIT(0)
+#define KEY_VALID_XD2		BIT(1)
+#define KSV_VALID_XD2		BIT(2)
+#define KSV_SEL_XD2		BIT(3)
+#define LOAD_AKSV_XD2		BIT(4)
+#define USE_KSV2_XD2		BIT(5)
+#define USE_KSV1_XD2		BIT(6)
+
+#define AUTO_MODE_XD3		BIT(7)
+
+#define BIST_FAIL_XDF		BIT(0)	/* Dual port RAM BIST result fail */
+#define BIST_PASS_XDF		BIT(1)	/* Dual port RAM BIST result passed */
+#define MSENS_PRT_XDF		BIT(6)	/* MSENS input port status */
+#define HPG_PRT_XDF		BIT(7)	/* Hot plug input port status */
+#define HPG_MSENS_PRT_XDF	(HPG_PRT_XDF | MSENS_PRT_XDF)
+
+#define EDID_ADDR_80_XC5	0x80	/* word address1 is 0x80 */
+#define EDID_ADDR_00_XC5	0x00	/* word address2 is 0x00 */
+
+#define HDMI_I2C_SLAVE_ADDR	0x72
+#define HDMI_EDID_RETRY_TIMES	10
+#define HDMI_EDID_BLK_SIZE	128
+#define HDMI_EDID_EXT_INDEX	126
+#define HDMI_44100_PARAM_N	0x1880
+#define HDMI_48000_PARAM_N	0x1800
+#define PHY_DATA_SIZE		10
+#define HB0_TO_PB27_SIZE	31
+#define HDMI_INFO_FRAME_SIZE	0x11
+#define HDMI_REG_MSK		0xff
+
+/* Video setting constants */
+#define VID_01_640X480P		1
+#define VID_02_720X480P		2
+#define VID_03_720X480P		3
+#define VID_04_1280X720P	4
+#define VID_05_1920X1080I	5
+#define VID_06_720X480I		6
+#define VID_07_720X480I		7
+#define VID_08_720X240P		8
+#define VID_09_720X240P		9
+#define VID_10_2880X480I	10
+#define VID_11_2880X480I	11
+#define VID_12_2880X240P	12
+#define VID_13_2880X240P	13
+#define VID_14_1440X480P	14
+#define VID_15_1440X480P	15
+#define VID_16_1920X1080P	16
+#define VID_17_720X576P		17
+#define VID_18_720X576P		18
+#define VID_19_1280X720P	19
+#define VID_20_1920X1080I	20
+#define VID_21_720X576I		21
+#define VID_22_720X576I		22
+#define VID_23_720X288p		23
+#define VID_24_720X288p		24
+#define VID_25_2880X576I	25
+#define VID_26_2880X576I	26
+#define VID_27_2880X288p	27
+#define VID_28_2880X288p	28
+#define VID_29_1440X576P	29
+#define VID_30_1440X576P	30
+#define VID_31_1920X1080P	31
+#define VID_32_1920X1080P	32
+#define VID_33_1920X1080P	33
+#define VID_34_1920X1080P	34
+#define VID_35_2880X480P	35
+#define VID_36_2880X480P	36
+#define VID_37_2880X576P	37
+#define VID_38_2880X567p	38
+#define VID_39_1920X1080I	39
+#define VID_40_1920X1080I	40
+#define VID_41_1280X720P	41
+#define VID_42_720X576P		42
+#define VID_43_720X576P		43
+#define VID_44_720X576I		44
+#define VID_45_720X576I		45
+#define VID_46_1920X1080I	46
+#define VID_47_1280X720P	47
+#define VID_48_720X480P		48
+#define VID_49_720X480P		49
+#define VID_50_720X480I		50
+#define VID_51_720X480I		51
+#define VID_52_720X576P		52
+#define VID_53_720X576P		53
+#define VID_54_720X576I		54
+#define VID_55_720X576I		55
+#define VID_56_720X480P		56
+#define VID_57_720X480P		57
+#define VID_58_720X480I		58
+#define VID_59_720X480I		59
+
+enum DEEP_COLOR {
+	DEEP_COLOR_8BIT = 4,
+	DEEP_COLOR_10BIT,
+	DEEP_COLOR_12BIT
+};
+
+enum PHY_TDMS_CLOCK {
+	PHY_TMDS_CLOCK_27,
+	PHY_TMDS_CLOCK_33,
+	PHY_TMDS_CLOCK_40,
+	PHY_TMDS_CLOCK_54,
+	PHY_TMDS_CLOCK_98,
+	PHY_TMDS_CLOCK_111,
+	PHY_TMDS_CLOCK_148,
+	PHY_TMDS_CLOCK_185,
+	PHY_TMDS_CLOCK_222
+};
+
+#endif /* __CSKY_HDMI_H__ */
diff --git a/addons/drivers/mailbox/Kconfig b/addons/drivers/mailbox/Kconfig
new file mode 100644
index 0000000..f6a1d08
--- /dev/null
+++ b/addons/drivers/mailbox/Kconfig
@@ -0,0 +1,22 @@
+#
+# C-SKY mailbox control drivers
+#
+
+menuconfig MAILBOX_CSKY
+	bool "C-SKY hardware Mailbox Support"
+	select MAILBOX
+
+if MAILBOX_CSKY
+
+config TTY_MAILBOX_CSKY
+	bool "TTY based on C-SKY hardware Mailbox Support"
+	depends on MAILBOX_CSKY && TTY
+
+config DEBUG_MAILBOX
+	bool "Debug Mailbox calls"
+	depends on MAILBOX_CSKY && DEBUG_KERNEL
+	help
+	  Say Y here to add some extra checks and diagnostics to Mailbox calls.
+
+endif
+
diff --git a/addons/drivers/mailbox/Makefile b/addons/drivers/mailbox/Makefile
new file mode 100644
index 0000000..3322375
--- /dev/null
+++ b/addons/drivers/mailbox/Makefile
@@ -0,0 +1,9 @@
+# C-SKY mailbox drivers
+ccflags-$(CONFIG_DEBUG_MAILBOX) += -O0
+ccflags-$(CONFIG_DEBUG_MAILBOX)	+= -DDEBUG
+
+obj-$(CONFIG_MAILBOX_CSKY)	+= mailbox-csky.o
+obj-$(CONFIG_MAILBOX_CSKY)	+= mailbox-client-csky.o
+obj-$(CONFIG_TTY_MAILBOX_CSKY)	+= tty-mailbox-csky.o
+obj-$(CONFIG_TTY_MAILBOX_CSKY)	+= tty-mailbox-client-csky.o
+
diff --git a/addons/drivers/mailbox/mailbox-client-csky.c b/addons/drivers/mailbox/mailbox-client-csky.c
new file mode 100644
index 0000000..d967f9b
--- /dev/null
+++ b/addons/drivers/mailbox/mailbox-client-csky.c
@@ -0,0 +1,337 @@
+/*
+ * mailbox client driver for C-SKY's SoCs.
+ *
+ * Copyright (C) 2017 C-SKY MicroSystems Co.,Ltd.
+ * Author: Charles Lu <chongzhi_lu@c-sky.com>
+ *
+ * This software is licensed under the terms of the GNU General Public
+ * License version 2, as published by the Free Software Foundation, and
+ * may be copied, distributed, and modified under those terms.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ */
+
+#include <linux/debugfs.h>
+#include <linux/err.h>
+#include <linux/io.h>
+#include <linux/kernel.h>
+#include <linux/mailbox_client.h>
+#include <linux/module.h>
+#include <linux/of.h>
+#include <linux/of_address.h>
+#include <linux/platform_device.h>
+#include <linux/slab.h>
+#include <linux/uaccess.h>
+
+#include "mailbox-csky.h"
+#include "mailbox-csky-internal.h"
+
+#define MBOX_MAX_MSG_LEN	CSKY_MBOX_MAX_MESSAGE_LENGTH
+#define HEXDUMP_BYTES_PER_LINE	16
+#define HEXDUMP_LINE_LEN	((HEXDUMP_BYTES_PER_LINE * 4) + 2)
+#define HEXDUMP_MAX_LEN		(HEXDUMP_LINE_LEN *		\
+				(MBOX_MAX_MSG_LEN / HEXDUMP_BYTES_PER_LINE))
+
+static struct dentry *root_debugfs_dir;
+
+struct mbox_client_csky_device {
+	struct device		*dev;
+	void __iomem		*tx_mmio;
+	void __iomem		*rx_mmio;
+	struct mbox_chan	*tx_channel;
+	struct mbox_chan	*rx_channel;
+	char			*rx_buffer;
+	struct mbox_message	*message;
+	spinlock_t		lock;
+};
+
+static ssize_t mbox_client_csky_message_write(struct file *filp,
+					      const char __user *userbuf,
+					      size_t count, loff_t *ppos)
+{
+	struct mbox_client_csky_device *tdev = filp->private_data;
+	void *data;
+	int ret;
+
+	if (!tdev->tx_channel) {
+		dev_err(tdev->dev, "Channel cannot do Tx\n");
+		return -EINVAL;
+	}
+
+	if (count > CSKY_MBOX_MAX_DATA_LENGTH) {
+		dev_err(tdev->dev,
+			"Message length %zd greater than max allowed %d\n",
+			count, CSKY_MBOX_MAX_DATA_LENGTH);
+		return -EINVAL;
+	}
+
+	tdev->message = kzalloc(MBOX_MAX_MSG_LEN, GFP_KERNEL);
+	if (!tdev->message)
+		return -ENOMEM;
+
+	/* Fill message according to struct mbox_message format */
+	tdev->message->mssg_type = CSKY_MBOX_MSSG_DATA;
+	tdev->message->length = count;
+	ret = copy_from_user(tdev->message->data, userbuf, count);
+	if (ret) {
+		ret = -EFAULT;
+		goto out;
+	}
+
+	data = tdev->message;
+	print_hex_dump_bytes("Client: Sending: Message: ",
+		DUMP_PREFIX_ADDRESS, tdev->message, MBOX_MAX_MSG_LEN);
+
+	ret = mbox_send_message(tdev->tx_channel, data);
+	if (ret < 0)
+		dev_err(tdev->dev, "Failed to send message via mailbox\n");
+
+out:
+	kfree(tdev->message);
+	return ret < 0 ? ret : count;
+}
+
+static ssize_t mbox_client_csky_message_read(struct file *filp,
+					     char __user *userbuf,
+					     size_t count, loff_t *ppos)
+{
+	struct mbox_client_csky_device *tdev = filp->private_data;
+	unsigned long flags;
+	char *touser, *ptr;
+	int l = 0;
+	int ret;
+
+	touser = kzalloc(HEXDUMP_MAX_LEN + 1, GFP_KERNEL);
+	if (!touser)
+		return -ENOMEM;
+
+	if (!tdev->rx_channel) {
+		ret = snprintf(touser, 20, "<NO RX CAPABILITY>\n");
+		ret = simple_read_from_buffer(userbuf, count, ppos,
+					      touser, ret);
+		goto out;
+	}
+
+	if (tdev->rx_buffer[0] == '\0') {
+		ret = snprintf(touser, 9, "<EMPTY>\n");
+		ret = simple_read_from_buffer(userbuf, count, ppos,
+					      touser, ret);
+		goto out;
+	}
+
+	spin_lock_irqsave(&tdev->lock, flags);
+
+	ptr = tdev->rx_buffer;
+	while (l < HEXDUMP_MAX_LEN) {
+		hex_dump_to_buffer(ptr,
+				   HEXDUMP_BYTES_PER_LINE,
+				   HEXDUMP_BYTES_PER_LINE, 1, touser + l,
+				   HEXDUMP_LINE_LEN, true);
+
+		ptr += HEXDUMP_BYTES_PER_LINE;
+		l += HEXDUMP_LINE_LEN;
+		*(touser + (l - 1)) = '\n';
+	}
+	*(touser + l) = '\0';
+
+	memset(tdev->rx_buffer, 0, MBOX_MAX_MSG_LEN);
+
+	spin_unlock_irqrestore(&tdev->lock, flags);
+
+	ret = simple_read_from_buffer(
+		userbuf, count, ppos, touser, HEXDUMP_MAX_LEN);
+out:
+	kfree(touser);
+	return ret;
+}
+
+static const struct file_operations mbox_client_csky_message_ops = {
+	.write	= mbox_client_csky_message_write,
+	.read	= mbox_client_csky_message_read,
+	.open	= simple_open,
+	.llseek	= generic_file_llseek,
+};
+
+static int index_names = 0;
+static bool debugfs_dir_created = false;
+static const char* file_names[] = {"mbox-client0", "mbox-client1"};
+
+static int mbox_client_csky_add_debugfs(struct platform_device *pdev,
+					struct mbox_client_csky_device *tdev)
+{
+	if (!debugfs_initialized())
+		return 0;
+
+	if (index_names > 2) {
+		dev_err(&pdev->dev, "Max device index is 2\n");
+		return 0;
+	}
+
+	if (!debugfs_dir_created) {
+		root_debugfs_dir = debugfs_create_dir("mailbox", NULL);
+		if (!root_debugfs_dir) {
+			dev_err(&pdev->dev,
+				"Failed to create mailbox debugfs\n");
+			return -EINVAL;
+		}
+		debugfs_dir_created = true;
+	}
+
+	debugfs_create_file(file_names[index_names], 0600, root_debugfs_dir,
+			    tdev, &mbox_client_csky_message_ops);
+
+	index_names++;
+	return 0;
+}
+
+static void mbox_client_csky_receive_message(struct mbox_client *client,
+					     void *message)
+{
+	struct mbox_client_csky_device *tdev = dev_get_drvdata(client->dev);
+	unsigned long flags;
+
+	if (tdev->rx_mmio == NULL) {
+		dev_err(client->dev, "rx_mmio is NULL\n");
+		return;
+	}
+
+	spin_lock_irqsave(&tdev->lock, flags);
+	memcpy_fromio(tdev->rx_buffer, tdev->rx_mmio, MBOX_MAX_MSG_LEN);
+#ifdef DEBUG
+	print_hex_dump_bytes("Client: Received [MMIO]: ",
+			     DUMP_PREFIX_ADDRESS,
+			     tdev->rx_buffer, MBOX_MAX_MSG_LEN);
+#endif
+	spin_unlock_irqrestore(&tdev->lock, flags);
+}
+
+static void mbox_client_csky_prepare_message(struct mbox_client *client,
+					     void *message)
+{
+	struct mbox_client_csky_device *tdev = dev_get_drvdata(client->dev);
+
+	if (tdev->tx_mmio) {
+		memcpy_toio(tdev->tx_mmio, message, MBOX_MAX_MSG_LEN);
+	}
+}
+
+static void mbox_client_csky_message_sent(struct mbox_client *client,
+					  void *message, int r)
+{
+	if (r) {
+		dev_warn(client->dev,
+			 "Client: Message could not be sent: %d\n", r);
+	}
+	else {
+#ifdef DEBUG
+		dev_info(client->dev, "Client: Message sent\n");
+#endif
+	}
+}
+
+static struct mbox_chan *
+mbox_client_csky_request_channel(struct platform_device *pdev,
+				 const char *name)
+{
+	struct mbox_client *client;
+	struct mbox_chan *channel;
+
+	client = devm_kzalloc(&pdev->dev, sizeof(*client), GFP_KERNEL);
+	if (!client)
+		return ERR_PTR(-ENOMEM);
+
+	client->dev		= &pdev->dev;
+	client->rx_callback	= mbox_client_csky_receive_message;
+	client->tx_prepare	= mbox_client_csky_prepare_message;
+	client->tx_done		= mbox_client_csky_message_sent;
+	client->tx_block	= true;
+	client->knows_txdone	= true;
+	client->tx_tout		= 500;
+
+	channel = mbox_request_channel_byname(client, name);
+	if (IS_ERR(channel)) {
+		devm_kfree(&pdev->dev, client);
+		dev_warn(&pdev->dev, "Failed to request %s channel\n", name);
+		return NULL;
+	}
+
+	return channel;
+}
+
+static int mbox_client_csky_probe(struct platform_device *pdev)
+{
+	struct device_node *node = pdev->dev.of_node;
+	struct mbox_client_csky_device *tdev;
+	int ret;
+
+	tdev = devm_kzalloc(&pdev->dev, sizeof(*tdev), GFP_KERNEL);
+	if (!tdev)
+		return -ENOMEM;
+
+	tdev->tx_mmio = of_iomap(node, 0);
+	tdev->rx_mmio = of_iomap(node, 1);
+
+	tdev->tx_channel = mbox_client_csky_request_channel(pdev, "channel");
+	if (!tdev->tx_channel) {
+		dev_err(&pdev->dev, "Request channel failed\n");
+		return -EPROBE_DEFER;
+	}
+	/* In fact, rx_channel is same with tx_channel in C-SKY's mailbox */
+	tdev->rx_channel = tdev->tx_channel;
+
+	tdev->dev = &pdev->dev;
+	platform_set_drvdata(pdev, tdev);
+
+	spin_lock_init(&tdev->lock);
+
+	tdev->rx_buffer = devm_kzalloc(&pdev->dev,
+					MBOX_MAX_MSG_LEN, GFP_KERNEL);
+	if (!tdev->rx_buffer)
+		return -ENOMEM;
+
+	ret = mbox_client_csky_add_debugfs(pdev, tdev);
+	if (ret)
+		return ret;
+
+	dev_info(&pdev->dev, "Successfully registered\n");
+
+	return 0;
+}
+
+static int mbox_client_csky_remove(struct platform_device *pdev)
+{
+	struct mbox_client_csky_device *tdev = platform_get_drvdata(pdev);
+
+	debugfs_remove_recursive(root_debugfs_dir);
+
+	if (tdev->tx_channel)
+		mbox_free_channel(tdev->tx_channel);
+
+	if (tdev->rx_channel && tdev->rx_channel != tdev->tx_channel)
+		mbox_free_channel(tdev->rx_channel);
+
+	return 0;
+}
+
+static const struct of_device_id mbox_client_csky_match[] = {
+	{ .compatible = "csky,mailbox-client" },
+	{},
+};
+
+static struct platform_driver mbox_client_csky_driver = {
+	.driver = {
+		.name = "csky,mailbox-client",
+		.of_match_table = mbox_client_csky_match,
+	},
+	.probe  = mbox_client_csky_probe,
+	.remove = mbox_client_csky_remove,
+};
+module_platform_driver(mbox_client_csky_driver);
+
+MODULE_DESCRIPTION("CSKY Mailbox Client driver");
+MODULE_AUTHOR("Charles Lu <chongzhi_lu@c-sky.com");
+MODULE_LICENSE("GPL v2");
diff --git a/addons/drivers/mailbox/mailbox-csky-internal.h b/addons/drivers/mailbox/mailbox-csky-internal.h
new file mode 100644
index 0000000..66ce303
--- /dev/null
+++ b/addons/drivers/mailbox/mailbox-csky-internal.h
@@ -0,0 +1,44 @@
+/*
+ * mailbox driver for C-SKY's SoCs.
+ *
+ * Copyright (C) 2017 C-SKY MicroSystems Co.,Ltd.
+ * Author: Charles Lu <chongzhi_lu@c-sky.com>
+ *
+ * This software is licensed under the terms of the GNU General Public
+ * License version 2, as published by the Free Software Foundation, and
+ * may be copied, distributed, and modified under those terms.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ */
+
+#ifndef __MAILBOX_CSKY_INTERNAL_H
+#define __MAILBOX_CSKY_INTERNAL_H
+
+enum mbox_csky_mssg_type {
+	CSKY_MBOX_MSSG_DATA = 'd',	/* Data to receiver */
+	CSKY_MBOX_MSSG_ACK  = 'a',	/* ACK to sender */
+};
+
+#define MBOX_CSKY_MSSG_HEAD_LENGTH 4
+/**
+ * struct mbox_message - Description of a message that send to mailbox
+ * @mssg_type:	The message type that transfer, refer to mbox_csky_mssg_type
+ * @length:	Then data length, must <= CSKY_MBOX_MAX_DATA_LENGTH
+ * @reserved0:	Undefined
+ * @reserved1:	Undefined
+ * @data:	The transfer data. Ignore if mssg_type is CSKY_MBOX_MSSG_ACK
+ */
+struct mbox_message {
+	u8 mssg_type;
+	u8 length;
+	u8 reserved0;
+	u8 reserved1;
+	u8 data[CSKY_MBOX_MAX_DATA_LENGTH];
+};
+
+#endif /* __MAILBOX_CSKY_INTERNAL_H */
+
diff --git a/addons/drivers/mailbox/mailbox-csky.c b/addons/drivers/mailbox/mailbox-csky.c
new file mode 100644
index 0000000..6de4f92
--- /dev/null
+++ b/addons/drivers/mailbox/mailbox-csky.c
@@ -0,0 +1,298 @@
+/*
+ * mailbox driver for C-SKY's SoCs.
+ *
+ * Copyright (C) 2017 C-SKY MicroSystems Co.,Ltd.
+ * Author: Charles Lu <chongzhi_lu@c-sky.com>
+ *
+ * This software is licensed under the terms of the GNU General Public
+ * License version 2, as published by the Free Software Foundation, and
+ * may be copied, distributed, and modified under those terms.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ */
+
+#include <linux/device.h>
+#include <linux/interrupt.h>
+#include <linux/io.h>
+#include <linux/kernel.h>
+#include <linux/mailbox_controller.h>
+#include <linux/module.h>
+#include <linux/of.h>
+#include <linux/of_address.h>
+#include <linux/platform_device.h>
+
+#include "mailbox-csky.h"
+#include "mailbox-csky-internal.h"
+
+#define DRIVER_NAME	"mailbox-csky"
+
+/* 0x18 is register length from CSKY_MBOX_INTGR to CSKY_MBOX_INTENB */
+#define MBOX_INTGR_ADDR(mbox)	\
+	(mbox->base + 0x18*(mbox->dev_id ? 0 : 1) + CSKY_MBOX_INTGR)
+#define MBOX_INTCR_ADDR(mbox)	\
+	(mbox->base + 0x18*(mbox->dev_id) + CSKY_MBOX_INTCR)
+#define MBOX_INTMR_ADDR(mbox)	\
+	(mbox->base + 0x18*(mbox->dev_id) + CSKY_MBOX_INTMR)
+#define MBOX_INTRSR_ADDR(mbox)	\
+	(mbox->base + 0x18*(mbox->dev_id) + CSKY_MBOX_INTRSR)
+#define MBOX_INTMSR_ADDR(mbox)	\
+	(mbox->base + 0x18*(mbox->dev_id) + CSKY_MBOX_INTMSR)
+#define MBOX_INTENB_ADDR(mbox)	\
+	(mbox->base + 0x18*(mbox->dev_id) + CSKY_MBOX_INTENB)
+#define MBOX_TX_MSSG_ADDR(mbox) (mbox->base + 0x18*2 + (mbox->dev_id ? 64 : 0))
+#define MBOX_RX_MSSG_ADDR(mbox) (mbox->base + 0x18*2 + (mbox->dev_id ? 0 : 64))
+
+#define TX_GENERATE_INTERRUPT(mbox)	writel(1, MBOX_INTGR_ADDR(mbox))
+#define RX_CLEAR_INTERRUPT(mbox) 	writel(1, MBOX_INTCR_ADDR(mbox))
+#define RX_MASK_INTERRUPT(mbox) 	writel(1, MBOX_INTMR_ADDR(mbox))
+#define RX_UNMASK_INTERRUPT(mbox)	writel(0, MBOX_INTMR_ADDR(mbox))
+#define RX_READ_INTERRUPT(mbox)		readl(MBOX_INTRSR_ADDR(mbox))
+#define RX_READ_MASKED_INTERRUPT(mbox)	readl(MBOX_INTMSR_ADDR(mbox))
+#define RX_ENABLE_INTERRUPT(mbox)	writel(1, MBOX_INTENB_ADDR(mbox))
+#define RX_DISABLE_INTERRUPT(mbox)	writel(0, MBOX_INTENB_ADDR(mbox))
+
+struct csky_mbox_chan {
+	struct csky_mbox *parent;
+};
+
+struct csky_mbox {
+	struct device *dev;
+	int dev_id;
+	struct mutex cfg_lock;
+	int irq;
+	void __iomem *base;
+	u32 chan_num;
+	struct csky_mbox_chan *mchans;
+	struct mbox_chan *chans;
+	struct mbox_controller controller;
+};
+
+#ifdef __LITTLE_ENDIAN
+#define	BYTE0(w)	((w) & 0xFF)
+#define	BYTE1(w)	(((w) >> 8) & 0xFF)
+#define	BYTE2(w)	(((w) >> 16) & 0xFF)
+#define	BYTE3(w)	(((w) >> 24) & 0xFF)
+#else
+#define	BYTE0(w)	(((w) >> 24) & 0xFF)
+#define	BYTE1(w)	(((w) >> 16) & 0xFF)
+#define	BYTE2(w)	(((w) >> 8) & 0xFF)
+#define	BYTE3(w)	((w) & 0xFF)
+#endif
+
+static irqreturn_t csky_mbox_interrupt(int irq, void *p)
+{
+	struct csky_mbox *mbox = (struct csky_mbox *)p;
+	struct mbox_chan *chan = &(mbox->chans[0]);
+	struct mbox_message *mssg_rx =
+		(struct mbox_message *)(MBOX_RX_MSSG_ADDR(mbox));
+
+	RX_CLEAR_INTERRUPT(mbox);
+
+	if (mssg_rx->mssg_type == CSKY_MBOX_MSSG_DATA) {
+		struct mbox_message *mssg_tx =
+			(struct mbox_message *)MBOX_TX_MSSG_ADDR(mbox);
+#ifdef DEBUG
+		u32 *data = (u32 *)mssg_rx;
+		dev_info(mbox->dev, "Recv data, first 8 bytes:" \
+			"%02x %02x %02x %02x %02x %02x %02x %02x\n",
+			BYTE0(data[0]), BYTE1(data[0]),
+			BYTE2(data[0]), BYTE3(data[0]),
+			BYTE0(data[1]), BYTE1(data[1]),
+			BYTE2(data[1]), BYTE3(data[1]));
+#endif
+
+		/* Receive message's data to upper */
+		mbox_chan_received_data(chan, (void*)(mssg_rx));
+
+		/* Send ACK back */
+		mssg_tx->mssg_type = CSKY_MBOX_MSSG_ACK;
+		TX_GENERATE_INTERRUPT(mbox);
+	}
+	else if (mssg_rx->mssg_type == CSKY_MBOX_MSSG_ACK) {
+		mbox_chan_txdone(chan, 0);	/* Notify tx done */
+	}
+	else {
+		dev_err(mbox->dev, "Undefined mssg_type:%02x",
+			mssg_rx->mssg_type);
+	}
+
+	return IRQ_HANDLED;
+}
+
+static struct mbox_chan *csky_mbox_xlate(struct mbox_controller *controller,
+					 const struct of_phandle_args *spec)
+{
+	struct csky_mbox *mbox = dev_get_drvdata(controller->dev);
+	u32 i = spec->args[0];
+	if (i > CSKY_MBOX_MAX_CHAN) {
+		dev_err(mbox->dev, "Failed to get chans[%d]\n", i);
+		return NULL;
+	}
+
+	return &mbox->chans[i];
+}
+
+static int csky_mbox_send_data(struct mbox_chan *chan, void *data)
+{
+	struct csky_mbox_chan *mchan = chan->con_priv;
+	struct csky_mbox *mbox = mchan->parent;
+
+#ifdef DEBUG
+	char *bytes = (char *)data;
+	dev_info(mbox->dev, "Send data, first 8 bytes:" \
+		"%02x %02x %02x %02x %02x %02x %02x %02x\n",
+		bytes[0], bytes[1], bytes[2], bytes[3],
+		bytes[4], bytes[5], bytes[6], bytes[7]);
+#endif
+	TX_GENERATE_INTERRUPT(mbox);
+	return 0;
+}
+
+static int csky_mbox_startup(struct mbox_chan *chan)
+{
+	struct csky_mbox_chan *mchan = chan->con_priv;
+	struct csky_mbox *mbox = mchan->parent;
+
+	/* enable and ummask interrupt */
+	RX_ENABLE_INTERRUPT(mbox);
+	RX_UNMASK_INTERRUPT(mbox);
+	return 0;
+}
+
+static void csky_mbox_shutdown(struct mbox_chan *chan)
+{
+	struct csky_mbox_chan *mchan = chan->con_priv;
+	struct csky_mbox *mbox = mchan->parent;
+
+	/* disable interrupts */
+	RX_CLEAR_INTERRUPT(mbox);
+	RX_DISABLE_INTERRUPT(mbox);
+	RX_MASK_INTERRUPT(mbox);
+}
+
+static const struct mbox_chan_ops csky_mbox_ops = {
+	.send_data	= csky_mbox_send_data,
+	.startup	= csky_mbox_startup,
+	.shutdown	= csky_mbox_shutdown,
+	.last_tx_done	= NULL,	/* Not needed, only txdone_poll mode needs */
+	.peek_data	= NULL, /* Not needed, interrupt will handle it */
+};
+
+static int csky_mbox_probe(struct platform_device *pdev)
+{
+	struct device_node *node = pdev->dev.of_node;
+	struct device *dev = &pdev->dev;
+	struct csky_mbox *mbox;
+
+	u32 val;
+	int i, err;
+
+	mbox = devm_kzalloc(dev, sizeof(*mbox), GFP_KERNEL);
+	if (!mbox)
+		return -ENOMEM;
+
+	mbox->dev = dev;
+	mbox->chan_num = CSKY_MBOX_MAX_CHAN;
+
+	mbox->mchans = devm_kzalloc(dev,
+		mbox->chan_num * sizeof(*mbox->mchans), GFP_KERNEL);
+	if (!mbox->mchans)
+		return -ENOMEM;
+
+	mbox->chans = devm_kzalloc(dev,
+		mbox->chan_num * sizeof(*mbox->chans), GFP_KERNEL);
+	if (!mbox->chans)
+		return -ENOMEM;
+
+	mbox->irq = platform_get_irq(pdev, 0);
+	if (mbox->irq < 0)
+		return mbox->irq;
+
+	err = device_property_read_u32(dev, "dev-id", &val);
+	if (err) {
+		dev_err(dev, "No 'dev_id' defined in dts\n");
+		return -ENODEV;
+	}
+	if (val != CSKY_MBOX_DEV_ID0 && val != CSKY_MBOX_DEV_ID1) {
+		dev_err(dev, "No such mailbox 'dev_id':%d\n", val);
+		return -ENODEV;
+	}
+	mbox->dev_id = val;
+	mbox->base = of_iomap(node, 0);
+
+	err = devm_request_irq(dev, mbox->irq, csky_mbox_interrupt, 0,
+				dev_name(dev), mbox);
+	if (err) {
+		dev_err(dev, "Failed to register a mailbox IRQ handler: %d\n",
+			err);
+		return -ENODEV;
+	}
+
+	mbox->controller.dev = dev;
+	mbox->controller.ops = &csky_mbox_ops;
+	mbox->controller.chans = &mbox->chans[0];
+	mbox->controller.num_chans = mbox->chan_num;
+	mbox->controller.of_xlate = csky_mbox_xlate;
+	mbox->controller.txdone_irq = true;
+	mbox->controller.txdone_poll = false;
+
+	for (i = 0; i < mbox->chan_num; ++i) {
+		mbox->chans[i].con_priv = &mbox->mchans[i];
+		mbox->mchans[i].parent = mbox;
+	}
+
+	/* Mask and clear all interrupt vectors */
+	RX_DISABLE_INTERRUPT(mbox);
+	RX_MASK_INTERRUPT(mbox);
+	RX_CLEAR_INTERRUPT(mbox);
+
+	err = mbox_controller_register(&mbox->controller);
+	if (err) {
+		dev_err(dev, "Failed to register mailbox-%d %d\n",
+			mbox->dev_id, err);
+		return err;
+	}
+
+	platform_set_drvdata(pdev, mbox);
+	dev_info(dev, "Mailbox enabled\n");
+
+	return 0;
+}
+
+static int csky_mbox_remove(struct platform_device *pdev)
+{
+	struct csky_mbox *mbox = platform_get_drvdata(pdev);
+
+	if (!mbox)
+		return -EINVAL;
+
+	mbox_controller_unregister(&mbox->controller);
+
+	return 0;
+}
+
+static const struct of_device_id csky_mbox_match[] = {
+	{ .compatible = "csky,mailbox-1.0" },
+	{},
+};
+
+MODULE_DEVICE_TABLE(of, csky_mbox_match);
+
+static struct platform_driver csky_mbox_driver = {
+	.probe	= csky_mbox_probe,
+	.remove	= csky_mbox_remove,
+	.driver	= {
+		.name	= DRIVER_NAME,
+		.of_match_table	= csky_mbox_match,
+	},
+};
+
+module_platform_driver(csky_mbox_driver);
+
+MODULE_LICENSE("GPL v2");
+MODULE_DESCRIPTION("C-SKY mailbox specific functions");
+MODULE_AUTHOR("Charles Lu <chongzhi_lu@csky.com>");
diff --git a/addons/drivers/mailbox/mailbox-csky.h b/addons/drivers/mailbox/mailbox-csky.h
new file mode 100644
index 0000000..a84ad42
--- /dev/null
+++ b/addons/drivers/mailbox/mailbox-csky.h
@@ -0,0 +1,68 @@
+/*
+ * mailbox driver for C-SKY's SoCs.
+ *
+ * Copyright (C) 2017 C-SKY MicroSystems Co.,Ltd.
+ * Author: Charles Lu <chongzhi_lu@c-sky.com>
+ *
+ * This software is licensed under the terms of the GNU General Public
+ * License version 2, as published by the Free Software Foundation, and
+ * may be copied, distributed, and modified under those terms.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ */
+
+#ifndef __MAILBOX_CSKY_H
+#define __MAILBOX_CSKY_H
+
+#define CSKY_MBOX_DEV_ID0		0
+#define CSKY_MBOX_DEV_ID1		1
+
+#define CSKY_MBOX_CHAN_0		0
+#define CSKY_MBOX_DIRECTION_TX		0
+#define CSKY_MBOX_DIRECTION_RX		1
+
+#define CSKY_MBOX_MAX_CHAN		1
+#define CSKY_MBOX_MAX_MESSAGE_LENGTH	64	/* u32 x 16 */
+#define CSKY_MBOX_MAX_DATA_LENGTH	(CSKY_MBOX_MAX_MESSAGE_LENGTH - 4)
+
+/* Interrupt Generate Register (R/W)
+ * Write 1 into it, enable interrupt to client immediately.
+ * Write 0 into it, disable interrupt to client immediately.
+ */
+#define CSKY_MBOX_INTGR		0x00
+
+/* Interrupt Clear Register (W1C)
+ * Write 1 into it, clear the
+ */
+#define CSKY_MBOX_INTCR		0x04
+
+/* Interrupt Mask Register (R/W)
+ * 1 means mask interrupt bit
+ * 0 means unmask interrupt bit
+ */
+#define CSKY_MBOX_INTMR		0x08
+
+/* Interrupt Register Status Register (RO)
+ * Read 1 means has interrupt
+ * Read 0 means no interrupt
+ */
+#define CSKY_MBOX_INTRSR	0x0C
+
+/* Interrupt Masked Status Register (RO)
+ * Read 1 means has interrupt on masked bit
+ * Read 0 means no interrupt on masked bit
+ */
+#define CSKY_MBOX_INTMSR	0x10
+
+/* Interrupt Enable (R/W)
+ * 1 means interrupt enabled
+ * 0 means interrupt disabled
+ */
+#define CSKY_MBOX_INTENB	0x14
+
+#endif /* __MAILBOX_CSKY_H */
+
diff --git a/addons/drivers/mailbox/tty-mailbox-client-csky.c b/addons/drivers/mailbox/tty-mailbox-client-csky.c
new file mode 100644
index 0000000..786a7c7
--- /dev/null
+++ b/addons/drivers/mailbox/tty-mailbox-client-csky.c
@@ -0,0 +1,399 @@
+/*
+ * TTY mailbox client driver for C-SKY's SoCs.
+ *
+ * Copyright (C) 2017 C-SKY MicroSystems Co.,Ltd.
+ * Author: Charles Lu <chongzhi_lu@c-sky.com>
+ *
+ * This software is licensed under the terms of the GNU General Public
+ * License version 2, as published by the Free Software Foundation, and
+ * may be copied, distributed, and modified under those terms.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ */
+
+#include <linux/debugfs.h>
+#include <linux/err.h>
+#include <linux/io.h>
+#include <linux/kernel.h>
+#include <linux/mailbox_client.h>
+#include <linux/module.h>
+#include <linux/of.h>
+#include <linux/of_address.h>
+#include <linux/platform_device.h>
+#include <linux/slab.h>
+#include <linux/uaccess.h>
+#include <linux/circ_buf.h>
+
+#include "mailbox-csky.h"
+#include "mailbox-csky-internal.h"
+
+#define MBOX_MAX_MSG_LEN	CSKY_MBOX_MAX_MESSAGE_LENGTH
+#define RX_BUF_SIZE		4096
+
+static struct dentry *root_debugfs_dir;
+
+struct tty_mbox_client_csky_device {
+	struct device		*dev;
+	void __iomem		*tx_mmio;
+	void __iomem		*rx_mmio;
+	struct mbox_chan	*tx_channel;
+	struct mbox_chan	*rx_channel;
+	char			*rx_buffer;
+	uint			rx_head;	/* circular rx buffer head */
+	uint			rx_tail;	/* circular rx buffer tail */
+	struct mbox_message	*message;
+	spinlock_t		lock;
+};
+
+static ssize_t tty_mbox_client_csky_message_write(struct file *filp,
+						  const char __user *userbuf,
+						  size_t count, loff_t *ppos)
+{
+	struct tty_mbox_client_csky_device *tdev = filp->private_data;
+	void *data;
+	uint sent_len = 0;
+	int ret;
+
+	if (!tdev->tx_channel) {
+		dev_err(tdev->dev, "Channel cannot do Tx\n");
+		return -EINVAL;
+	}
+
+	if (tdev->message == NULL) {
+		tdev->message = devm_kzalloc(tdev->dev,
+					     MBOX_MAX_MSG_LEN, GFP_KERNEL);
+		if (tdev->message == NULL)
+			return -ENOMEM;
+	}
+
+	while (sent_len < count) {
+		uint tx_len =
+			((count - sent_len) < CSKY_MBOX_MAX_DATA_LENGTH) ?
+			(count - sent_len) : CSKY_MBOX_MAX_DATA_LENGTH;
+
+		tdev->message->mssg_type = CSKY_MBOX_MSSG_DATA;
+		tdev->message->length = tx_len;
+		ret = copy_from_user(tdev->message->data,
+				     &(userbuf[sent_len]),
+				     MBOX_CSKY_MSSG_HEAD_LENGTH + tx_len);
+
+#ifdef DEBUG
+		print_hex_dump_bytes("Client: Sending: Message: ",
+			DUMP_PREFIX_ADDRESS, tdev->message, MBOX_MAX_MSG_LEN);
+#endif
+		data = tdev->message;
+		ret = mbox_send_message(tdev->tx_channel, data);
+		if (ret < 0) {
+			dev_err(tdev->dev, "Failed to send message\n");
+			return -EIO;
+		}
+		sent_len += tx_len;
+	}
+
+	return sent_len;
+}
+
+static ssize_t tty_mbox_client_csky_message_read(struct file *filp,
+						 char __user *userbuf,
+						 size_t count, loff_t *ppos)
+{
+	struct tty_mbox_client_csky_device *tdev = filp->private_data;
+	uint read_length, rx_buffer_length, rx_cnt_to_end;
+	int ret;
+
+#ifdef DEBUG
+	char touser_debug[32];
+#endif
+
+	if (count == 0) {
+		return 0;
+	}
+
+	if (!tdev->rx_channel) {
+#ifdef DEBUG
+		ret = snprintf(touser_debug, 20, "<NO RX CAPABILITY>\n");
+		ret = simple_read_from_buffer(userbuf, count, ppos,
+					      touser_debug, ret);
+		return ret;
+#else
+		dev_err(tdev->dev, "NO RX CAPABILITY\n");
+		return -ENXIO;
+#endif
+	}
+
+	rx_buffer_length = CIRC_CNT(tdev->rx_head, tdev->rx_tail, RX_BUF_SIZE);
+	if (rx_buffer_length == 0) {
+#ifdef DEBUG
+		ret = snprintf(touser_debug, 9, "<EMPTY>\n");
+		ret = simple_read_from_buffer(userbuf, count, ppos,
+					      touser_debug, ret);
+		return ret;
+#else
+		return 0;
+#endif
+	}
+
+	read_length = min(count, rx_buffer_length);
+
+	rx_cnt_to_end = CIRC_CNT_TO_END(tdev->rx_head,
+					tdev->rx_tail,
+					RX_BUF_SIZE);
+	if (rx_cnt_to_end >= read_length) {
+		/* Copy once */
+		ret = copy_to_user(userbuf,
+				   &(tdev->rx_buffer[tdev->rx_tail]),
+				   read_length);
+		if (ret != 0) {
+			return -EFAULT;
+		}
+		tdev->rx_tail += read_length;
+		return read_length;
+	}
+	else {
+		/* Copy twice */
+		ret = copy_to_user(&(userbuf[0]),
+				   &(tdev->rx_buffer[tdev->rx_tail]),
+				   rx_cnt_to_end);
+		if (ret != 0) {
+			return -EFAULT;
+		}
+
+		ret = copy_to_user(&(userbuf[rx_cnt_to_end]),
+				   &(tdev->rx_buffer[0]),
+				   read_length - rx_cnt_to_end);
+		if (ret != 0) {
+			return -EFAULT;
+		}
+
+		tdev->rx_tail = read_length - rx_cnt_to_end;
+		return read_length;
+	}
+}
+
+static const struct file_operations tty_mbox_client_csky_message_ops = {
+	.write	= tty_mbox_client_csky_message_write,
+	.read	= tty_mbox_client_csky_message_read,
+	.open	= simple_open,
+	.llseek	= generic_file_llseek,
+};
+
+static int index_names = 0;
+static bool debugfs_dir_created = false;
+static const char* file_names[] = {"ttym-client0", "ttym-client1"};
+
+static int
+tty_mbox_client_csky_add_debugfs(struct platform_device *pdev,
+				 struct tty_mbox_client_csky_device *tdev)
+{
+	if (!debugfs_initialized())
+		return 0;
+
+	if (index_names > 2) {
+		dev_err(&pdev->dev, "Max device index is 2\n");
+		return 0;
+	}
+
+	if (!debugfs_dir_created) {
+		root_debugfs_dir = debugfs_create_dir("mailbox", NULL);
+		if (!root_debugfs_dir) {
+			dev_err(&pdev->dev,
+				"Failed to create mailbox debugfs\n");
+			return -EINVAL;
+		}
+		debugfs_dir_created = true;
+	}
+
+	debugfs_create_file(file_names[index_names], 0600, root_debugfs_dir,
+			    tdev, &tty_mbox_client_csky_message_ops);
+
+	index_names++;
+	return 0;
+}
+
+static void tty_mbox_client_csky_receive_message(struct mbox_client *client,
+						 void *message)
+{
+	struct tty_mbox_client_csky_device *tdev =
+		dev_get_drvdata(client->dev);
+	unsigned long flags;
+	struct mbox_message mssg;
+	uint rx_buffer_space, copy_len;
+
+	if (tdev->rx_mmio == NULL) {
+		dev_err(client->dev, "rx_mmio is NULL\n");
+		return;
+	}
+
+	spin_lock_irqsave(&tdev->lock, flags);
+	memcpy(&mssg, (struct mbox_message*)(tdev->rx_mmio), sizeof(mssg));
+	rx_buffer_space = CIRC_SPACE(tdev->rx_head,
+				     tdev->rx_tail,
+				     RX_BUF_SIZE);
+
+	copy_len = (rx_buffer_space < mssg.length) ?
+		   rx_buffer_space : mssg.length;
+
+	if (copy_len) {
+		uint space_to_end = CIRC_SPACE_TO_END(tdev->rx_head,
+						      tdev->rx_tail,
+						      RX_BUF_SIZE);
+
+		if (copy_len <= space_to_end) {
+			/* head to end has enough space, copy once */
+			memcpy(tdev->rx_buffer + tdev->rx_head,
+			       &(mssg.data[0]),
+			       copy_len);
+			tdev->rx_head = (tdev->rx_head + copy_len) &
+					(RX_BUF_SIZE - 1);
+		}
+		else {
+			/* head to end has not enough space, copy twice */
+			uint len_from_buffer = copy_len - space_to_end;
+			memcpy(tdev->rx_buffer + tdev->rx_head,
+			       &(mssg.data[0]),
+			       space_to_end);
+
+			memcpy(tdev->rx_buffer,
+			       &(mssg.data[space_to_end]),
+			       len_from_buffer);
+			tdev->rx_head = (len_from_buffer) & (RX_BUF_SIZE - 1);
+		}
+	}
+	spin_unlock_irqrestore(&tdev->lock, flags);
+}
+
+static void tty_mbox_client_csky_prepare_message(struct mbox_client *client,
+						 void *message)
+{
+	struct tty_mbox_client_csky_device *tdev =
+		dev_get_drvdata(client->dev);
+
+	if (tdev->tx_mmio) {
+		memcpy_toio(tdev->tx_mmio, message, MBOX_MAX_MSG_LEN);
+	}
+}
+
+static void tty_mbox_client_csky_message_sent(struct mbox_client *client,
+					      void *message, int r)
+{
+	if (r) {
+		dev_warn(client->dev,
+			 "Client: Message could not be sent: %d\n", r);
+	}
+	else {
+#ifdef DEBUG
+		dev_info(client->dev, "Client: Message sent\n");
+#endif
+	}
+}
+
+static struct mbox_chan *
+tty_mbox_client_csky_request_channel(struct platform_device *pdev,
+				     const char *name)
+{
+	struct mbox_client *client;
+	struct mbox_chan *channel;
+
+	client = devm_kzalloc(&pdev->dev, sizeof(*client), GFP_KERNEL);
+	if (!client)
+		return ERR_PTR(-ENOMEM);
+
+	client->dev		= &pdev->dev;
+	client->rx_callback	= tty_mbox_client_csky_receive_message;
+	client->tx_prepare	= tty_mbox_client_csky_prepare_message;
+	client->tx_done		= tty_mbox_client_csky_message_sent;
+	client->tx_block	= true;
+	client->knows_txdone	= true;
+	client->tx_tout		= 500;
+
+	channel = mbox_request_channel_byname(client, name);
+	if (IS_ERR(channel)) {
+		devm_kfree(&pdev->dev, client);
+		dev_warn(&pdev->dev, "Failed to request %s channel\n", name);
+		return NULL;
+	}
+
+	return channel;
+}
+
+static int tty_mbox_client_csky_probe(struct platform_device *pdev)
+{
+	struct device_node *node = pdev->dev.of_node;
+	struct tty_mbox_client_csky_device *tdev;
+	int ret;
+
+	tdev = devm_kzalloc(&pdev->dev, sizeof(*tdev), GFP_KERNEL);
+	if (!tdev)
+		return -ENOMEM;
+
+	tdev->tx_mmio = of_iomap(node, 0);
+	tdev->rx_mmio = of_iomap(node, 1);
+
+	tdev->tx_channel = tty_mbox_client_csky_request_channel(pdev,
+								"channel");
+	if (!tdev->tx_channel) {
+		dev_err(&pdev->dev, "Request channel failed\n");
+		return -EPROBE_DEFER;
+	}
+	/* In fact, rx_channel is same with tx_channel in C-SKY's mailbox */
+	tdev->rx_channel = tdev->tx_channel;
+
+	tdev->dev = &pdev->dev;
+	platform_set_drvdata(pdev, tdev);
+
+	spin_lock_init(&tdev->lock);
+
+	tdev->rx_buffer = devm_kzalloc(&pdev->dev, RX_BUF_SIZE, GFP_KERNEL);
+	if (!tdev->rx_buffer)
+		return -ENOMEM;
+	tdev->rx_head = 0;
+	tdev->rx_tail = 0;
+
+	ret = tty_mbox_client_csky_add_debugfs(pdev, tdev);
+	if (ret)
+		return ret;
+
+	dev_info(&pdev->dev, "Successfully registered\n");
+
+	return 0;
+}
+
+static int tty_mbox_client_csky_remove(struct platform_device *pdev)
+{
+	struct tty_mbox_client_csky_device *tdev = platform_get_drvdata(pdev);
+
+	debugfs_remove_recursive(root_debugfs_dir);
+
+	if (tdev->tx_channel)
+		mbox_free_channel(tdev->tx_channel);
+
+	if (tdev->rx_channel && tdev->rx_channel != tdev->tx_channel)
+		mbox_free_channel(tdev->rx_channel);
+
+	if (tdev->message)
+		devm_kfree(tdev->dev, tdev->message);
+	return 0;
+}
+
+static const struct of_device_id tty_mbox_client_csky_match[] = {
+	{ .compatible = "csky,tty-mailbox-client" },
+	{},
+};
+
+static struct platform_driver tty_mbox_client_csky_driver = {
+	.driver = {
+		.name = "csky,tty-mailbox-client",
+		.of_match_table = tty_mbox_client_csky_match,
+	},
+	.probe  = tty_mbox_client_csky_probe,
+	.remove = tty_mbox_client_csky_remove,
+};
+module_platform_driver(tty_mbox_client_csky_driver);
+
+MODULE_DESCRIPTION("CSKY TTY Mailbox Client driver");
+MODULE_AUTHOR("Charles Lu <chongzhi_lu@c-sky.com");
+MODULE_LICENSE("GPL v2");
diff --git a/addons/drivers/mailbox/tty-mailbox-csky.c b/addons/drivers/mailbox/tty-mailbox-csky.c
new file mode 100644
index 0000000..83ffbfc
--- /dev/null
+++ b/addons/drivers/mailbox/tty-mailbox-csky.c
@@ -0,0 +1,460 @@
+/*
+ * TTY based on C-SKY mailbox driver for C-SKY's SoCs.
+ *
+ * Copyright (C) 2017 C-SKY MicroSystems Co.,Ltd.
+ * Author: Charles Lu <chongzhi_lu@c-sky.com>
+ *
+ * This software is licensed under the terms of the GNU General Public
+ * License version 2, as published by the Free Software Foundation, and
+ * may be copied, distributed, and modified under those terms.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ */
+
+#include <linux/device.h>
+#include <linux/interrupt.h>
+#include <linux/io.h>
+#include <linux/kernel.h>
+#include <linux/mailbox_client.h>
+#include <linux/module.h>
+#include <linux/of.h>
+#include <linux/of_address.h>
+#include <linux/platform_device.h>
+
+#include <linux/slab.h>
+#include <linux/tty.h>
+#include <linux/tty_driver.h>
+#include <linux/tty_flip.h>
+#include <linux/circ_buf.h>
+
+#include "mailbox-csky.h"
+#include "mailbox-csky-internal.h"
+
+#define MBOX_MAX_MSG_LEN	CSKY_MBOX_MAX_MESSAGE_LENGTH
+#define TTY_MBOX_DRIVER_NAME	"ttym"
+#define TTY_MBOX_MAJOR		0	/* Let kernel decides */
+#define TTY_MBOX_MAX_CONSOLES	1	/* Only 1 supported, don't try more */
+
+#define BUF_SIZE	2048	/* This must be a power of two */
+
+static const struct of_device_id csky_ttym_match[];
+
+struct ttym_data {
+	struct device		*dev;
+	spinlock_t		lock;		/* lock when send buffer */
+	struct mutex		mtx;		/* unlock when recv data */
+
+	struct tty_driver	*tty_driver;
+	struct tty_port		tty_port;
+
+	bool			rx_throttle;
+	void __iomem		*tx_mmio;
+	void __iomem		*rx_mmio;
+	struct mbox_chan	*tx_channel;
+	struct mbox_chan	*rx_channel;
+	struct mbox_message	*tx_buffer;
+	char			*rx_buffer;
+	bool			tx_sent;	/* Tx message has been sent */
+
+#if 0
+	u8			buf[BUF_SIZE];	/* transmit circular buffer */
+	u8			head;		/* circular buffer head */
+	u8			tail;		/* circular buffer tail */
+#endif
+};
+
+static struct tty_driver *s_ttym_driver;
+static struct ttym_data  *s_ttym_data;		/* only one ttym supported */
+
+static int ttym_open(struct tty_struct *ttys, struct file *filp)
+{
+	struct ttym_data *ttymd = s_ttym_data;
+
+	if (!ttymd->dev)
+		return -ENODEV;
+
+	return tty_port_open(&ttymd->tty_port, ttys, filp);
+}
+
+static void ttym_close(struct tty_struct *ttys, struct file *filp)
+{
+	struct ttym_data *ttymd = s_ttym_data;
+
+	if (ttymd->dev)
+		tty_port_close(&ttymd->tty_port, ttys, filp);
+}
+
+/*
+ * This function is called when the tty layer has data for us send.
+ */
+static int ttym_write(struct tty_struct *ttys, const unsigned char *s,
+		      int count)
+{
+	struct ttym_data *ttymd = ttys->driver_data;
+	uint copy_len;
+	uint written = 0;
+	int ret;
+
+	if (!ttymd->tx_channel) {
+		dev_err(ttymd->dev, "Channel cannot do Tx\n");
+		return -EINVAL;
+	}
+
+	if (!ttymd->tx_sent) {
+		dev_warn(ttymd->dev, "Tx message has not sent yet\n");
+		return 0;
+	}
+
+	written = (count <= CSKY_MBOX_MAX_DATA_LENGTH) ?
+		count : CSKY_MBOX_MAX_DATA_LENGTH;
+
+	ttymd->tx_buffer->mssg_type = CSKY_MBOX_MSSG_DATA;
+	ttymd->tx_buffer->length = written;	/* Payload len without head */
+	/* Align copy_len with 4, because IO only accept 4Bytes aligned data */
+	copy_len = (MBOX_CSKY_MSSG_HEAD_LENGTH + written + 3) & 0xFFFFFFFC;
+	memcpy(ttymd->tx_buffer->data, s, copy_len);
+
+#ifdef DEBUG
+	print_hex_dump_bytes("Client: Sending: Message: ",
+		DUMP_PREFIX_ADDRESS, ttymd->tx_buffer, MBOX_MAX_MSG_LEN);
+#endif
+
+	ret = mbox_send_message(ttymd->tx_channel, ttymd->tx_buffer);
+	if (ret < 0)
+		dev_err(ttymd->dev, "Failed to send message via mailbox\n");
+
+	return ret < 0 ? ret : written;
+}
+
+static int ttym_write_room(struct tty_struct *ttys)
+{
+	struct ttym_data *ttymd = ttys->driver_data;
+	int count = ttymd->tx_sent ? CSKY_MBOX_MAX_DATA_LENGTH : 0;
+
+	return count;
+}
+
+static void ttym_throttle(struct tty_struct *ttys)
+{
+	struct ttym_data *ttymd = ttys->driver_data;
+	ttymd->rx_throttle = true;
+}
+
+static void ttym_unthrottle(struct tty_struct *ttys)
+{
+	struct ttym_data *ttymd = ttys->driver_data;
+	ttymd->rx_throttle = false;
+}
+
+static void ttym_hangup(struct tty_struct *ttys)
+{
+	struct ttym_data *ttymd = ttys->driver_data;
+	tty_port_hangup(&ttymd->tty_port);
+}
+
+/*
+ * TTY driver operations
+ *
+ * If we could ask the hypervisor how much data is still in the TX buffer, or
+ * at least how big the TX buffers are, then we could implement the
+ * .wait_until_sent and .chars_in_buffer functions.
+ */
+static const struct tty_operations ttym_ops = {
+	.open		= ttym_open,
+	.close		= ttym_close,
+	.write		= ttym_write,
+	.write_room	= ttym_write_room,
+	.throttle	= ttym_throttle,
+	.unthrottle	= ttym_unthrottle,
+	.hangup		= ttym_hangup,
+};
+
+static void csky_ttym_mbox_client_receive_message(struct mbox_client *client,
+						  void *message)
+{
+	struct ttym_data *ttymd = dev_get_drvdata(client->dev);
+	if (ttymd == NULL) {
+		return;
+	}
+	struct mbox_message *mssg = (struct mbox_message *)ttymd->rx_buffer;
+	int count, ret;
+	ulong flags;
+
+	if (ttymd->rx_throttle) {
+		return;
+	}
+
+	if (ttymd->rx_mmio == NULL) {
+		dev_err(client->dev, "rx_mmio is NULL\n");
+		return;
+	}
+
+	spin_lock_irqsave(&ttymd->lock, flags);
+	memcpy_fromio(ttymd->rx_buffer, ttymd->rx_mmio, MBOX_MAX_MSG_LEN);
+	spin_unlock_irqrestore(&ttymd->lock, flags);
+
+
+#ifdef DEBUG
+	print_hex_dump_bytes("Client: Received: ", DUMP_PREFIX_ADDRESS,
+			     ttymd->rx_buffer, MBOX_MAX_MSG_LEN);
+#endif
+
+	count = tty_buffer_request_room(&ttymd->tty_port, mssg->length);
+	if (count != mssg->length) {
+		dev_err(client->dev, "tty buffer request %dB room failed\n",
+			mssg->length);
+		return;
+	}
+	ret = tty_insert_flip_string(&ttymd->tty_port, mssg->data, count);
+	if (ret != count) {
+		dev_err(client->dev, "Insert %dB but copied %dB\n",
+			count, ret);
+	}
+
+	tty_flip_buffer_push(&ttymd->tty_port);
+}
+
+static void csky_ttym_mbox_client_prepare_message(struct mbox_client *client,
+						  void *message)
+{
+	struct ttym_data *ttymd = dev_get_drvdata(client->dev);
+
+	if (ttymd->tx_mmio) {
+		memcpy_toio(ttymd->tx_mmio, message, MBOX_MAX_MSG_LEN);
+	}
+}
+
+static void csky_ttym_mbox_client_message_sent(struct mbox_client *client,
+					       void *message, int r)
+{
+	struct ttym_data *ttymd = dev_get_drvdata(client->dev);
+	if (r) {
+		dev_warn(client->dev,
+			 "Client: Message could not be sent: %d\n", r);
+	}
+	else {
+#ifdef DEBUG
+		dev_info(client->dev, "Client: Message sent\n");
+#endif
+	}
+	ttymd->tx_sent = true;	/* Set to be true anyway */
+	tty_port_tty_wakeup(&ttymd->tty_port);
+}
+
+static struct mbox_chan *
+csky_ttym_mbox_client_request_channel(struct platform_device *pdev,
+				      const char *name)
+{
+	struct mbox_client *client;
+	struct mbox_chan *channel;
+
+	client = devm_kzalloc(&pdev->dev, sizeof(*client), GFP_KERNEL);
+	if (!client)
+		return ERR_PTR(-ENOMEM);
+
+	client->dev		= &pdev->dev;
+	client->rx_callback	= csky_ttym_mbox_client_receive_message;
+	client->tx_prepare	= csky_ttym_mbox_client_prepare_message;
+	client->tx_done		= csky_ttym_mbox_client_message_sent;
+	client->tx_block	= true;
+	client->knows_txdone	= true;
+	client->tx_tout		= 1000;
+
+	channel = mbox_request_channel_byname(client, name);
+	if (IS_ERR(channel)) {
+		devm_kfree(&pdev->dev, client);
+		dev_warn(&pdev->dev, "Failed to request %s channel\n", name);
+		return NULL;
+	}
+
+	return channel;
+}
+
+/*
+ * initialize the TTY port
+ *
+ * This function will only be called once, no matter how many times
+ * csky_ttym_open() is called.  That's why we register the ISR here, and also
+ * why we initialize tty_struct-related variables here.
+ */
+static int csky_ttym_port_activate(struct tty_port *port,
+				   struct tty_struct *ttys)
+{
+	struct ttym_data *ttymd = container_of(port,
+					       struct ttym_data, tty_port);
+	ttys->driver_data = ttymd;
+	dev_info(ttymd->dev, "ttym port activated\n");
+	return 0;
+}
+
+/*
+ * The port is being closed by the last user.
+ * Do any hardware specific stuff here
+ */
+static void csky_ttym_port_shutdown(struct tty_port *port)
+{
+	struct ttym_data *ttymd = container_of(port,
+					       struct ttym_data, tty_port);
+	dev_info(ttymd->dev, "ttym port shutdown\n");
+}
+
+static const struct tty_port_operations csky_ttym_port_ops = {
+	.activate = csky_ttym_port_activate,
+	.shutdown = csky_ttym_port_shutdown,
+};
+
+static int csky_ttym_probe(struct platform_device *pdev)
+{
+	struct device_node *node = pdev->dev.of_node;
+	struct device *dev = &pdev->dev;
+	struct device_node *np;
+	uint count = 0;
+
+	int ret;
+
+	/* Count the number of byte channels */
+	for_each_compatible_node(np, NULL, csky_ttym_match[0].compatible)
+				 count++;
+
+	if (count == 0 || count > TTY_MBOX_MAX_CONSOLES) {
+		dev_err(dev, "Max %d mtty support, but now %d\n",
+			TTY_MBOX_MAX_CONSOLES, count);
+		return -ENODEV;
+	}
+
+	/* Allocate memorys */
+	s_ttym_driver = alloc_tty_driver(1);
+	if (!s_ttym_driver) {
+		ret = -ENOMEM;
+		goto error;
+	}
+
+	s_ttym_data = devm_kzalloc(&pdev->dev,
+				   sizeof(struct ttym_data), GFP_KERNEL);
+	if (!s_ttym_data) {
+		ret = -ENOMEM;
+		goto error;
+	}
+
+	s_ttym_data->tx_buffer = devm_kzalloc(&pdev->dev,
+					      MBOX_MAX_MSG_LEN, GFP_KERNEL);
+	if (!s_ttym_data->tx_buffer) {
+		ret = -ENOMEM;
+		goto error;
+	}
+
+	s_ttym_data->rx_buffer = devm_kzalloc(&pdev->dev,
+					      MBOX_MAX_MSG_LEN, GFP_KERNEL);
+	if (!s_ttym_data->rx_buffer) {
+		ret = -ENOMEM;
+		goto error;
+	}
+
+	/* Initialize the tty driver */
+	s_ttym_driver->owner = THIS_MODULE;
+	s_ttym_driver->driver_name = TTY_MBOX_DRIVER_NAME;
+	s_ttym_driver->name = "ttym";
+	s_ttym_driver->major = TTY_MBOX_MAJOR,
+	s_ttym_driver->type = TTY_DRIVER_TYPE_CONSOLE,
+	s_ttym_driver->subtype = SYSTEM_TYPE_CONSOLE,
+	s_ttym_driver->flags = TTY_DRIVER_REAL_RAW | TTY_DRIVER_DYNAMIC_DEV,
+	s_ttym_driver->init_termios = tty_std_termios;
+	tty_set_operations(s_ttym_driver, &ttym_ops);
+
+	ret = tty_register_driver(s_ttym_driver);
+	if (ret) {
+		dev_info(dev, "Could not register ttym driver, ret=%d\n", ret);
+		goto error;
+	}
+
+	/* Initialize the s_ttym_data */
+	spin_lock_init(&s_ttym_data->lock);
+	mutex_init(&s_ttym_data->mtx);
+	s_ttym_data->tty_driver = s_ttym_driver;
+
+	tty_port_init(&s_ttym_data->tty_port);
+	s_ttym_data->tty_port.ops = &csky_ttym_port_ops;
+	s_ttym_data->dev = tty_port_register_device(&s_ttym_data->tty_port,
+		s_ttym_driver, 0, &pdev->dev);
+	if (IS_ERR(s_ttym_data->dev)) {
+		ret = PTR_ERR(s_ttym_data->dev);
+		dev_err(&pdev->dev, "could not register ttym (ret=%i)\n", ret);
+		goto error;
+	}
+
+	s_ttym_data->rx_throttle = false;
+	s_ttym_data->tx_mmio = of_iomap(node, 0);
+	s_ttym_data->rx_mmio = of_iomap(node, 1);
+	s_ttym_data->tx_channel =
+		csky_ttym_mbox_client_request_channel(pdev, "channel");
+	if (!s_ttym_data->tx_channel) {
+		dev_err(&pdev->dev, "Request maiblox channel failed\n");
+		return -EPROBE_DEFER;
+	}
+	/* In fact, rx_channel is same with tx_channel in C-SKY's mailbox */
+	s_ttym_data->rx_channel = s_ttym_data->tx_channel;
+	s_ttym_data->tx_sent = true;
+
+	dev_set_drvdata(&pdev->dev, s_ttym_data);
+
+	dev_info(dev, "tty based on mailbox enabled\n");
+	return 0;
+
+error:
+	if (s_ttym_driver) {
+		tty_unregister_driver(s_ttym_driver);
+		put_tty_driver(s_ttym_driver);
+	}
+
+	tty_port_destroy(&s_ttym_data->tty_port);
+	devm_kfree(&pdev->dev, s_ttym_data->tx_buffer);
+	devm_kfree(&pdev->dev, s_ttym_data->rx_buffer);
+	devm_kfree(&pdev->dev, s_ttym_data);
+	s_ttym_data = NULL;
+
+	return ret;
+}
+
+static int csky_ttym_remove(struct platform_device *pdev)
+{
+	struct device *dev = &pdev->dev;
+
+	tty_unregister_device(s_ttym_driver, 0);
+	tty_unregister_driver(s_ttym_driver);
+	put_tty_driver(s_ttym_driver);
+
+	if(s_ttym_data->tty_port.count)
+		csky_ttym_port_shutdown(&s_ttym_data->tty_port);
+	tty_port_destroy(&s_ttym_data->tty_port);
+	kfree(s_ttym_data);
+	s_ttym_data = NULL;
+
+	dev_info(dev, "tty based on mailbox removed\n");
+	return 0;
+}
+
+static const struct of_device_id csky_ttym_match[] = {
+	{ .compatible = "csky,tty_mailbox" },
+	{},
+};
+
+MODULE_DEVICE_TABLE(of, csky_ttym_match);
+
+static struct platform_driver csky_ttym_driver = {
+	.probe	= csky_ttym_probe,
+	.remove	= csky_ttym_remove,
+	.driver	= {
+		.name	= TTY_MBOX_DRIVER_NAME,
+		.of_match_table	= csky_ttym_match,
+	},
+};
+
+module_platform_driver(csky_ttym_driver);
+
+MODULE_LICENSE("GPL v2");
+MODULE_DESCRIPTION("TTY based on C-SKY mailbox specific functions");
+MODULE_AUTHOR("Charles Lu <chongzhi_lu@csky.com>");
diff --git a/addons/drivers/pinctrl/Kconfig b/addons/drivers/pinctrl/Kconfig
new file mode 100644
index 0000000..7c05bfa
--- /dev/null
+++ b/addons/drivers/pinctrl/Kconfig
@@ -0,0 +1,22 @@
+#
+# C-SKY Pin control drivers
+#
+
+menu "Pin Controllers"
+
+config DEBUG_PINCTRL
+	bool "Debug PINCTRL calls"
+	depends on DEBUG_KERNEL
+	help
+	  Say Y here to add some extra checks and diagnostics to PINCTRL calls.
+
+config PINCTRL_CSKY
+	bool "C-SKY pinctrl driver"
+	depends on OF
+	select PINCTRL
+	select PINMUX
+	select PINCONF
+	select GPIOLIB
+
+endmenu
+
diff --git a/addons/drivers/pinctrl/Makefile b/addons/drivers/pinctrl/Makefile
new file mode 100644
index 0000000..1017632
--- /dev/null
+++ b/addons/drivers/pinctrl/Makefile
@@ -0,0 +1,4 @@
+# C-SKY pin control drivers
+
+obj-$(CONFIG_PINCTRL_CSKY)	+= pinctrl-csky.o
+
diff --git a/addons/drivers/pinctrl/pinctrl-csky.c b/addons/drivers/pinctrl/pinctrl-csky.c
new file mode 100644
index 0000000..7c1ff29
--- /dev/null
+++ b/addons/drivers/pinctrl/pinctrl-csky.c
@@ -0,0 +1,1349 @@
+/*
+ * pin-controller/pin-mux/pin-config/gpio-driver for C-SKY's SoCs.
+ *
+ * Copyright (C) 2017 C-SKY MicroSystems Co.,Ltd.
+ * Author: Charles Lu <chongzhi_lu@c-sky.com>
+ *
+ * This software is licensed under the terms of the GNU General Public
+ * License version 2, as published by the Free Software Foundation, and
+ * may be copied, distributed, and modified under those terms.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ */
+
+#include <linux/init.h>
+#include <linux/platform_device.h>
+#include <linux/io.h>
+#include <linux/bitops.h>
+#include <linux/gpio.h>
+#include <linux/of_address.h>
+#include <linux/of_irq.h>
+#include <linux/pinctrl/machine.h>
+#include <linux/pinctrl/pinconf.h>
+#include <linux/pinctrl/pinctrl.h>
+#include <linux/pinctrl/pinmux.h>
+#include <linux/pinctrl/pinconf-generic.h>
+#include <linux/irqchip/chained_irq.h>
+#include <linux/regmap.h>
+#include <linux/mfd/syscon.h>
+
+#include <../../../drivers/pinctrl/core.h>
+#include <../../../drivers/pinctrl/pinconf.h>
+
+#include "pinctrl-csky.h"
+
+
+/* GPIO control registers */
+#define GPIO_SWPORT_DR		0x00
+#define GPIO_SWPORT_DDR		0x04
+#define GPIO_PORT_CTL		0x08
+#define GPIO_INTEN		0x30
+#define GPIO_INTMASK		0x34
+#define GPIO_INTTYPE_LEVEL	0x38
+#define GPIO_INT_POLARITY	0x3c
+#define GPIO_INT_STATUS		0x40
+#define GPIO_INT_RAWSTATUS	0x44
+#define GPIO_DEBOUNCE		0x48
+#define GPIO_PORTS_EOI		0x4c
+#define GPIO_EXT_PORT		0x50
+#define GPIO_LS_SYNC		0x60
+
+/* GPIO irq numbers */
+#define GPIO0_IRQS 0
+#define GPIO1_IRQS 1
+#define GPIO2_IRQS 2
+#define GPIO3_IRQS 3
+
+
+
+enum csky_pinctrl_type {
+	ERAGON,
+};
+
+/**
+ * @reg_base: register base of the gpio bank
+ * @reg_pull: optional separate register for additional pull settings
+ * @irq: interrupt of the gpio bank
+ * @saved_masks: Saved content of GPIO_INTEN at suspend time.
+ * @pin_base: first pin number
+ * @nr_pins: number of pins in this bank
+ * @name: name of the bank
+ * @bank_num: number of the bank, to account for holes
+ * @iomux: array describing the 4 iomux sources of the bank
+ * @drv: array describing the 4 drive strength sources of the bank
+ * @pull_type: array describing the 4 pull type sources of the bank
+ * @valid: are all necessary informations present
+ * @of_node: dt node of this bank
+ * @drvdata: common pinctrl basedata
+ * @domain: irqdomain of the gpio bank
+ * @gpio_chip: gpiolib chip
+ * @grange: gpio range
+ * @slock: spinlock for the gpio bank
+ */
+struct csky_pin_bank {
+	void __iomem			*reg_base;
+	struct regmap			*regmap_pull;
+	int				irq;
+	u32				saved_masks;
+	u32				pin_base;
+	u8				nr_pins;
+	char				*name;
+	u8				bank_num;
+	bool				valid;
+	struct device_node		*of_node;
+	struct csky_pinctrl		*drvdata;
+	struct irq_domain		*domain;
+	struct gpio_chip		gpio_chip;
+	struct pinctrl_gpio_range	grange;
+	spinlock_t			slock;
+	u32				toggle_edge_mode;
+};
+
+#define PIN_BANK(id, pins, label)		\
+	{					\
+		.bank_num	= id,		\
+		.nr_pins	= pins,		\
+		.name		= label,	\
+	}
+
+struct csky_pin_ctrl {
+	struct csky_pin_bank	*pin_banks;
+	u32			nr_banks;
+	u32			nr_pins;
+	char			*label;
+	enum csky_pinctrl_type	type;
+	u32			mux_regs[4];
+};
+
+struct csky_pin_config {
+	unsigned int		func;
+	unsigned long		*configs;
+	unsigned int		nconfigs;
+};
+
+/**
+ * struct csky_pin_group: represent group of pins of a pinmux function.
+ * @name: name of the pin group, used to lookup the group.
+ * @pins: the pins included in this group.
+ * @npins: number of pins included in this group.
+ * @func: the mux function number to be programmed when selected.
+ * @configs: the config values to be set for each pin
+ * @nconfigs: number of configs for each pin
+ */
+struct csky_pin_group {
+	const char		*name;
+	unsigned int		npins;
+	unsigned int		*pins;
+	struct csky_pin_config	*data;
+};
+
+/**
+ * struct csky_pmx_func: represent a pin function.
+ * @name: name of the pin function, used to lookup the function.
+ * @groups: one or more names of pin groups that provide this function.
+ * @num_groups: number of groups included in @groups.
+ */
+struct csky_pmx_func {
+	const char		*name;
+	const char		**groups;
+	u8			ngroups;
+};
+
+struct csky_pinctrl {
+	struct device		*dev;
+	struct csky_pin_ctrl	*ctrl;
+	struct pinctrl_desc	pctl;
+	struct pinctrl_dev	*pctl_dev;
+	struct csky_pin_group	*groups;
+	unsigned int		ngroups;
+	struct csky_pmx_func	*functions;
+	unsigned int		nfunctions;
+};
+
+static inline const struct csky_pin_group *pinctrl_name_to_group(
+					const struct csky_pinctrl *info,
+					const char *name)
+{
+	int i;
+
+	for (i = 0; i < info->ngroups; i++) {
+		if (!strcmp(info->groups[i].name, name))
+			return &info->groups[i];
+	}
+
+	return NULL;
+}
+
+/*
+ * given a pin number that is local to a pin controller, find out the pin bank
+ * and the register base of the pin bank.
+ */
+static struct csky_pin_bank *pin_to_bank(struct csky_pinctrl *info,
+					 unsigned pin)
+{
+	struct csky_pin_bank *b = info->ctrl->pin_banks;
+
+	while (pin >= (b->pin_base + b->nr_pins))
+		b++;
+
+	return b;
+}
+
+static struct csky_pin_bank *bank_num_to_bank(struct csky_pinctrl *info,
+					      unsigned num)
+{
+	struct csky_pin_bank *b = info->ctrl->pin_banks;
+	int i;
+
+	for (i = 0; i < info->ctrl->nr_banks; i++, b++) {
+		if (b->bank_num == num)
+			return b;
+	}
+
+	return ERR_PTR(-EINVAL);
+}
+
+/*
+ * Pinctrl_ops handling
+ */
+
+static int csky_get_groups_count(struct pinctrl_dev *pctldev)
+{
+	struct csky_pinctrl *info = pinctrl_dev_get_drvdata(pctldev);
+
+	return info->ngroups;
+}
+
+static const char *csky_get_group_name(struct pinctrl_dev *pctldev,
+				       unsigned selector)
+{
+	struct csky_pinctrl *info = pinctrl_dev_get_drvdata(pctldev);
+
+	return info->groups[selector].name;
+}
+
+static int csky_get_group_pins(struct pinctrl_dev *pctldev,
+			       unsigned selector,
+			       const unsigned **pins,
+			       unsigned *npins)
+{
+	struct csky_pinctrl *info = pinctrl_dev_get_drvdata(pctldev);
+
+	if (selector >= info->ngroups)
+		return -EINVAL;
+
+	*pins = info->groups[selector].pins;
+	*npins = info->groups[selector].npins;
+
+	return 0;
+}
+
+static int csky_dt_node_to_map(struct pinctrl_dev *pctldev,
+			       struct device_node *np,
+			       struct pinctrl_map **map, unsigned *num_maps)
+{
+	struct csky_pinctrl *info = pinctrl_dev_get_drvdata(pctldev);
+	const struct csky_pin_group *grp;
+	struct pinctrl_map *new_map;
+	struct device_node *parent;
+	int map_num = 1;
+	int i;
+
+	/*
+	 * first find the group of this node and check if we need to create
+	 * config maps for pins
+	 */
+	grp = pinctrl_name_to_group(info, np->name);
+	if (!grp) {
+		dev_err(info->dev, "unable to find group for node %s\n",
+			np->name);
+		return -EINVAL;
+	}
+
+	map_num += grp->npins;
+	new_map = devm_kzalloc(pctldev->dev, sizeof(*new_map) * map_num,
+				GFP_KERNEL);
+	if (!new_map)
+		return -ENOMEM;
+
+	*map = new_map;
+	*num_maps = map_num;
+
+	/* create mux map */
+	parent = of_get_parent(np);
+	if (!parent) {
+		devm_kfree(pctldev->dev, new_map);
+		return -EINVAL;
+	}
+	new_map[0].type = PIN_MAP_TYPE_MUX_GROUP;
+	new_map[0].data.mux.function = parent->name;
+	new_map[0].data.mux.group = np->name;
+	of_node_put(parent);
+
+	/* create config map */
+	new_map++;
+	for (i = 0; i < grp->npins; i++) {
+		new_map[i].type = PIN_MAP_TYPE_CONFIGS_PIN;
+		new_map[i].data.configs.group_or_pin =
+				pin_get_name(pctldev, grp->pins[i]);
+		new_map[i].data.configs.configs = grp->data[i].configs;
+		new_map[i].data.configs.num_configs = grp->data[i].nconfigs;
+	}
+
+	dev_dbg(pctldev->dev, "maps: function %s group %s num %d\n",
+		(*map)->data.mux.function, (*map)->data.mux.group, map_num);
+
+	return 0;
+}
+
+static void csky_dt_free_map(struct pinctrl_dev *pctldev,
+			     struct pinctrl_map *map, unsigned num_maps)
+{
+}
+
+static const struct pinctrl_ops csky_pctrl_ops = {
+	.get_groups_count	= csky_get_groups_count,
+	.get_group_name		= csky_get_group_name,
+	.get_group_pins		= csky_get_group_pins,
+	.dt_node_to_map		= csky_dt_node_to_map,
+	.dt_free_map		= csky_dt_free_map,
+};
+
+/*
+ * Hardware access
+ */
+
+static int csky_get_mux(struct csky_pin_bank *bank, int pin)
+{
+	return 0;
+}
+
+/*
+ * Set a new mux function for a pin.
+ *
+ * The register is divided into the upper and lower 16 bit. When changing
+ * a value, the previous register value is not read and changed. Instead
+ * it seems the changed bits are marked in the upper 16 bit, while the
+ * changed value gets set in the same offset in the lower 16 bit.
+ * All pin settings seem to be 2 bit wide in both the upper and lower
+ * parts.
+ * @bank: pin bank to change
+ * @pin: pin to change
+ * @mux: new mux function to set
+ */
+static int csky_set_mux(struct csky_pin_bank *bank, int pin, int mux)
+{
+	u32 data, rmask;
+
+	if (pin > 7)
+		return -EINVAL;
+
+	if (mux == CSKY_FUNC_GPIO) {
+		rmask = BIT(pin);
+		data = readl_relaxed(bank->reg_base + GPIO_PORT_CTL);
+		data &= ~rmask;
+		writel_relaxed(data, bank->reg_base + GPIO_PORT_CTL);
+	} else {
+		rmask = BIT(pin);
+		data = readl_relaxed(bank->reg_base + GPIO_PORT_CTL);
+		data |= rmask;
+		writel_relaxed(data, bank->reg_base + GPIO_PORT_CTL);
+	}
+
+	return 0;
+}
+
+#define ERAGON_PULL_OFFSET		0x164
+#define ERAGON_PULL_BITS_PER_PIN	1
+#define ERAGON_PULL_PINS_PER_REG	8
+#define ERAGON_PULL_BANK_STRIDE		16
+#define ERAGON_PULL_PMU_OFFSET		0x64
+
+/*
+ * Pinmux_ops handling
+ */
+
+static int csky_pmx_get_funcs_count(struct pinctrl_dev *pctldev)
+{
+	struct csky_pinctrl *info = pinctrl_dev_get_drvdata(pctldev);
+
+	return info->nfunctions;
+}
+
+static const char *csky_pmx_get_func_name(struct pinctrl_dev *pctldev,
+					  unsigned selector)
+{
+	struct csky_pinctrl *info = pinctrl_dev_get_drvdata(pctldev);
+
+	return info->functions[selector].name;
+}
+
+static int csky_pmx_get_groups(struct pinctrl_dev *pctldev,
+			       unsigned selector, const char * const **groups,
+			       unsigned * const num_groups)
+{
+	struct csky_pinctrl *info = pinctrl_dev_get_drvdata(pctldev);
+
+	*groups = info->functions[selector].groups;
+	*num_groups = info->functions[selector].ngroups;
+
+	return 0;
+}
+
+static int csky_pmx_set(struct pinctrl_dev *pctldev, unsigned selector,
+			unsigned group)
+{
+	struct csky_pinctrl *info = pinctrl_dev_get_drvdata(pctldev);
+	const unsigned int *pins = info->groups[group].pins;
+	const struct csky_pin_config *data = info->groups[group].data;
+	struct csky_pin_bank *bank;
+	int cnt, ret = 0;
+
+	dev_dbg(info->dev, "enable function %s group %s\n",
+		info->functions[selector].name, info->groups[group].name);
+
+	/*
+	 * for each pin in the pin group selected, program the correspoding pin
+	 * pin function number in the config register.
+	 */
+	for (cnt = 0; cnt < info->groups[group].npins; cnt++) {
+		bank = pin_to_bank(info, pins[cnt]);
+		ret = csky_set_mux(bank, pins[cnt] - bank->pin_base,
+				   data[cnt].func);
+		if (ret)
+			break;
+	}
+
+	if (ret) {
+		/* revert the already done pin settings */
+		for (cnt--; cnt >= 0; cnt--)
+			csky_set_mux(bank, pins[cnt] - bank->pin_base, 0);
+
+		return ret;
+	}
+
+	return 0;
+}
+
+static int csky_gpio_get_direction(struct gpio_chip *chip, unsigned offset)
+{
+	struct csky_pin_bank *bank = gpiochip_get_data(chip);
+	u32 data;
+
+	data = readl_relaxed(bank->reg_base + GPIO_SWPORT_DDR);
+
+	return !(data & BIT(offset));
+}
+
+/*
+ * The calls to gpio_direction_output() and gpio_direction_input()
+ * leads to this function call (via the pinctrl_gpio_direction_{input|output}()
+ * function called from the gpiolib interface).
+ */
+static int _csky_pmx_gpio_set_direction(struct gpio_chip *chip,
+					int pin, bool input)
+{
+	struct csky_pin_bank *bank;
+	int ret;
+	unsigned long flags;
+	u32 data;
+
+	bank = gpiochip_get_data(chip);
+
+	ret = csky_set_mux(bank, pin, CSKY_FUNC_GPIO);
+	if (ret < 0)
+		return ret;
+
+	spin_lock_irqsave(&bank->slock, flags);
+
+	data = readl_relaxed(bank->reg_base + GPIO_SWPORT_DDR);
+	/* set bit to 1 for output, 0 for input */
+	if (!input)
+		data |= BIT(pin);
+	else
+		data &= ~BIT(pin);
+	writel_relaxed(data, bank->reg_base + GPIO_SWPORT_DDR);
+
+	spin_unlock_irqrestore(&bank->slock, flags);
+
+	return 0;
+}
+
+static int csky_pmx_gpio_set_direction(struct pinctrl_dev *pctldev,
+				       struct pinctrl_gpio_range *range,
+				       unsigned offset, bool input)
+{
+	struct csky_pinctrl *info = pinctrl_dev_get_drvdata(pctldev);
+	struct gpio_chip *chip;
+	int pin;
+
+	chip = range->gc;
+	pin = offset - chip->base;
+	dev_dbg(info->dev, "gpio_direction for pin %u as %s-%d to %s\n",
+		 offset, range->name, pin, input ? "input" : "output");
+
+	return _csky_pmx_gpio_set_direction(chip, offset - chip->base,
+						input);
+}
+
+static const struct pinmux_ops csky_pmx_ops = {
+	.get_functions_count	= csky_pmx_get_funcs_count,
+	.get_function_name	= csky_pmx_get_func_name,
+	.get_function_groups	= csky_pmx_get_groups,
+	.set_mux		= csky_pmx_set,
+	.gpio_set_direction	= csky_pmx_gpio_set_direction,
+};
+
+static void csky_gpio_set(struct gpio_chip *gc, unsigned offset, int value);
+static int csky_gpio_get(struct gpio_chip *gc, unsigned offset);
+
+/* set the pin config settings for a specified pin */
+static int csky_pinconf_set(struct pinctrl_dev *pctldev, unsigned int pin,
+			    unsigned long *configs, unsigned num_configs)
+{
+	return 0;
+}
+
+/* get the pin config settings for a specified pin */
+static int csky_pinconf_get(struct pinctrl_dev *pctldev, unsigned int pin,
+			    unsigned long *config)
+{
+	return 0;
+}
+
+static const struct pinconf_ops csky_pinconf_ops = {
+	.pin_config_get	= csky_pinconf_get,
+	.pin_config_set	= csky_pinconf_set,
+	.is_generic	= true,
+};
+
+static const struct of_device_id csky_bank_match[] = {
+	{ .compatible = "csky,gpio-bank-v1" },
+	{},
+};
+
+static void csky_pinctrl_child_count(struct csky_pinctrl *info,
+				     struct device_node *np)
+{
+	struct device_node *child;
+
+	for_each_child_of_node(np, child) {
+		if (of_match_node(csky_bank_match, child))
+			continue;
+
+		info->nfunctions++;
+		info->ngroups += of_get_child_count(child);
+	}
+}
+
+static int csky_pinctrl_parse_groups(struct device_node *np,
+				     struct csky_pin_group *grp,
+				     struct csky_pinctrl *info,
+				     u32 index)
+{
+	struct csky_pin_bank *bank;
+	int size;
+	const __be32 *list;
+	int num;
+	int i, j;
+	int ret;
+
+	dev_dbg(info->dev, "group(%d): %s\n", index, np->name);
+
+	/* Initialise group */
+	grp->name = np->name;
+
+	/*
+	 * the binding format is csky,pins = <bank pin mux CONFIG>,
+	 * do sanity check and calculate pins number
+	 */
+	list = of_get_property(np, "csky,pins", &size);
+	/* we do not check return since it's safe node passed down */
+	size /= sizeof(*list);
+	if (!size || size % 4) {
+		dev_err(info->dev, "wrong pins number or pins and configs should be by 4\n");
+		return -EINVAL;
+	}
+
+	grp->npins = size / 4;
+
+	grp->pins = devm_kzalloc(info->dev, grp->npins * sizeof(unsigned int),
+				 GFP_KERNEL);
+	grp->data = devm_kzalloc(info->dev,
+				 grp->npins * sizeof(struct csky_pin_config),
+				 GFP_KERNEL);
+	if (!grp->pins || !grp->data)
+		return -ENOMEM;
+
+	for (i = 0, j = 0; i < size; i += 4, j++) {
+		const __be32 *phandle;
+		struct device_node *np_config;
+
+		num = be32_to_cpu(*list++);
+		bank = bank_num_to_bank(info, num);
+		if (IS_ERR(bank))
+			return PTR_ERR(bank);
+
+		grp->pins[j] = bank->pin_base + be32_to_cpu(*list++);
+		grp->data[j].func = be32_to_cpu(*list++);
+
+		phandle = list++;
+		if (!phandle)
+			return -EINVAL;
+
+		np_config = of_find_node_by_phandle(be32_to_cpup(phandle));
+		ret = pinconf_generic_parse_dt_config(np_config, NULL,
+				&grp->data[j].configs, &grp->data[j].nconfigs);
+		if (ret)
+			return ret;
+	}
+
+	return 0;
+}
+
+static int csky_pinctrl_parse_functions(struct device_node *np,
+					struct csky_pinctrl *info,
+					u32 index)
+{
+	struct device_node *child;
+	struct csky_pmx_func *func;
+	struct csky_pin_group *grp;
+	int ret;
+	static u32 grp_index;
+	u32 i = 0;
+
+	dev_dbg(info->dev, "parse function(%d): %s\n", index, np->name);
+
+	func = &info->functions[index];
+
+	/* Initialise function */
+	func->name = np->name;
+	func->ngroups = of_get_child_count(np);
+	if (func->ngroups <= 0)
+		return 0;
+
+	func->groups = devm_kzalloc(info->dev,
+			func->ngroups * sizeof(char *), GFP_KERNEL);
+	if (!func->groups)
+		return -ENOMEM;
+
+	for_each_child_of_node(np, child) {
+		func->groups[i] = child->name;
+		grp = &info->groups[grp_index++];
+		ret = csky_pinctrl_parse_groups(child, grp, info, i++);
+		if (ret) {
+			of_node_put(child);
+			return ret;
+		}
+	}
+
+	return 0;
+}
+
+static int csky_pinctrl_parse_dt(struct platform_device *pdev,
+				 struct csky_pinctrl *info)
+{
+	struct device *dev = &pdev->dev;
+	struct device_node *np = dev->of_node;
+	struct device_node *child;
+	int ret;
+	int i;
+
+	csky_pinctrl_child_count(info, np);
+
+	dev_dbg(&pdev->dev, "nfunctions = %d\n", info->nfunctions);
+	dev_dbg(&pdev->dev, "ngroups = %d\n", info->ngroups);
+
+	info->functions = devm_kzalloc(dev, info->nfunctions *
+				       sizeof(struct csky_pmx_func),
+				       GFP_KERNEL);
+	if (!info->functions) {
+		dev_err(dev, "failed to allocate memory for function list\n");
+		return -EINVAL;
+	}
+
+	info->groups = devm_kzalloc(dev, info->ngroups *
+				    sizeof(struct csky_pin_group),
+				    GFP_KERNEL);
+	if (!info->groups) {
+		dev_err(dev, "failed allocate memory for ping group list\n");
+		return -EINVAL;
+	}
+
+	i = 0;
+
+	for_each_child_of_node(np, child) {
+		if (of_match_node(csky_bank_match, child))
+			continue;
+
+		ret = csky_pinctrl_parse_functions(child, info, i++);
+		if (ret) {
+			dev_err(&pdev->dev, "failed to parse function\n");
+			of_node_put(child);
+			return ret;
+		}
+	}
+
+	return 0;
+}
+
+static int csky_pinctrl_register(struct platform_device *pdev,
+				 struct csky_pinctrl *info)
+{
+	struct pinctrl_desc *ctrldesc = &info->pctl;
+	struct pinctrl_pin_desc *pindesc, *pdesc;
+	struct csky_pin_bank *pin_bank;
+	int pin, bank, ret;
+	int k;
+
+	ctrldesc->name = "csky-pinctrl";
+	ctrldesc->owner = THIS_MODULE;
+	ctrldesc->pctlops = &csky_pctrl_ops;
+	ctrldesc->pmxops = &csky_pmx_ops;
+	ctrldesc->confops = &csky_pinconf_ops;
+
+	pindesc = devm_kzalloc(&pdev->dev, sizeof(*pindesc) *
+			       info->ctrl->nr_pins, GFP_KERNEL);
+	if (!pindesc) {
+		dev_err(&pdev->dev, "mem alloc for pin descriptors failed\n");
+		return -ENOMEM;
+	}
+	ctrldesc->pins = pindesc;
+	ctrldesc->npins = info->ctrl->nr_pins;
+
+	pdesc = pindesc;
+	for (bank = 0 , k = 0; bank < info->ctrl->nr_banks; bank++) {
+		pin_bank = &info->ctrl->pin_banks[bank];
+		for (pin = 0; pin < pin_bank->nr_pins; pin++, k++) {
+			pdesc->number = k;
+			pdesc->name = kasprintf(GFP_KERNEL, "%s-%d",
+						pin_bank->name, pin);
+			pdesc++;
+		}
+	}
+
+	ret = csky_pinctrl_parse_dt(pdev, info);
+	if (ret)
+		return ret;
+
+	info->pctl_dev = devm_pinctrl_register(&pdev->dev, ctrldesc, info);
+	if (IS_ERR(info->pctl_dev)) {
+		dev_err(&pdev->dev, "could not register pinctrl driver\n");
+		return PTR_ERR(info->pctl_dev);
+	}
+
+	for (bank = 0; bank < info->ctrl->nr_banks; ++bank) {
+		pin_bank = &info->ctrl->pin_banks[bank];
+		pin_bank->grange.name = pin_bank->name;
+		pin_bank->grange.id = bank;
+		pin_bank->grange.pin_base = pin_bank->pin_base;
+		pin_bank->grange.base = pin_bank->gpio_chip.base;
+		pin_bank->grange.npins = pin_bank->gpio_chip.ngpio;
+		pin_bank->grange.gc = &pin_bank->gpio_chip;
+		pinctrl_add_gpio_range(info->pctl_dev, &pin_bank->grange);
+	}
+
+	return 0;
+}
+
+/*
+ * GPIO handling
+ */
+
+static void csky_gpio_set(struct gpio_chip *gc, unsigned offset, int value)
+{
+	struct csky_pin_bank *bank = gpiochip_get_data(gc);
+	void __iomem *reg = bank->reg_base + GPIO_SWPORT_DR;
+	unsigned long flags;
+	u32 data;
+
+	spin_lock_irqsave(&bank->slock, flags);
+
+	data = readl(reg);
+	data &= ~BIT(offset);
+	if (value)
+		data |= BIT(offset);
+	writel(data, reg);
+
+	spin_unlock_irqrestore(&bank->slock, flags);
+}
+
+/*
+ * Returns the level of the pin for input direction and setting of the DR
+ * register for output gpios.
+ */
+static int csky_gpio_get(struct gpio_chip *gc, unsigned offset)
+{
+	struct csky_pin_bank *bank = gpiochip_get_data(gc);
+	u32 data;
+
+	data = readl(bank->reg_base + GPIO_EXT_PORT);
+	data >>= offset;
+	data &= 1;
+	return data;
+}
+
+/*
+ * gpiolib gpio_direction_input callback function. The setting of the pin
+ * mux function as 'gpio input' will be handled by the pinctrl susbsystem
+ * interface.
+ */
+static int csky_gpio_direction_input(struct gpio_chip *gc, unsigned offset)
+{
+	return pinctrl_gpio_direction_input(gc->base + offset);
+}
+
+/*
+ * gpiolib gpio_direction_output callback function. The setting of the pin
+ * mux function as 'gpio output' will be handled by the pinctrl susbsystem
+ * interface.
+ */
+static int csky_gpio_direction_output(struct gpio_chip *gc,
+				      unsigned offset, int value)
+{
+	csky_gpio_set(gc, offset, value);
+	return pinctrl_gpio_direction_output(gc->base + offset);
+}
+
+/*
+ * gpiolib gpio_to_irq callback function. Creates a mapping between a GPIO pin
+ * and a virtual IRQ, if not already present.
+ */
+static int csky_gpio_to_irq(struct gpio_chip *gc, unsigned offset)
+{
+	struct csky_pin_bank *bank = gpiochip_get_data(gc);
+	unsigned int virq;
+
+	if (!bank->domain)
+		return -ENXIO;
+
+	virq = irq_create_mapping(bank->domain, offset);
+
+	return (virq) ? : -ENXIO;
+}
+
+static const struct gpio_chip csky_gpiolib_chip = {
+	.request = gpiochip_generic_request,
+	.free = gpiochip_generic_free,
+	.set = csky_gpio_set,
+	.get = csky_gpio_get,
+	.get_direction = csky_gpio_get_direction,
+	.direction_input = csky_gpio_direction_input,
+	.direction_output = csky_gpio_direction_output,
+	.to_irq = csky_gpio_to_irq,
+	.owner = THIS_MODULE,
+};
+
+/*
+ * Interrupt handling
+ */
+
+static void csky_irq_demux(struct irq_desc *desc)
+{
+	struct irq_chip *chip = irq_desc_get_chip(desc);
+	struct csky_pin_bank *bank = irq_desc_get_handler_data(desc);
+	u32 pend;
+
+	dev_dbg(bank->drvdata->dev, "got irq for bank %s\n", bank->name);
+
+	chained_irq_enter(chip, desc);
+
+	pend = readl_relaxed(bank->reg_base + GPIO_INT_STATUS);
+
+	while (pend) {
+		unsigned int irq, virq;
+
+		irq = __ffs(pend);
+		pend &= ~BIT(irq);
+		virq = irq_linear_revmap(bank->domain, irq);
+
+		if (!virq) {
+			dev_err(bank->drvdata->dev, "unmapped irq %d\n", irq);
+			continue;
+		}
+
+		dev_dbg(bank->drvdata->dev, "handling irq %d\n", irq);
+
+		/*
+		 * Triggering IRQ on both rising and falling edge
+		 * needs manual intervention.
+		 */
+		if (bank->toggle_edge_mode & BIT(irq)) {
+			u32 data, data_old, polarity;
+			unsigned long flags;
+
+			data = readl_relaxed(bank->reg_base + GPIO_EXT_PORT);
+			do {
+				spin_lock_irqsave(&bank->slock, flags);
+
+				polarity = readl_relaxed(bank->reg_base +
+							 GPIO_INT_POLARITY);
+				if (data & BIT(irq))
+					polarity &= ~BIT(irq);
+				else
+					polarity |= BIT(irq);
+				writel(polarity,
+				       bank->reg_base + GPIO_INT_POLARITY);
+
+				spin_unlock_irqrestore(&bank->slock, flags);
+
+				data_old = data;
+				data = readl_relaxed(bank->reg_base +
+						     GPIO_EXT_PORT);
+			} while ((data & BIT(irq)) != (data_old & BIT(irq)));
+		}
+
+		generic_handle_irq(virq);
+	}
+
+	chained_irq_exit(chip, desc);
+}
+
+static int csky_irq_set_type(struct irq_data *d, unsigned int type)
+{
+	struct irq_chip_generic *gc = irq_data_get_irq_chip_data(d);
+	struct csky_pin_bank *bank = gc->private;
+	u32 mask = BIT(d->hwirq);
+	u32 polarity;
+	u32 level;
+	u32 data;
+	unsigned long flags;
+	int ret;
+
+	/* make sure the pin is configured as gpio input */
+	ret = csky_set_mux(bank, d->hwirq, CSKY_FUNC_GPIO);
+	if (ret < 0)
+		return ret;
+
+	spin_lock_irqsave(&bank->slock, flags);
+
+	data = readl_relaxed(bank->reg_base + GPIO_SWPORT_DDR);
+	data &= ~mask;
+	writel_relaxed(data, bank->reg_base + GPIO_SWPORT_DDR);
+
+	spin_unlock_irqrestore(&bank->slock, flags);
+
+	if (type & IRQ_TYPE_EDGE_BOTH)
+		irq_set_handler_locked(d, handle_edge_irq);
+	else
+		irq_set_handler_locked(d, handle_level_irq);
+
+	spin_lock_irqsave(&bank->slock, flags);
+	irq_gc_lock(gc);
+
+	level = readl_relaxed(gc->reg_base + GPIO_INTTYPE_LEVEL);
+	polarity = readl_relaxed(gc->reg_base + GPIO_INT_POLARITY);
+
+	switch (type) {
+	case IRQ_TYPE_EDGE_BOTH:
+		bank->toggle_edge_mode |= mask;
+		level |= mask;
+
+		/*
+		 * Determine gpio state. If 1 next interrupt should be falling
+		 * otherwise rising.
+		 */
+		data = readl(bank->reg_base + GPIO_EXT_PORT);
+		if (data & mask)
+			polarity &= ~mask;
+		else
+			polarity |= mask;
+		break;
+	case IRQ_TYPE_EDGE_RISING:
+		bank->toggle_edge_mode &= ~mask;
+		level |= mask;
+		polarity |= mask;
+		break;
+	case IRQ_TYPE_EDGE_FALLING:
+		bank->toggle_edge_mode &= ~mask;
+		level |= mask;
+		polarity &= ~mask;
+		break;
+	case IRQ_TYPE_LEVEL_HIGH:
+		bank->toggle_edge_mode &= ~mask;
+		level &= ~mask;
+		polarity |= mask;
+		break;
+	case IRQ_TYPE_LEVEL_LOW:
+		bank->toggle_edge_mode &= ~mask;
+		level &= ~mask;
+		polarity &= ~mask;
+		break;
+	default:
+		irq_gc_unlock(gc);
+		spin_unlock_irqrestore(&bank->slock, flags);
+		return -EINVAL;
+	}
+
+	writel_relaxed(level, gc->reg_base + GPIO_INTTYPE_LEVEL);
+	writel_relaxed(polarity, gc->reg_base + GPIO_INT_POLARITY);
+
+	irq_gc_unlock(gc);
+	spin_unlock_irqrestore(&bank->slock, flags);
+
+	return 0;
+}
+
+static void csky_irq_suspend(struct irq_data *d)
+{
+	struct irq_chip_generic *gc = irq_data_get_irq_chip_data(d);
+	struct csky_pin_bank *bank = gc->private;
+
+	bank->saved_masks = irq_reg_readl(gc, GPIO_INTMASK);
+	irq_reg_writel(gc, ~gc->wake_active, GPIO_INTMASK);
+}
+
+static void csky_irq_resume(struct irq_data *d)
+{
+	struct irq_chip_generic *gc = irq_data_get_irq_chip_data(d);
+	struct csky_pin_bank *bank = gc->private;
+
+	irq_reg_writel(gc, bank->saved_masks, GPIO_INTMASK);
+}
+
+static void csky_irq_gc_mask_clr_bit(struct irq_data *d)
+{
+	struct irq_chip_generic *gc = irq_data_get_irq_chip_data(d);
+	struct csky_pin_bank *bank = gc->private;
+
+	irq_gc_mask_clr_bit(d);
+}
+
+static void csky_irq_gc_mask_set_bit(struct irq_data *d)
+{
+	struct irq_chip_generic *gc = irq_data_get_irq_chip_data(d);
+	struct csky_pin_bank *bank = gc->private;
+
+	irq_gc_mask_set_bit(d);
+}
+
+static int csky_interrupts_register(struct platform_device *pdev,
+				    struct csky_pinctrl *info)
+{
+	struct csky_pin_ctrl *ctrl = info->ctrl;
+	struct csky_pin_bank *bank = ctrl->pin_banks;
+	unsigned int clr = IRQ_NOREQUEST | IRQ_NOPROBE | IRQ_NOAUTOEN;
+	struct irq_chip_generic *gc;
+	int ret;
+	int i, j;
+
+	for (i = 0; i < ctrl->nr_banks; ++i, ++bank) {
+		if (!bank->valid) {
+			dev_warn(&pdev->dev, "bank %s is not valid\n",
+				 bank->name);
+			continue;
+		}
+
+		// TODO: 32 should be: gpio_chip->ngpio
+		bank->domain = irq_domain_add_linear(bank->of_node,
+						     bank->nr_pins,
+						     &irq_generic_chip_ops,
+						     NULL);
+		switch (i) {
+		case 0:
+			bank->irq = GPIO0_IRQS;
+			break;
+		case 1:
+			bank->irq = GPIO1_IRQS;
+			break;
+		case 2:
+			bank->irq = GPIO2_IRQS;
+			break;
+		case 3:
+			bank->irq = GPIO3_IRQS;
+			break;
+		default:
+			dev_err(&pdev->dev,
+				"The GPIO irqs is wrong !\n");
+			return -1;
+		}
+		if (!bank->domain) {
+			dev_warn(&pdev->dev,
+				 "could not init irq domain for bank %s\n",
+				 bank->name);
+			continue;
+		}
+
+		ret = irq_alloc_domain_generic_chips(bank->domain,
+					bank->nr_pins, 1,
+					"csky_gpio_irq", handle_level_irq,
+					clr, 0, IRQ_GC_INIT_MASK_CACHE);
+		if (ret) {
+			dev_err(&pdev->dev,
+				"could not alloc generic chips for bank %s\n",
+				bank->name);
+			irq_domain_remove(bank->domain);
+			continue;
+		}
+
+		/*
+		 * Linux assumes that all interrupts start out disabled/masked.
+		 * Our driver only uses the concept of masked and always keeps
+		 * things enabled, so for us that's all masked and all enabled.
+		 */
+		writel_relaxed(0xffffffff, bank->reg_base + GPIO_INTMASK);
+		writel_relaxed(0xffffffff, bank->reg_base + GPIO_INTEN);
+
+		gc = irq_get_domain_generic_chip(bank->domain, 0);
+		gc->reg_base = bank->reg_base;
+		gc->private = bank;
+		gc->chip_types[0].regs.mask = GPIO_INTMASK;
+		gc->chip_types[0].regs.ack = GPIO_PORTS_EOI;
+		gc->chip_types[0].chip.irq_ack = irq_gc_ack_set_bit;
+		gc->chip_types[0].chip.irq_mask = csky_irq_gc_mask_set_bit;
+		gc->chip_types[0].chip.irq_unmask = csky_irq_gc_mask_clr_bit;
+		gc->chip_types[0].chip.irq_set_wake = irq_gc_set_wake;
+		gc->chip_types[0].chip.irq_suspend = csky_irq_suspend;
+		gc->chip_types[0].chip.irq_resume = csky_irq_resume;
+		gc->chip_types[0].chip.irq_set_type = csky_irq_set_type;
+		gc->wake_enabled = IRQ_MSK(bank->nr_pins);
+
+		irq_set_chained_handler_and_data(bank->irq,
+						 csky_irq_demux, bank);
+
+		/* map the gpio irqs here, when the clock is still running */
+		// TODO: 32 should be: gpio_chip->ngpio
+		for (j = 0 ; j < 8 ; j++)
+			irq_create_mapping(bank->domain, j);
+	}
+
+	return 0;
+}
+
+static int csky_gpiolib_register(struct platform_device *pdev,
+				 struct csky_pinctrl *info)
+{
+	struct csky_pin_ctrl *ctrl = info->ctrl;
+	struct csky_pin_bank *bank = ctrl->pin_banks;
+	struct gpio_chip *gc;
+	int ret;
+	int i;
+
+	for (i = 0; i < ctrl->nr_banks; ++i, ++bank) {
+		if (!bank->valid) {
+			dev_warn(&pdev->dev, "bank %s is not valid\n",
+				 bank->name);
+			continue;
+		}
+
+		bank->gpio_chip = csky_gpiolib_chip;
+
+		gc = &bank->gpio_chip;
+		gc->base = bank->pin_base;
+		gc->ngpio = bank->nr_pins;
+		gc->parent = &pdev->dev;
+		gc->of_node = bank->of_node;
+		gc->label = bank->name;
+
+		ret = gpiochip_add_data(gc, bank);
+		if (ret) {
+			dev_err(&pdev->dev, "failed to register gpio_chip %s, error code: %d\n",
+							gc->label, ret);
+			goto fail;
+		}
+	}
+
+	ret = csky_interrupts_register(pdev, info);
+	if (ret < 0)
+		goto fail;
+
+	return 0;
+
+fail:
+	for (--i, --bank; i >= 0; --i, --bank) {
+		if (!bank->valid)
+			continue;
+		gpiochip_remove(&bank->gpio_chip);
+	}
+	return ret;
+}
+
+static int csky_gpiolib_unregister(struct platform_device *pdev,
+				   struct csky_pinctrl *info)
+{
+	struct csky_pin_ctrl *ctrl = info->ctrl;
+	struct csky_pin_bank *bank = ctrl->pin_banks;
+	int i;
+
+	for (i = 0; i < ctrl->nr_banks; ++i, ++bank) {
+		if (!bank->valid)
+			continue;
+		gpiochip_remove(&bank->gpio_chip);
+	}
+
+	return 0;
+}
+
+static int csky_get_bank_data(struct csky_pin_bank *bank,
+			      struct csky_pinctrl *info)
+{
+	struct resource res;
+
+	if (!of_device_is_compatible(bank->of_node, "csky,gpio-bank-v1")) {
+		dev_err(info->dev, "Only 'eragon-gpio-bank' is supported\n");
+		return -ENODEV;
+	}
+
+	if (of_address_to_resource(bank->of_node, 0, &res)) {
+		dev_err(info->dev, "cannot find IO resource for bank\n");
+		return -ENOENT;
+	}
+
+	bank->reg_base = devm_ioremap_resource(info->dev, &res);
+	if (IS_ERR(bank->reg_base))
+		return PTR_ERR(bank->reg_base);
+
+	return 0;
+}
+
+static const struct of_device_id csky_pinctrl_dt_match[];
+
+/* retrieve the soc specific data */
+static struct csky_pin_ctrl *csky_pinctrl_get_soc_data(
+						struct csky_pinctrl *d,
+						struct platform_device *pdev)
+{
+	const struct of_device_id *match;
+	struct device_node *node = pdev->dev.of_node;
+	struct device_node *np;
+	struct csky_pin_ctrl *ctrl;
+	struct csky_pin_bank *bank;
+	int i;
+	//int grf_offs, pmu_offs, drv_grf_offs, drv_pmu_offs, j
+
+	match = of_match_node(csky_pinctrl_dt_match, node);
+	ctrl = (struct csky_pin_ctrl *)match->data;
+
+	for_each_child_of_node(node, np) {
+		if (!of_find_property(np, "gpio-controller", NULL))
+			continue;
+
+		bank = ctrl->pin_banks;
+		for (i = 0; i < ctrl->nr_banks; ++i, ++bank) {
+			if (!strcmp(bank->name, np->name)) {
+				bank->of_node = np;
+
+				if (!csky_get_bank_data(bank, d))
+					bank->valid = true;
+
+				break;
+			}
+		}
+	}
+
+	bank = ctrl->pin_banks;
+	for (i = 0; i < ctrl->nr_banks; ++i, ++bank) {
+		//int bank_pins = 0;
+
+		spin_lock_init(&bank->slock);
+		bank->drvdata = d;
+		bank->pin_base = ctrl->nr_pins;
+		ctrl->nr_pins += bank->nr_pins;
+	}
+
+	return ctrl;
+}
+
+static int __maybe_unused csky_pinctrl_suspend(struct device *dev)
+{
+	struct csky_pinctrl *info = dev_get_drvdata(dev);
+	int ret = pinctrl_force_sleep(info->pctl_dev);
+	if (ret)
+		return ret;
+
+	// TODO: implement on eragon
+	return 0;
+}
+
+static int __maybe_unused csky_pinctrl_resume(struct device *dev)
+{
+	struct csky_pinctrl *info = dev_get_drvdata(dev);
+
+	// TODO: implement on eragon
+
+	return pinctrl_force_default(info->pctl_dev);
+}
+
+static SIMPLE_DEV_PM_OPS(csky_pinctrl_dev_pm_ops,
+			 NULL, /* csky_pinctrl_suspend, */
+			 NULL  /* csky_pinctrl_resume */);
+
+static int csky_pinctrl_probe(struct platform_device *pdev)
+{
+	struct csky_pinctrl *info;
+	struct device *dev = &pdev->dev;
+	struct csky_pin_ctrl *ctrl;
+	int ret;
+
+	if (!dev->of_node) {
+		dev_err(dev, "device tree node not found\n");
+		return -ENODEV;
+	}
+
+	info = devm_kzalloc(dev, sizeof(struct csky_pinctrl), GFP_KERNEL);
+	if (!info)
+		return -ENOMEM;
+
+	info->dev = dev;
+
+	ctrl = csky_pinctrl_get_soc_data(info, pdev);
+	if (!ctrl) {
+		dev_err(dev, "driver data not available\n");
+		return -EINVAL;
+	}
+	info->ctrl = ctrl;
+
+	ret = csky_gpiolib_register(pdev, info);
+	if (ret)
+		return ret;
+
+	ret = csky_pinctrl_register(pdev, info);
+	if (ret) {
+		csky_gpiolib_unregister(pdev, info);
+		return ret;
+	}
+
+	platform_set_drvdata(pdev, info);
+
+	return 0;
+}
+
+static struct csky_pin_bank eragon_pin_banks[] = {
+	PIN_BANK(0, 8, "gpio0"),
+	PIN_BANK(1, 8, "gpio1"),
+	PIN_BANK(2, 8, "gpio2"),
+	PIN_BANK(3, 8, "gpio3"),
+};
+
+static struct csky_pin_ctrl eragon_pin_ctrl = {
+	.pin_banks	= eragon_pin_banks,
+	.nr_banks	= ARRAY_SIZE(eragon_pin_banks),
+	.label		= "ERAGON-GPIO",
+	.type		= ERAGON,
+};
+
+static const struct of_device_id csky_pinctrl_dt_match[] = {
+	{ .compatible 	= "csky,pinctrl-v1",
+	  .data 	= (void *)&eragon_pin_ctrl },
+	{},
+};
+
+static struct platform_driver csky_pinctrl_driver = {
+	.probe	= csky_pinctrl_probe,
+	.driver = {
+		.name		= "csky-pinctrl",
+		.pm		= &csky_pinctrl_dev_pm_ops,
+		.of_match_table	= csky_pinctrl_dt_match,
+	},
+};
+
+static int __init csky_pinctrl_drv_register(void)
+{
+	return platform_driver_register(&csky_pinctrl_driver);
+}
+postcore_initcall(csky_pinctrl_drv_register);
+
diff --git a/addons/drivers/pinctrl/pinctrl-csky.h b/addons/drivers/pinctrl/pinctrl-csky.h
new file mode 100644
index 0000000..6d4314a
--- /dev/null
+++ b/addons/drivers/pinctrl/pinctrl-csky.h
@@ -0,0 +1,35 @@
+/*
+ * pin-controller/pin-mux/pin-config/gpio-driver for C-SKY's SoCs.
+ *
+ * Copyright (C) 2017 C-SKY MicroSystems Co.,Ltd.
+ * Author: Charles Lu <chongzhi_lu@c-sky.com>
+ *
+ * This software is licensed under the terms of the GNU General Public
+ * License version 2, as published by the Free Software Foundation, and
+ * may be copied, distributed, and modified under those terms.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ */
+
+#ifndef __PINCTRL_CSKY_H
+#define __PINCTRL_CSKY_H
+
+#define CSKY_GPIO0	0
+#define CSKY_GPIO1	1
+#define CSKY_GPIO2	2
+#define CSKY_GPIO3	3
+#define CSKY_GPIO4	4
+#define CSKY_GPIO6	6
+
+#define CSKY_FUNC_GPIO	0
+#define CSKY_FUNC_1	1
+#define CSKY_FUNC_2	2
+#define CSKY_FUNC_3	3
+#define CSKY_FUNC_4	4
+
+
+#endif /* __PINCTRL_CSKY_H */
diff --git a/addons/drivers/pwm/Kconfig b/addons/drivers/pwm/Kconfig
new file mode 100644
index 0000000..17b6c97
--- /dev/null
+++ b/addons/drivers/pwm/Kconfig
@@ -0,0 +1,13 @@
+#
+# C-SKY Pin control drivers
+#
+
+menu "PWM"
+
+config PWM_CSKY
+	bool "C-SKY PWM DRIVER"
+	depends on OF
+	select PWM
+	select BACKLIGHT_PWM
+endmenu
+
diff --git a/addons/drivers/pwm/Makefile b/addons/drivers/pwm/Makefile
new file mode 100644
index 0000000..a30ecfa
--- /dev/null
+++ b/addons/drivers/pwm/Makefile
@@ -0,0 +1,4 @@
+# C-SKY pin control drivers
+
+obj-$(CONFIG_PWM_CSKY)	+= pwm-csky.o
+
diff --git a/addons/drivers/pwm/pwm-csky.c b/addons/drivers/pwm/pwm-csky.c
new file mode 100644
index 0000000..c15c005
--- /dev/null
+++ b/addons/drivers/pwm/pwm-csky.c
@@ -0,0 +1,274 @@
+/*
+ * pwm driver for C-SKY's SoCs.
+ *
+ * Copyright (C) 2017 C-SKY MicroSystems Co.,Ltd.
+ * Author: Minfeng Zhang <minfeng_zhang@c-sky.com>
+ *
+ * This software is licensed under the terms of the GNU General Public
+ * License version 2, as published by the Free Software Foundation, and
+ * may be copied, distributed, and modified under those terms.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ */
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/platform_device.h>
+#include <linux/slab.h>
+#include <linux/err.h>
+#include <linux/io.h>
+#include <linux/pwm.h>
+#include <linux/delay.h>
+#include <linux/clk.h>
+
+#include <linux/of.h>
+#include <linux/of_device.h>
+#include <linux/of_address.h>
+
+#define NUM_PWM			3
+#define PWM_MIN_PRESCALE	0
+#define PWM_MAX_PRESCALE	0x3FFF
+#define PWM_MIN_PERIOD		0x0001
+#define PWM_MAX_PERIOD		0xFFFF
+#define PWM_CLK_RATE		60000000
+#define PWM_PWM_ENABLE		1
+#define PWM_MIN_DUTY		0x0001
+#define PWM_MAX_DUTY		0xFFFF
+
+/* PWM registers and bits definitions */
+#define PWMCFG		0x0
+#define PWMCTL		0x34
+#define PWM01LOAD	0x38
+#define PWM23LOAD	0x3c
+#define PWM45LOAD	0x40
+#define PWM0CMP		0x50
+#define PWM1CMP		0x54
+#define PWM2CMP		0x58
+#define PWM3CMP		0x5c
+#define PWM4CMP		0x60
+#define PWM5CMP		0x64
+#define PWM01DB		0x68
+#define PWM23DB		0x6c
+#define PWM45DB		0x70
+
+
+/**
+ * struct spear_pwm_chip - struct representing pwm chip
+ *
+ * @base: base address of pwm chip
+ * @clk: pointer to clk structure of pwm chip
+ * @chip: linux pwm chip representation
+ */
+struct csky_pwm_chip {
+	struct pwm_chip chip;
+	void __iomem *base;
+	struct clk *clk;
+	int	period;
+	int	duty;
+};
+
+static inline struct csky_pwm_chip *to_csky_pwm_chip(struct pwm_chip *chip)
+{
+	return container_of(chip, struct csky_pwm_chip, chip);
+}
+
+/*
+ * period_ns = 10^9 * period_cycles / PWM_CLK_RATE
+ * duty_ns   = 10^9 * duty_cycles / PWM_CLK_RATE
+ */
+static int csky_pwm_config(struct pwm_chip *chip, struct pwm_device *pwm,
+		int duty_ns, int period_ns)
+{
+	struct csky_pwm_chip *pc = to_csky_pwm_chip(chip);
+	u64 val, div, clk_rate;
+	unsigned long prescale = PWM_MIN_PRESCALE, pv, dc;
+	int ret;
+
+	if (pc->period == 0 || pc->duty == 0) {
+		if (duty_ns != 0)
+			pc->duty = duty_ns;
+		if (period_ns != 0)
+			pc->period = period_ns;
+		if (pc->duty == 0 || pc->period == 0) {
+			return 0;
+		}
+	}
+	/*
+	 * Find pv, dc and prescale to suit duty_ns and period_ns. This is done
+	 * according to formulas described below:
+	 *
+	 * period_ns = 10^9 * (PRESCALE + 1) * PV / PWM_CLK_RATE
+	 * duty_ns = 10^9 * (PRESCALE + 1) * DC / PWM_CLK_RATE
+	 *
+	 * PV = (PWM_CLK_RATE * period_ns) / (10^9 * (PRESCALE + 1))
+	 * DC = (PWM_CLK_RATE * duty_ns) / (10^9 * (PRESCALE + 1))
+	 */
+	clk_rate = clk_get_rate(pc->clk);
+	while (1) {
+		div = 1000000000;
+		div *= 1 + prescale;
+		val = clk_rate * period_ns;
+		pv = div64_u64(val, div);
+		val = clk_rate * duty_ns;
+		dc = div64_u64(val, div);
+
+		/* if duty_ns and period_ns are not achievable then return */
+		if (pv < PWM_MIN_PERIOD || dc < PWM_MIN_DUTY)
+			return -EINVAL;
+
+		/*
+		 * if pv and dc have crossed their upper limit, then increase
+		 * prescale and recalculate pv and dc.
+		 */
+		if (pv > PWM_MAX_PERIOD || dc > PWM_MAX_DUTY) {
+			if (++prescale > PWM_MAX_PRESCALE)
+				return -EINVAL;
+			continue;
+		}
+		break;
+	}
+
+	ret = clk_enable(pc->clk);
+	if (ret)
+		return ret;
+
+	writel_relaxed(0x0, pc->base + PWMCTL);
+	/* pwm->hwpwm is hardware pwm number */
+	switch(pwm->hwpwm) {
+	case 0:
+		writel_relaxed(pv, pc->base + PWM01LOAD);
+		writel_relaxed(dc, pc->base + PWM0CMP);
+		writel_relaxed(0x0, pc->base + PWM01DB);
+		break;
+	case 1:
+		writel_relaxed(pv << 16, pc->base + PWM01LOAD);
+		writel_relaxed(dc, pc->base + PWM1CMP);
+		writel_relaxed(0x0, pc->base + PWM01DB);
+		break;
+	case 2:
+		writel_relaxed(pv, pc->base + PWM23LOAD);
+		writel_relaxed(dc, pc->base + PWM2CMP);
+		writel_relaxed(0x0, pc->base + PWM23DB);
+		break;
+	default:
+		return -EINVAL;
+	}
+
+	pc->period = 0;
+	pc->duty = 0;
+	return 0;
+}
+
+static int csky_pwm_enable(struct pwm_chip *chip, struct pwm_device *pwm)
+{
+	struct csky_pwm_chip *pc = to_csky_pwm_chip(chip);
+	u32 val;
+
+	clk_enable(pc->clk);
+	val = readl_relaxed(pc->base + PWMCFG);
+	val |= PWM_PWM_ENABLE << (pwm->hwpwm) * 2;
+	writel_relaxed(val, pc->base + PWMCFG);
+
+	return 0;
+}
+
+
+static void csky_pwm_disable(struct pwm_chip *chip, struct pwm_device *pwm)
+{
+	struct csky_pwm_chip *pc = to_csky_pwm_chip(chip);
+	u32 val;
+
+	val = readl_relaxed(pc->base + PWMCFG);
+	val &= ~PWM_PWM_ENABLE << (pwm->hwpwm) * 2;
+	writel_relaxed(val, pc->base + PWMCFG);
+
+	clk_disable(pc->clk);
+}
+
+static struct pwm_ops csky_pwm_ops = {
+	.enable = csky_pwm_enable,
+	.disable = csky_pwm_disable,
+	.config = csky_pwm_config,
+	.owner = THIS_MODULE,
+};
+
+static int csky_pwm_probe(struct platform_device *pdev)
+{
+	struct csky_pwm_chip *pc;
+	struct device *dev = &pdev->dev;
+	struct resource *r;
+	int ret;
+	pc = devm_kzalloc(&pdev->dev, sizeof(*pc), GFP_KERNEL);
+	if (!pc)
+		return -ENOMEM;
+
+	r = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	pc->base = devm_ioremap_resource(&pdev->dev, r);
+	if (IS_ERR(pc->base))
+		return PTR_ERR(pc->base);
+
+	platform_set_drvdata(pdev, pc);
+
+	pc->chip.dev = &pdev->dev;
+	pc->chip.ops = &csky_pwm_ops;
+	pc->chip.base = -1;
+	pc->chip.npwm = NUM_PWM;
+	pc->duty = 0;
+	pc->period = 0;
+
+	pc->clk = devm_clk_get(dev, NULL);
+	if (IS_ERR(pc->clk)) {
+		dev_err(dev, "failed to get PWM clock\n");
+		return PTR_ERR(pc->clk);
+	}
+
+	ret = clk_prepare(pc->clk);
+	if (ret) {
+		dev_err(dev, "failed to prepare clock\n");
+		return ret;
+	}
+
+	ret = pwmchip_add(&pc->chip);
+	if (ret < 0) {
+		clk_unprepare(pc->clk);
+		dev_err(&pdev->dev, "pwmchip_add() failed: %d\n", ret);
+	}
+
+	return ret;
+}
+
+static int csky_pwm_remove(struct platform_device *pdev)
+{
+	struct csky_pwm_chip *pc = platform_get_drvdata(pdev);
+	int i;
+
+	for(i = 0;i < NUM_PWM; i++)
+		pwm_disable(&pc->chip.pwms[i]);
+
+	/* clk was prepared in probe, hence unprepare it here */
+	clk_unprepare(pc->clk);
+	return pwmchip_remove(&pc->chip);
+}
+
+static const struct of_device_id csky_pwm_dt_ids[] = {
+	{ .compatible = "csky,pwm-v1", },
+	{}
+};
+MODULE_DEVICE_TABLE(of, csky_pwm_dt_ids);
+
+static struct platform_driver csky_pwm_driver = {
+	.probe		= csky_pwm_probe,
+	.remove		= csky_pwm_remove,
+	.driver		= {
+		.name	= "csky-pwm",
+		.of_match_table = csky_pwm_dt_ids,
+	},
+};
+module_platform_driver(csky_pwm_driver);
+
+MODULE_DESCRIPTION("CSKY PWM Driver");
+MODULE_AUTHOR("Minfeng Zhang <minfeng_zhang@c-sky.com>");
+MODULE_LICENSE("GPL");
diff --git a/addons/drivers/reset/Kconfig b/addons/drivers/reset/Kconfig
new file mode 100644
index 0000000..d68dc57
--- /dev/null
+++ b/addons/drivers/reset/Kconfig
@@ -0,0 +1,7 @@
+
+config RESET_CSKY
+	bool "C-SKY SoCs Reset Driver"
+	default n
+	help
+	  This enables the reset driver for C-SKY SoCs.
+
diff --git a/addons/drivers/reset/Makefile b/addons/drivers/reset/Makefile
new file mode 100644
index 0000000..2ccac5d
--- /dev/null
+++ b/addons/drivers/reset/Makefile
@@ -0,0 +1,3 @@
+
+obj-$(CONFIG_RESET_CSKY) += reset-csky.o
+
diff --git a/addons/drivers/reset/reset-csky.c b/addons/drivers/reset/reset-csky.c
new file mode 100644
index 0000000..8770796
--- /dev/null
+++ b/addons/drivers/reset/reset-csky.c
@@ -0,0 +1,128 @@
+/*
+ * C-SKY SoCs Reset Controller driver
+ *
+ * Copyright (C) 2017 C-SKY MicroSystems Co.,Ltd.
+ *
+ * Author: Lei Ling <lei_ling@c-sky.com>
+ *
+ * This software is licensed under the terms of the GNU General Public
+ * License version 2, as published by the Free Software Foundation, and
+ * may be copied, distributed, and modified under those terms.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include <linux/err.h>
+#include <linux/io.h>
+#include <linux/module.h>
+#include <linux/of.h>
+#include <linux/of_address.h>
+#include <linux/platform_device.h>
+#include <linux/reset-controller.h>
+#include <linux/slab.h>
+#include <linux/spinlock.h>
+#include <linux/types.h>
+
+struct csky_reset_data {
+	spinlock_t			lock;
+	void __iomem			*membase;
+	struct reset_controller_dev	rcdev;
+};
+
+static int csky_reset_assert(struct reset_controller_dev *rcdev,
+			     unsigned long id)
+{
+	struct csky_reset_data *data = container_of(rcdev,
+						    struct csky_reset_data,
+						    rcdev);
+	int bank = id / BITS_PER_LONG;
+	int offset = id % BITS_PER_LONG;
+	unsigned long flags;
+	u32 reg;
+
+	spin_lock_irqsave(&data->lock, flags);
+
+	reg = readl(data->membase + (bank * 4));
+	writel(reg & ~BIT(offset), data->membase + (bank * 4));
+
+	spin_unlock_irqrestore(&data->lock, flags);
+
+	return 0;
+}
+
+static int csky_reset_deassert(struct reset_controller_dev *rcdev,
+			       unsigned long id)
+{
+	struct csky_reset_data *data = container_of(rcdev,
+						    struct csky_reset_data,
+						    rcdev);
+	int bank = id / BITS_PER_LONG;
+	int offset = id % BITS_PER_LONG;
+	unsigned long flags;
+	u32 reg;
+
+	spin_lock_irqsave(&data->lock, flags);
+
+	reg = readl(data->membase + (bank * 4));
+	writel(reg | BIT(offset), data->membase + (bank * 4));
+
+	spin_unlock_irqrestore(&data->lock, flags);
+
+	return 0;
+}
+
+static const struct reset_control_ops csky_reset_ops = {
+	.assert		= csky_reset_assert,
+	.deassert	= csky_reset_deassert,
+};
+
+static const struct of_device_id csky_reset_dt_ids[] = {
+	{ .compatible = "csky,reset-v1", },
+	{ }
+};
+MODULE_DEVICE_TABLE(of, csky_reset_dt_ids);
+
+static int csky_reset_probe(struct platform_device *pdev)
+{
+	struct csky_reset_data *data;
+	struct resource *res;
+
+	data = devm_kzalloc(&pdev->dev, sizeof(*data), GFP_KERNEL);
+	if (!data)
+		return -ENOMEM;
+
+	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	data->membase = devm_ioremap_resource(&pdev->dev, res);
+	if (IS_ERR(data->membase))
+		return PTR_ERR(data->membase);
+
+	spin_lock_init(&data->lock);
+
+	data->rcdev.owner = THIS_MODULE;
+	data->rcdev.nr_resets = resource_size(res) * 8;
+	data->rcdev.ops = &csky_reset_ops;
+	data->rcdev.of_node = pdev->dev.of_node;
+
+	return devm_reset_controller_register(&pdev->dev, &data->rcdev);
+}
+
+static struct platform_driver csky_reset_driver = {
+	.probe	= csky_reset_probe,
+	.driver = {
+		.name		= "csky-reset",
+		.of_match_table	= csky_reset_dt_ids,
+	},
+};
+
+static int __init csky_reset_driver_register(void)
+{
+	return platform_driver_register(&csky_reset_driver);
+}
+postcore_initcall(csky_reset_driver_register);
+
+MODULE_DESCRIPTION("C-SKY SoCs Reset Controller Driver");
+MODULE_AUTHOR("Lei Ling <lei_ling@c-sky.com>");
+MODULE_LICENSE("GPL v2");
\ No newline at end of file
diff --git a/addons/drivers/video/fbdev/Kconfig b/addons/drivers/video/fbdev/Kconfig
new file mode 100644
index 0000000..2189e67
--- /dev/null
+++ b/addons/drivers/video/fbdev/Kconfig
@@ -0,0 +1,12 @@
+
+config FB_CSKY
+	tristate "C-SKY framebuffer support"
+	depends on FB
+	select VIDEOMODE_HELPERS
+	select FB_CFB_FILLRECT
+	select FB_CFB_COPYAREA
+	select FB_CFB_IMAGEBLIT
+	default n
+	help
+	  Say Y if you want support for the C-SKY framebuffer.
+
diff --git a/addons/drivers/video/fbdev/Makefile b/addons/drivers/video/fbdev/Makefile
new file mode 100644
index 0000000..d5630da
--- /dev/null
+++ b/addons/drivers/video/fbdev/Makefile
@@ -0,0 +1,2 @@
+# C-SKY framebuffer driver
+obj-$(CONFIG_FB_CSKY) += csky-fb.o
diff --git a/addons/drivers/video/fbdev/csky-fb.c b/addons/drivers/video/fbdev/csky-fb.c
new file mode 100644
index 0000000..f736430
--- /dev/null
+++ b/addons/drivers/video/fbdev/csky-fb.c
@@ -0,0 +1,715 @@
+/*
+ * C-SKY SoCs LCDC driver
+ *
+ * Copyright (C) 2017 C-SKY MicroSystems Co.,Ltd.
+ *
+ * Author: Lei Ling <lei_ling@c-sky.com>
+ *
+ * This software is licensed under the terms of the GNU General Public
+ * License version 2, as published by the Free Software Foundation, and
+ * may be copied, distributed, and modified under those terms.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include <linux/clk.h>
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/dma-mapping.h>
+#include <linux/errno.h>
+#include <linux/string.h>
+#include <linux/slab.h>
+#include <linux/delay.h>
+#include <linux/mm.h>
+#include <linux/fb.h>
+#include <linux/init.h>
+#include <linux/interrupt.h>
+#include <linux/ioport.h>
+#include <linux/platform_device.h>
+#include <linux/uaccess.h>
+#include "csky-fb.h"
+
+#define DRIVER_NAME "csky_fb"
+
+#define VSYNC_TIMEOUT_MSEC	100
+
+
+static void csky_fb_enable_irq(struct csky_fb_info *info, u32 mask)
+{
+	u32 tmp;
+	tmp = readl(info->iobase + CSKY_LCD_INT_MASK);
+	tmp |= mask;
+	writel(tmp, info->iobase + CSKY_LCD_INT_MASK);
+	return;
+}
+
+static void csky_fb_disable_irq(struct csky_fb_info *info, u32 mask)
+{
+	u32 tmp;
+	tmp = readl(info->iobase + CSKY_LCD_INT_MASK);
+	tmp &= ~mask;
+	writel(tmp, info->iobase + CSKY_LCD_INT_MASK);
+	return;
+}
+
+/*
+ * sleep until next VSYNC interrupt or timeout
+ */
+static int csky_fb_wait_for_vsync(struct fb_info *fbinfo)
+{
+	struct csky_fb_info *info = fbinfo->par;
+	unsigned long count;
+	int ret;
+
+	count = info->vsync_info.count;
+	csky_fb_enable_irq(info, CSKY_LCDINT_MASK_BAU);
+	ret = wait_event_interruptible_timeout(
+				info->vsync_info.wait,
+				count != info->vsync_info.count,
+				msecs_to_jiffies(VSYNC_TIMEOUT_MSEC));
+	if (ret == 0)
+		return -ETIMEDOUT;
+
+	return 0;
+}
+
+static void csky_fb_set_pixel_format(struct csky_fb_info *info,
+				     enum csky_fb_pixel_format fmt)
+{
+	u32 control;
+
+	control = readl(info->iobase + CSKY_LCD_CONTROL);
+	control &= ~CSKY_LCDCON_DFS_MASK_SHIFTED;
+	control |= fmt;
+	writel(control, info->iobase + CSKY_LCD_CONTROL);
+
+	info->pixel_fmt = fmt;
+	return;
+}
+
+static void csky_fb_set_lcd_pbase(struct csky_fb_info *info,
+				  struct csky_fb_lcd_pbase_yuv *pbase)
+{
+	writel(pbase->y, info->iobase + CSKY_LCD_PBASE_Y);
+	writel(pbase->u, info->iobase + CSKY_LCD_PBASE_U);
+	writel(pbase->v, info->iobase + CSKY_LCD_PBASE_V);
+	info->pbase_yuv.y = pbase->y;
+	info->pbase_yuv.u = pbase->u;
+	info->pbase_yuv.v = pbase->v;
+	return;
+}
+
+static void csky_fb_lcd_enable(struct csky_fb_info *info)
+{
+	u32 control;
+	control = readl(info->iobase + CSKY_LCD_CONTROL);
+	control |= CSKY_LCDCON_LEN;
+	writel(control, info->iobase + CSKY_LCD_CONTROL);
+	info->lcdc_enabled = true;
+}
+
+#define LCDC_DISABLE_DONE_MAX_DELAY	100	/* in milliseconds */
+
+static void csky_fb_lcd_disable(struct csky_fb_info *info)
+{
+	u32 control;
+	u32 status;
+	int count;
+
+	/* disable lcdc */
+	control = readl(info->iobase + CSKY_LCD_CONTROL);
+	control &= ~CSKY_LCDCON_LEN;
+	writel(control, info->iobase + CSKY_LCD_CONTROL);
+
+	/* wait lcdc disable done */
+	for (count = 0; count < LCDC_DISABLE_DONE_MAX_DELAY; count++) {
+		status = readl(info->iobase + CSKY_LCD_INT_STAT);
+		if (status & CSKY_LCDINT_STAT_LDD) {
+			/* clear interrupt status */
+			writel(CSKY_LCDINT_STAT_LDD,
+			       info->iobase + CSKY_LCD_INT_STAT);
+			break;
+		}
+		mdelay(1);
+	}
+
+	info->lcdc_enabled = false;
+}
+
+static void csky_fb_lcd_reset(struct csky_fb_info *info)
+{
+	reset_control_assert(info->rst);
+	mdelay(1); /* delay >1us */
+	reset_control_deassert(info->rst);
+	mdelay(1);
+
+	info->lcdc_enabled = false;
+	return;
+}
+
+static int csky_fb_set_timing(struct fb_info *fbinfo)
+{
+	struct csky_fb_info *info = fbinfo->par;
+
+	u32 timing0 = (((info->vm.hback_porch - 1) & 0xff) << 24) |
+		      (((info->vm.hfront_porch - 1) & 0xff) << 16) |
+		      (((info->vm.hsync_len - 1) & 0x3f) << 10) |
+		      ((info->vm.hactive - 1) & 0x3ff);
+	u32 timing1 = (((info->vm.vback_porch - 1) & 0xff) << 24) |
+		      (((info->vm.vfront_porch - 1) & 0xff) << 16) |
+		      (((info->vm.vsync_len - 1) & 0x3f) << 10) |
+		      ((info->vm.vactive - 1) & 0x3ff);
+	u32 timing2 = 0;
+
+	if (info->pixel_clock_pol)
+		timing2 |= CSKY_LCDTIM2_PCP_FALLING;
+	if (info->hsync_pulse_pol)
+		timing2 |= CSKY_LCDTIM2_HSP_ACT_LOW;
+	if (info->vsync_pulse_pol)
+		timing2 |= CSKY_LCDTIM2_VSP_ACT_LOW;
+	if (info->pixel_clk_src)
+		timing2 |= CSKY_LCDTIM2_CLKS_EXT;
+	timing2 |= info->pcd & 0xff;
+
+	if (info->vm.hactive > 1024)
+		timing2 |= CSKY_LCDTIM2_PPL_MSB;
+	if (info->vm.vactive > 1024)
+		timing2 |= CSKY_LCDTIM2_LPP_MSB;
+
+	writel(timing0, info->iobase + CSKY_LCD_TIMING0);
+	writel(timing1, info->iobase + CSKY_LCD_TIMING1);
+	writel(timing2, info->iobase + CSKY_LCD_TIMING2);
+
+	return 0;
+}
+
+static int csky_fb_init_registers(struct fb_info *fbinfo)
+{
+	struct csky_fb_info *info = fbinfo->par;
+	u32 videosize;
+	u32 control;
+
+	csky_fb_set_timing(fbinfo);
+
+	/* disable all the lcdc interrupts */
+	writel(0x0, info->iobase + CSKY_LCD_INT_MASK);
+
+	videosize = ((info->vm.vactive - 1) << 11) |
+		    (info->vm.hactive - 1);
+	writel(videosize, info->iobase + CSKY_LCD_VIDEOSIZE);
+
+	/* set base address */
+	writel(fbinfo->fix.smem_start, info->iobase + CSKY_LCD_PBASE);
+	writel(info->pbase_yuv.y, info->iobase + CSKY_LCD_PBASE_Y);
+	writel(info->pbase_yuv.u, info->iobase + CSKY_LCD_PBASE_U);
+	writel(info->pbase_yuv.v, info->iobase + CSKY_LCD_PBASE_V);
+
+	control = info->pixel_fmt |
+		      CSKY_LCDCON_OUT_24BIT |
+		      CSKY_LCDCON_WML_8WORD |
+		      CSKY_LCDCON_VBL_16CYCLES |
+		      CSKY_LCDCON_PAS_TFT;
+	/* enable lcdc */
+	control |= CSKY_LCDCON_LEN;
+	writel(control, info->iobase + CSKY_LCD_CONTROL);
+
+	/* skip the vsync interrupt triggered by enabling the LCDC */
+	csky_fb_wait_for_vsync(fbinfo);
+
+	info->lcdc_enabled = true;
+	return 0;
+}
+
+static int csky_fb_check_var(struct fb_var_screeninfo *var,
+			     struct fb_info *fbinfo)
+{
+	struct csky_fb_info *info = fbinfo->par;
+
+	var->xres = info->vm.hactive;
+	var->yres = info->vm.vactive;
+	var->xres_virtual = var->xres;
+	var->yres_virtual = var->yres * 2; /* double buffer supported */
+
+	var->width = info->vm.hactive;
+	var->height = info->vm.vactive;
+
+	var->pixclock = info->vm.pixelclock;
+	var->left_margin = info->vm.hback_porch;
+	var->right_margin = info->vm.hfront_porch;
+	var->upper_margin = info->vm.vback_porch;
+	var->lower_margin = info->vm.vfront_porch;
+	var->hsync_len = info->vm.hsync_len;
+	var->vsync_len = info->vm.vsync_len;
+
+	var->transp.offset = 0;
+	var->transp.length = 0;
+	switch (var->bits_per_pixel) {
+	case 32:
+		var->red.length = 8;
+		var->red.offset = 16;
+		var->green.length = 8;
+		var->green.offset = 8;
+		var->blue.length = 8;
+		var->blue.offset = 0;
+		var->transp.length = 0; /* no support for transparency */
+		var->transp.offset = 24;
+		break;
+	default:
+		dev_err(info->dev, "bits_per_pixel(%d) not supported\n",
+			var->bits_per_pixel);
+		break;
+	}
+	return 0;
+}
+
+static int csky_fb_set_par(struct fb_info *fbinfo)
+{
+	return 0;
+}
+
+static int csky_fb_blank(int blank_mode, struct fb_info *fbinfo)
+{
+	struct csky_fb_info *info = fbinfo->par;
+
+	switch (blank_mode) {
+	case FB_BLANK_UNBLANK:
+		/* enable/init lcdc */
+		if (!info->lcdc_enabled)
+			csky_fb_init_registers(fbinfo);
+		break;
+	case FB_BLANK_NORMAL:
+	case FB_BLANK_VSYNC_SUSPEND:
+	case FB_BLANK_HSYNC_SUSPEND:
+	case FB_BLANK_POWERDOWN:
+		/* disable/reset lcdc */
+		if (info->lcdc_enabled) {
+			csky_fb_wait_for_vsync(fbinfo);
+			csky_fb_lcd_disable(info);
+			csky_fb_lcd_reset(info);
+		}
+		break;
+	default:
+		break;
+	}
+	return 0;
+}
+
+static int csky_fb_setcolreg(unsigned regno,
+			     unsigned red, unsigned green, unsigned blue,
+			     unsigned transp, struct fb_info *info)
+{
+	return 0;
+}
+
+static int csky_fb_pan_display(struct fb_var_screeninfo *var,
+			       struct fb_info *fbinfo)
+{
+	struct csky_fb_info *info = fbinfo->par;
+	unsigned long base;
+
+	/*
+	 * adjust the position of visible screen
+	 * note: xoffset not supported
+	 */
+	base = fbinfo->fix.smem_start +
+	       var->yoffset * fbinfo->fix.line_length;
+	writel(base, info->iobase + CSKY_LCD_PBASE);
+	return 0;
+}
+
+static int csky_fb_set_out_mode(struct fb_info *fbinfo,
+				enum csky_fb_out_mode mode)
+{
+	int ret;
+	struct videomode vm;
+	struct csky_fb_info *info = fbinfo->par;
+	struct device *dev = info->dev;
+	u32 hclk_freq = info->hclk_freq;
+	struct device_node *screen_node;
+
+	screen_node = of_parse_phandle(dev->of_node, "screen-timings", 0);
+	ret = of_get_videomode(screen_node, &vm, mode);
+	if (ret) {
+		dev_err(dev, "Failed to get videomode from DT\n");
+		return ret;
+	}
+	if (memcmp(&info->vm, &vm, sizeof(vm))) {
+		memcpy(&info->vm, &vm, sizeof(vm));
+		info->pcd = hclk_freq / (vm.pixelclock * 2) - 1;
+		csky_fb_check_var(&fbinfo->var, fbinfo);
+		csky_fb_set_timing(fbinfo);
+	}
+
+	return 0;
+}
+
+static int csky_fb_ioctl(struct fb_info *fbinfo,
+			 unsigned int cmd,
+			 unsigned long arg)
+{
+	struct csky_fb_info *info = fbinfo->par;
+	void __user *argp = (void __user *)arg;
+	int ret = 0;
+
+	switch (cmd) {
+	case FBIO_WAITFORVSYNC:
+		ret = csky_fb_wait_for_vsync(fbinfo);
+		break;
+
+	case CSKY_FBIO_SET_PIXEL_FMT:
+		{
+			enum csky_fb_pixel_format fmt;
+
+			if (copy_from_user(&fmt, argp, sizeof(fmt))) {
+				ret = -EFAULT;
+				break;
+			}
+
+			if (fmt == info->pixel_fmt)
+				break;
+
+			csky_fb_set_pixel_format(info, fmt);
+			break;
+		}
+
+	case CSKY_FBIO_GET_PIXEL_FMT:
+		{
+			if (copy_to_user(argp, &info->pixel_fmt,
+					 sizeof(info->pixel_fmt)))
+				ret = -EFAULT;
+			break;
+		}
+
+	case CSKY_FBIO_SET_PBASE_YUV:
+		{
+			struct csky_fb_lcd_pbase_yuv base;
+
+			if (copy_from_user(&base, argp, sizeof(base))) {
+				ret = -EFAULT;
+				break;
+			}
+
+			if ((base.y == info->pbase_yuv.y) &&
+			    (base.u == info->pbase_yuv.u) &&
+			    (base.v == info->pbase_yuv.v))
+				break;
+
+			csky_fb_set_lcd_pbase(info, &base);
+			break;
+		}
+	case CSKY_FBIO_SET_OUT_MODE:
+		{
+			enum csky_fb_out_mode mode;
+
+			if (copy_from_user(&mode, argp, sizeof(mode))) {
+				ret = -EFAULT;
+				break;
+			}
+
+			csky_fb_set_out_mode(fbinfo, mode);
+			break;
+		}
+	default:
+		ret = -ENOIOCTLCMD;
+	}
+
+	return ret;
+}
+
+static struct fb_ops csky_fb_ops = {
+	.owner          = THIS_MODULE,
+	.fb_check_var   = csky_fb_check_var,
+	.fb_set_par     = csky_fb_set_par,
+	.fb_blank       = csky_fb_blank,
+	.fb_setcolreg   = csky_fb_setcolreg,
+	.fb_pan_display = csky_fb_pan_display,
+	.fb_ioctl       = csky_fb_ioctl,
+	.fb_fillrect    = cfb_fillrect,
+	.fb_copyarea    = cfb_copyarea,
+	.fb_imageblit   = cfb_imageblit,
+};
+
+static int csky_fb_map_video_memory(struct fb_info *fbinfo)
+{
+	struct csky_fb_info *info = fbinfo->par;
+	phys_addr_t map_phys;
+	/* apply for max size. 1080p single buffer */
+	unsigned map_size = PAGE_ALIGN(CSKY_FB_1080P_SIZE *
+				       (fbinfo->var.bits_per_pixel / 8));
+
+	fbinfo->screen_base = kmalloc(map_size, GFP_KERNEL);
+
+	if (fbinfo->screen_base == NULL) {
+		return -ENOMEM;
+	}
+
+	map_phys = virt_to_phys(fbinfo->screen_base);
+	memset(fbinfo->screen_base, 0, map_size);
+	fbinfo->fix.smem_start = map_phys;
+	fbinfo->fix.smem_len = map_size;
+
+	info->pbase_yuv.y = fbinfo->fix.smem_start;
+	info->pbase_yuv.u = info->pbase_yuv.y;
+	info->pbase_yuv.v = info->pbase_yuv.y;
+	return 0;
+}
+
+static inline void csky_fb_unmap_video_memory(struct fb_info *fbinfo)
+{
+	kfree(fbinfo->screen_base);
+
+	return;
+}
+
+static irqreturn_t csky_fb_irq(int irq, void *dev_id)
+{
+	struct csky_fb_info *info = dev_id;
+	unsigned long status;
+
+	raw_spin_lock(&info->slock);
+
+	status = readl(info->iobase + CSKY_LCD_INT_STAT);
+	/* clear interrupts */
+	writel(status, info->iobase + CSKY_LCD_INT_STAT);
+
+	if (status & CSKY_LCDINT_STAT_BAU) { /* VSYNC interrupt */
+		info->vsync_info.count++;
+		wake_up_interruptible(&info->vsync_info.wait);
+		/* disable vsync interrupt */
+		csky_fb_disable_irq(info, CSKY_LCDINT_MASK_BAU);
+	}
+
+	raw_spin_unlock(&info->slock);
+	return IRQ_HANDLED;
+}
+
+static int csky_fb_probe(struct platform_device *pdev)
+{
+	int irq;
+	struct resource *mem;
+	void __iomem *iobase;
+	struct reset_control *rst;
+	u32 bits_per_pixel;
+	u32 hclk_freq;
+	u32 pixel_clk_src; /* pixel clock source */
+	u32 hsync_pulse_pol; /* HSYNC pulse polarity */
+	u32 vsync_pulse_pol; /* VSYNC pulse polarity */
+	u32 pixel_clock_pol; /* pixel clock polarity */
+	struct device *dev = &pdev->dev;
+	struct videomode vm;
+	struct fb_info *fbinfo;
+	struct csky_fb_info *info;
+	struct clk *hclk;
+	struct device_node *screen_node;
+	int ret;
+
+	/* get resources */
+
+	irq = platform_get_irq(pdev, 0);
+	if (irq < 0)
+		return irq;
+
+	mem = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	iobase = devm_ioremap_resource(dev, mem);
+	if (IS_ERR(iobase))
+		return PTR_ERR(iobase);
+
+	rst = devm_reset_control_get(&pdev->dev, NULL);
+	if (IS_ERR(rst)) {
+		dev_err(&pdev->dev, "Failed to get reset control\n");
+		return PTR_ERR(rst);
+	}
+
+	hclk = devm_clk_get(&pdev->dev, NULL);
+	if (IS_ERR(hclk)) {
+		dev_err(&pdev->dev, "Failed to get hclk");
+		return PTR_ERR(hclk);
+	}
+
+	hclk_freq = clk_get_rate(hclk);
+	if (!hclk_freq) {
+		dev_err(&pdev->dev, "Failed, hclk is 0!\n");
+		return -EINVAL;
+	}
+
+	ret = of_property_read_u32(dev->of_node, "bits-per-pixel",
+				   &bits_per_pixel);
+	if (ret < 0) {
+		dev_err(&pdev->dev, "Failed to get property bits-per-pixel\n");
+		return ret;
+	}
+
+	ret = of_property_read_u32(dev->of_node,
+				   "pixel-clock-source", &pixel_clk_src);
+	if (ret < 0) {
+		dev_err(&pdev->dev,
+			"Failed to get property pixel-clock-source\n");
+		return ret;
+	}
+
+	ret = of_property_read_u32(dev->of_node,
+				   "hsync-pulse-pol", &hsync_pulse_pol);
+	if (ret < 0) {
+		dev_err(&pdev->dev, "Failed to get property hsync-pulse-pol\n");
+		return ret;
+	}
+
+	ret = of_property_read_u32(dev->of_node,
+				   "vsync-pulse-pol", &vsync_pulse_pol);
+	if (ret < 0) {
+		dev_err(&pdev->dev, "Failed to get property vsync-pulse-pol\n");
+		return ret;
+	}
+
+	ret = of_property_read_u32(dev->of_node,
+				   "pixel-clock-pol", &pixel_clock_pol);
+	if (ret < 0) {
+		dev_err(&pdev->dev, "Failed to get property pixel-clock-pol\n");
+		return ret;
+	}
+
+	screen_node = of_parse_phandle(dev->of_node, "screen-timings", 0);
+	ret = of_get_videomode(screen_node, &vm, OF_USE_NATIVE_MODE);
+	if (ret) {
+		dev_err(&pdev->dev, "Failed to get videomode from DT\n");
+		return ret;
+	}
+
+	/* allocate a fb_info */
+	fbinfo = framebuffer_alloc(sizeof(struct csky_fb_info), &pdev->dev);
+	if (!fbinfo)
+		return -ENOMEM;
+	platform_set_drvdata(pdev, fbinfo);
+
+	/* initialize the fb_info */
+
+	info = fbinfo->par;
+	spin_lock_init(&info->slock);
+	info->dev = &pdev->dev;
+	info->iobase = iobase;
+	info->rst = rst;
+	info->irq = irq;
+	memcpy(&info->vm, &vm, sizeof(vm));
+	info->pixel_clk_src = pixel_clk_src;
+	info->hclk_freq = hclk_freq;
+	info->hsync_pulse_pol = hsync_pulse_pol;
+	info->vsync_pulse_pol = vsync_pulse_pol;
+	info->pixel_clock_pol = pixel_clock_pol;
+	init_waitqueue_head(&info->vsync_info.wait);
+	info->pixel_fmt = CSKY_LCDCON_DFS_RGB;
+
+	if (hclk_freq % (vm.pixelclock * 2) != 0) {
+		dev_err(&pdev->dev, "Failed to calculate the value of pcd\n");
+		return -EINVAL;
+	}
+	info->pcd = hclk_freq / (vm.pixelclock * 2) - 1;
+
+	strcpy(fbinfo->fix.id, DRIVER_NAME);
+	fbinfo->fix.smem_len = vm.hactive * vm.vactive *
+			       (bits_per_pixel / 8) *
+			       2; /* double buffer supported */
+	fbinfo->fix.type = FB_TYPE_PACKED_PIXELS;
+	fbinfo->fix.type_aux = 0;
+	fbinfo->fix.visual = FB_VISUAL_TRUECOLOR;
+	fbinfo->fix.xpanstep = 0;
+	fbinfo->fix.ypanstep = 1; /* double buffer supported */
+	fbinfo->fix.ywrapstep = 0;
+	fbinfo->fix.line_length = vm.hactive * (bits_per_pixel / 8);
+	fbinfo->fix.mmio_start = mem->start;
+	fbinfo->fix.mmio_len = mem->end - mem->start + 1;
+	fbinfo->fix.accel = FB_ACCEL_NONE;
+
+	fbinfo->var.xres = vm.hactive;
+	fbinfo->var.yres = vm.vactive;
+	fbinfo->var.xres_virtual = fbinfo->var.xres;
+	fbinfo->var.yres_virtual = fbinfo->var.yres;
+	fbinfo->var.xoffset = 0;
+	fbinfo->var.yoffset = 0;
+	fbinfo->var.bits_per_pixel = bits_per_pixel;
+	fbinfo->var.grayscale = 0;
+	fbinfo->var.nonstd = 0;
+	fbinfo->var.activate = FB_ACTIVATE_NOW;
+	fbinfo->var.accel_flags = 0;
+	fbinfo->var.vmode = FB_VMODE_NONINTERLACED;
+
+	fbinfo->fbops = &csky_fb_ops;
+	fbinfo->flags = FBINFO_FLAG_DEFAULT;
+
+	/* allocate video memory */
+	ret = csky_fb_map_video_memory(fbinfo);
+	if (ret) {
+		dev_err(&pdev->dev, "Failed to allocate video memory\n");
+		goto RELEASE_FBINFO;
+	}
+
+	csky_fb_check_var(&fbinfo->var, fbinfo);
+
+	csky_fb_init_registers(fbinfo);
+
+	ret = register_framebuffer(fbinfo);
+	if (ret < 0) {
+		dev_err(&pdev->dev, "Failed to register framebuffer device\n");
+		goto FREE_VIDEO_MEMORY;
+	}
+
+	ret = request_irq(irq, csky_fb_irq, 0, pdev->name, info);
+	if (ret) {
+		dev_err(&pdev->dev, "Failed to get irq %d, err %d\n", irq, ret);
+		goto UNREGISTER_FB;
+	}
+
+	dev_info(&pdev->dev, "fb%d: %s frame buffer device\n",
+		 fbinfo->node, fbinfo->fix.id);
+	return 0;
+
+UNREGISTER_FB:
+	unregister_framebuffer(fbinfo);
+FREE_VIDEO_MEMORY:
+	csky_fb_unmap_video_memory(fbinfo);
+RELEASE_FBINFO:
+	framebuffer_release(fbinfo);
+	return ret;
+}
+
+static int csky_fb_remove(struct platform_device *pdev)
+{
+	struct fb_info *fbinfo = platform_get_drvdata(pdev);
+	struct csky_fb_info *info = fbinfo->par;
+
+	csky_fb_lcd_reset(info);
+
+	free_irq(info->irq, info);
+
+	unregister_framebuffer(fbinfo);
+
+	csky_fb_unmap_video_memory(fbinfo);
+
+	platform_set_drvdata(pdev, NULL);
+
+	framebuffer_release(fbinfo);
+	return 0;
+}
+
+static const struct of_device_id csky_fb_of_dev_id[] = {
+	{ .compatible = "csky,lcdc-v1", },
+	{ }
+};
+MODULE_DEVICE_TABLE(of, csky_fb_of_dev_id);
+
+static struct platform_driver csky_fb_driver = {
+	.probe	= csky_fb_probe,
+	.remove	= csky_fb_remove,
+	.driver	= {
+		.name = DRIVER_NAME,
+		.of_match_table = csky_fb_of_dev_id,
+	}
+};
+
+module_platform_driver(csky_fb_driver);
+
+MODULE_DESCRIPTION("C-SKY SoCs LCDC Driver");
+MODULE_AUTHOR("Lei Ling <lei_ling@c-sky.com>");
+MODULE_LICENSE("GPL v2");
diff --git a/addons/drivers/video/fbdev/csky-fb.h b/addons/drivers/video/fbdev/csky-fb.h
new file mode 100644
index 0000000..48c24a4
--- /dev/null
+++ b/addons/drivers/video/fbdev/csky-fb.h
@@ -0,0 +1,196 @@
+/*
+ * C-SKY SoCs LCDC driver
+ *
+ * Copyright (C) 2017 C-SKY MicroSystems Co.,Ltd.
+ *
+ * Author: Lei Ling <lei_ling@c-sky.com>
+ *
+ * This software is licensed under the terms of the GNU General Public
+ * License version 2, as published by the Free Software Foundation, and
+ * may be copied, distributed, and modified under those terms.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef __CSKY_FB_H__
+#define __CSKY_FB_H__
+
+#include <video/display_timing.h>
+#include <video/of_display_timing.h>
+#include <video/of_videomode.h>
+#include <video/videomode.h>
+#include <linux/reset.h>
+
+/* LCDC registers */
+#define CSKY_LCD_CONTROL	0x00
+#define CSKY_LCD_TIMING0	0x04
+#define CSKY_LCD_TIMING1	0x08
+#define CSKY_LCD_TIMING2	0x0c
+#define CSKY_LCD_PBASE		0x10
+#define CSKY_LCD_PCURR		0x18
+#define CSKY_LCD_INT_STAT	0x20
+#define CSKY_LCD_INT_MASK	0x24
+#define CSKY_LCD_DP1_2		0x28
+#define CSKY_LCD_DP4_7		0x2c
+#define CSKY_LCD_DP3_5		0x30
+#define CSKY_LCD_DP2_3		0x34
+#define CSKY_LCD_DP5_7		0x38
+#define CSKY_LCD_DP3_4		0x3c
+#define CSKY_LCD_DP4_5		0x40
+#define CSKY_LCD_DP6_7		0x44
+#define CSKY_LCD_PBASE_Y	0x48
+#define CSKY_LCD_PBASE_U	0x50
+#define CSKY_LCD_PBASE_V	0x58
+#define CSKY_LCD_VIDEOSIZE	0x60
+#define CSKY_LCD_PALETTE_BASE	0x800
+
+#define CSKY_LCD_PALETTE_ENTRIES_NUM	256
+#define CSKY_FB_1080P_SIZE		(1920 * 1080)
+
+/* bits definition */
+
+/*
+ * LCD_CONTROL register
+ */
+
+/* LEN, LCD controller Enable */
+#define CSKY_LCDCON_LEN			1
+/*
+ * CMS, *STN LCD* color/monochrome select
+ * 0: Monochrome
+ * 1: Color
+ * Note: CMS is ignored in active/TFT mode (PAS=1)
+ */
+#define CSKY_LCDCON_CMS_COLOR		(1 << 1)
+/*
+ * PAS, Passive/active display select
+ * 0: Passive or STN display
+ * 1: Active or TFT display
+ */
+#define CSKY_LCDCON_PAS_TFT		(1 << 3)
+/* PBS, Pixel bit size */
+#define CSKY_LCDCON_PBS_8BITS		(1 << 5)
+#define CSKY_LCDCON_PBS_16BITS		(2 << 5)
+/* BES, Little/ Big-endian Select(read only) */
+#define CSKY_LCDCON_BES_BIG		(1 << 8)
+/* VBL: Video memory Burst Length */
+#define CSKY_LCDCON_VBL_1CYCLES		(0 << 9)
+#define CSKY_LCDCON_VBL_4CYCLES		(1 << 9)
+#define CSKY_LCDCON_VBL_8CYCLES		(2 << 9)
+#define CSKY_LCDCON_VBL_16CYCLES	(3 << 9)
+/* WML, LCD DMA FIFO Watermark level. 0=4, 1=8 */
+#define CSKY_LCDCON_WML_8WORD		(1 << 11)
+/*
+ * Real color/pseudo color select
+ * 0: pseudo colors 8bit or 16bit (which depend on PBS)
+ * 1: RGB data is 24bit
+ */
+#define CSKY_LCDCON_OUT_24BIT		(1 << 12)
+/*
+ * DFS, Data format select(Storage format of YUV is planar mode)
+ */
+#define CSKY_LCDCON_DFS_RGB		(0 << 13)
+#define CSKY_LCDCON_DFS_YUV444		(1 << 13)
+#define CSKY_LCDCON_DFS_YUV422		(2 << 13)
+#define CSKY_LCDCON_DFS_YUV420		(3 << 13)
+#define CSKY_LCDCON_DFS_MASK_SHIFTED	(3 << 13)
+
+/*
+ * LCD_TIMING2 register
+ */
+
+/* CLKS, Pixel clock source select */
+#define CSKY_LCDTIM2_CLKS_HCLK		(0 << 8) /* HCLK */
+#define CSKY_LCDTIM2_CLKS_EXT		(1 << 8) /* External clock */
+/* VSP, Vertical sync polarity (VSYNC pulse polarity) */
+#define CSKY_LCDTIM2_VSP_ACT_LOW	(1 << 9)
+/* HSP, Horizontal sync polarity (HSYNC pulse polarity) */
+#define CSKY_LCDTIM2_HSP_ACT_LOW	(1 << 10)
+/* PCP, Pixel clock polarity */
+#define CSKY_LCDTIM2_PCP_RISING		(0 << 11)
+#define CSKY_LCDTIM2_PCP_FALLING	(1 << 11)
+/* OEP, Output Enable polarity */
+#define CSKY_LCDTIM2_OEP_ACT_LOW	(1 << 12)
+
+#define CSKY_LCDTIM2_PPL_MSB		(1 << 24)
+#define CSKY_LCDTIM2_LPP_MSB		(1 << 25)
+
+/*
+ * LCD_INT_STAT register
+ */
+#define CSKY_LCDINT_STAT_LDD	(1 << 0) /* LDD, LCD disable done status */
+#define CSKY_LCDINT_STAT_BAU	(1 << 1) /* BAU, Base address update flag */
+#define CSKY_LCDINT_STAT_BER	(1 << 2) /* BER, Bus error status */
+#define CSKY_LCDINT_STAT_LFU	(1 << 3) /* LFU, Line FIFO under run status */
+/*
+ * LCD_INT_MASK register
+ * 0: disable interrupt
+ * 1: enable interrupt
+ */
+#define CSKY_LCDINT_MASK_LDD	(1 << 0)
+#define CSKY_LCDINT_MASK_BAU	(1 << 1)
+#define CSKY_LCDINT_MASK_BER	(1 << 2)
+#define CSKY_LCDINT_MASK_LFU	(1 << 3)
+
+/**
+ * struct csky_fb_vsync - vsync information
+ * @wait:  a queue for processes waiting for vsync
+ * @count: vsync interrupt count
+ */
+struct csky_fb_vsync {
+	wait_queue_head_t wait;
+	unsigned int count;
+};
+
+#define CSKY_FBIO_BASE	0x30
+#define CSKY_FBIO_SET_PIXEL_FMT	_IOW('F', CSKY_FBIO_BASE+0, \
+					enum csky_fb_pixel_format)
+#define CSKY_FBIO_GET_PIXEL_FMT	_IOW('F', CSKY_FBIO_BASE+1, \
+					enum csky_fb_pixel_format)
+#define CSKY_FBIO_SET_PBASE_YUV	_IOW('F', CSKY_FBIO_BASE+2, \
+					struct csky_fb_lcd_pbase_yuv)
+#define CSKY_FBIO_SET_OUT_MODE	_IOW('F', CSKY_FBIO_BASE+3, \
+					enum csky_fb_out_mode)
+
+enum csky_fb_pixel_format {
+	CSKY_FB_PIXEL_FMT_RGB = CSKY_LCDCON_DFS_RGB,
+	CSKY_FB_PIXEL_FMT_YUV444 = CSKY_LCDCON_DFS_YUV444,
+	CSKY_FB_PIXEL_FMT_YUV422 = CSKY_LCDCON_DFS_YUV422,
+	CSKY_FB_PIXEL_FMT_YUV420 = CSKY_LCDCON_DFS_YUV420,
+};
+
+enum csky_fb_out_mode {
+	CSKY_FB_OUT_LCD_MODE = 0,
+	CSKY_FB_OUT_HDMI_MODE,
+};
+
+struct csky_fb_lcd_pbase_yuv {
+	unsigned int y; /* LCD_PBASE_Y */
+	unsigned int u; /* LCD_PBASE_U */
+	unsigned int v; /* LCD_PBASE_V */
+};
+
+struct csky_fb_info {
+	spinlock_t slock;
+	struct device *dev;
+	void __iomem *iobase;
+	struct reset_control *rst;
+	int irq;
+	struct clk *clk;
+	struct videomode vm;
+	u32 pixel_clk_src;	/* pixel clock source */
+	u32 hclk_freq;		/* hclk frequence */
+	u32 pcd;		/* pixel clock divider. f=HCLK/2(pcd+1) */
+	u32 hsync_pulse_pol;	/* HSYNC pulse polarity */
+	u32 vsync_pulse_pol;	/* VSYNC pulse polarity */
+	u32 pixel_clock_pol;	/* pixel clock polarity */
+	struct csky_fb_vsync vsync_info;
+	enum csky_fb_pixel_format pixel_fmt;
+	struct csky_fb_lcd_pbase_yuv pbase_yuv;
+	bool lcdc_enabled;	/* indicate whether the lcdc is enabled */
+};
+
+#endif /* __CSKY_FB_H__ */
diff --git a/addons/drivers/vpu/Kconfig b/addons/drivers/vpu/Kconfig
new file mode 100644
index 0000000..49090e0
--- /dev/null
+++ b/addons/drivers/vpu/Kconfig
@@ -0,0 +1,24 @@
+#
+# C-SKY VPU driver configuration
+#
+
+menuconfig CSKY_VPU
+	bool "VPU support"
+
+if CSKY_VPU
+config DEBUG_VPU
+	bool "Debug VPU calls"
+	depends on DEBUG_KERNEL
+	help
+	  Say Y here to add some extra checks and diagnostics to PINCTRL calls.
+
+config VPU_CODA7541
+	tristate "cnm coda7541 driver support"
+	depends on OF
+	select VIDEO_CODA
+
+config FORCE_MAX_ZONEORDER
+	int "Max kmalloc size. Set to 12 is 8MB for FHD(1080p) output frame buffer"
+	default 11
+endif
+
diff --git a/addons/drivers/watchdog/Kconfig b/addons/drivers/watchdog/Kconfig
new file mode 100644
index 0000000..caf5c99
--- /dev/null
+++ b/addons/drivers/watchdog/Kconfig
@@ -0,0 +1,12 @@
+#
+# C-SKY watchdog  driver configuration
+#
+
+config CSKY_WDT
+	bool "C-SKY Watchdog Driver"
+	depends on OF
+	select WATCHDOG_CORE
+	select WATCHDOG
+	help
+	  This enables the watchdog driver for C-SKY.
+
diff --git a/addons/drivers/watchdog/Makefile b/addons/drivers/watchdog/Makefile
new file mode 100644
index 0000000..9feb420
--- /dev/null
+++ b/addons/drivers/watchdog/Makefile
@@ -0,0 +1,2 @@
+# C-SKY watchdog drivers
+obj-$(CONFIG_CSKY_WDT)	+= csky-wdt.o
diff --git a/addons/drivers/watchdog/csky-wdt.c b/addons/drivers/watchdog/csky-wdt.c
new file mode 100644
index 0000000..1aeba1f
--- /dev/null
+++ b/addons/drivers/watchdog/csky-wdt.c
@@ -0,0 +1,275 @@
+/*
+ * watchdog driver for C-SKY's SoCs.
+ *
+ * Copyright (C) 2017 C-SKY MicroSystems Co.,Ltd.
+ * Author: Huoqing Cai <huoqing_cai@c-sky.com>
+ *
+ * This software is licensed under the terms of the GNU General Public
+ * License version 2, as published by the Free Software Foundation, and
+ * may be copied, distributed, and modified under those terms.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ */
+
+#include <linux/clk.h>
+#include <linux/reboot.h>
+#include <linux/interrupt.h>
+#include <linux/io.h>
+#include <linux/module.h>
+#include <linux/of.h>
+#include <linux/platform_device.h>
+#include <linux/signal.h>
+#include <linux/string.h>
+#include <linux/delay.h>
+#include "csky-wdt.h"
+
+static int csky_wdt_calc_period(struct csky_wdt_priv *priv)
+{
+	int i;
+	unsigned long counters;
+	u32 period = 0;
+	struct watchdog_device *wdd;
+
+	wdd = &priv->wdd;
+	counters = priv->wdt_cnts >> 16;
+
+	/* transfer counters to period */
+	for (i = 0; i < 16; ++i) {
+		if (counters < 2) {
+			period = i;
+			break;
+		}
+		counters = counters >> 1;
+	}
+
+	/* max period is 15 and the period round up */
+	priv->wdt_period = period;
+
+	return 0;
+}
+
+static int csky_wdt_feed(struct watchdog_device *wdd)
+{
+	struct csky_wdt_priv *priv = watchdog_get_drvdata(wdd);
+
+	/* WDT counter restart */
+	iowrite32(WDTCNF_CCR_EN, priv->iobase + WDT_CRR);
+	iowrite32(WDTCNF_CR_RMOD_INT |
+		  ioread32(priv->iobase + WDT_CR),
+		  priv->iobase + WDT_CR);
+
+	return 0;
+}
+
+static unsigned int csky_wdt_gettimeleft(struct watchdog_device *wdd)
+{
+	struct csky_wdt_priv *priv = watchdog_get_drvdata(wdd);
+	unsigned long counters;
+
+	counters = ioread32(priv->iobase + WDT_CCVR);
+
+	return DIV_ROUND_CLOSEST(counters, priv->wdt_freq);
+}
+
+
+static int csky_wdt_updatetimeout(struct csky_wdt_priv *priv)
+{
+	csky_wdt_calc_period(priv);
+	iowrite32(priv->wdt_period, priv->iobase + WDT_TORR);
+
+	return 0;
+}
+
+static int csky_wdt_enable(struct watchdog_device *wdd)
+{
+	struct csky_wdt_priv *priv = watchdog_get_drvdata(wdd);
+
+	iowrite32(WDTCNF_TORR_DEFAULT, priv->iobase + WDT_TORR);
+	iowrite32(WDTCNF_CR_EN |
+		  ioread32(priv->iobase + WDT_CR),
+		  priv->iobase + WDT_CR);
+	iowrite32(WDTCNF_CCR_EN, priv->iobase + WDT_CRR);
+
+	return 0;
+}
+
+static int csky_sys_restart(struct notifier_block *this,
+			    unsigned long mode, void *cmd)
+{
+	struct csky_wdt_priv *priv = container_of(this, struct csky_wdt_priv,
+						  restart_handler);
+
+	iowrite32(0x0, priv->iobase + WDT_TORR);
+	iowrite32(WDTCNF_CR_EN |
+		  ioread32(priv->iobase + WDT_CR),
+		  priv->iobase + WDT_CR);
+	iowrite32(WDTCNF_CCR_EN, priv->iobase + WDT_CRR);
+
+	return 0;
+}
+
+static int csky_wdt_disable(struct watchdog_device *wdd)
+{
+	struct csky_wdt_priv *priv = watchdog_get_drvdata(wdd);
+
+	/*
+	 * disable wdt controler
+	 * Once this bit has been enabled,
+	 * it can only be cleared by a system reset.
+	 */
+	iowrite32(WDTCNF_CR_DIS &
+		  ioread32(priv->iobase + WDT_CR),
+		  priv->iobase + WDT_CR);
+
+	return 0;
+}
+
+static int csky_wdt_settimeout(struct watchdog_device *wdd, unsigned int to)
+{
+	struct csky_wdt_priv *priv = watchdog_get_drvdata(wdd);
+
+	wdd->timeout = to;
+	priv->wdt_cnts = wdd->timeout * priv->wdt_freq;
+	if (priv->wdt_cnts > WDT_MAX_COUNTS) {
+		dev_err(priv->dev, "timeout %d too big\n", wdd->timeout);
+		return -EINVAL;
+	}
+	csky_wdt_updatetimeout(priv);
+	csky_wdt_feed(wdd);
+
+	return 0;
+}
+
+static irqreturn_t csky_wdt_irq(int irq, void *devid)
+{
+	u32 clr_intr;
+	struct csky_wdt_priv *priv = devid;
+
+	/* read-clear type interupt */
+	clr_intr = ioread32(priv->iobase + WDT_EOI);
+	iowrite32(WDTCNF_CR_RMOD_RST &
+		  ioread32(priv->iobase + WDT_CR),
+		  priv->iobase + WDT_CR);
+
+	return IRQ_HANDLED;
+}
+
+static const struct watchdog_info csky_wdt_ident = {
+	.options	= WDIOF_SETTIMEOUT |
+			  WDIOF_KEEPALIVEPING |
+			  WDIOF_MAGICCLOSE,
+	.identity	= "csky watchdog",
+};
+
+static struct watchdog_ops csky_wdt_ops = {
+	.owner		= THIS_MODULE,
+	.start		= csky_wdt_enable,
+	.stop		= csky_wdt_disable,
+	.get_timeleft	= csky_wdt_gettimeleft,
+	.ping		= csky_wdt_feed,
+	.set_timeout	= csky_wdt_settimeout,
+	.restart	= NULL,
+};
+
+static int csky_wdt_probe(struct platform_device *pdev)
+{
+	struct csky_wdt_priv *priv;
+	struct watchdog_device *wdd;
+	struct resource *res;
+	unsigned long clk;
+	int ret;
+
+	priv = devm_kzalloc(&pdev->dev,
+			    sizeof(struct csky_wdt_priv),
+			    GFP_KERNEL);
+	if (!priv)
+		return -ENOMEM;
+
+	priv->dev = &pdev->dev;
+
+	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	priv->iobase = devm_ioremap_resource(&pdev->dev, res);
+	if (IS_ERR(priv->iobase))
+		return PTR_ERR(priv->iobase);
+
+	priv->clk_apb = devm_clk_get(priv->dev, NULL);
+	if (IS_ERR(priv->clk_apb)) {
+		dev_err(priv->dev, "Failed to get \"apb\" clk\n");
+		return PTR_ERR(priv->clk_apb);
+	}
+
+	clk = clk_get_rate(priv->clk_apb);
+	if (!clk) {
+		dev_err(priv->dev, "Failed, apb clk is 0!\n");
+		return -EINVAL;
+	}
+
+	priv->wdt_freq = clk;
+	wdd = &priv->wdd;
+	wdd->info = &csky_wdt_ident;
+	wdd->ops = &csky_wdt_ops;
+	wdd->parent = &pdev->dev;
+
+	watchdog_set_drvdata(wdd, priv);
+
+	priv->irq = platform_get_irq(pdev, 0);
+
+	if (priv->irq > 0) {
+		/*
+		 * Not all supported platforms specify an interrupt for the
+		 * watchdog, so let's make it optional.
+		 */
+		ret = devm_request_irq(&pdev->dev, priv->irq,
+				       csky_wdt_irq, 0, pdev->name, priv);
+		if (ret < 0)
+			dev_warn(&pdev->dev, "failed to request IRQ\n");
+	}
+
+	ret = watchdog_register_device(wdd);
+	if (ret)
+		return ret;
+
+	platform_set_drvdata(pdev, priv);
+	priv->restart_handler.notifier_call = csky_sys_restart;
+	priv->restart_handler.priority = 128;
+	register_restart_handler(&priv->restart_handler);
+
+	return 0;
+}
+
+static int csky_wdt_remove(struct platform_device *pdev)
+{
+	struct csky_wdt_priv *priv = platform_get_drvdata(pdev);
+
+	csky_wdt_disable(&priv->wdd);
+	unregister_restart_handler(&priv->restart_handler);
+	watchdog_unregister_device(&priv->wdd);
+
+	return 0;
+}
+
+static const struct of_device_id csky_wdt_of_match[] = {
+	{ .compatible = "csky,wdt-v1"},
+	{},
+};
+
+MODULE_DEVICE_TABLE(of, csky_wdt_of_match);
+
+static struct platform_driver csky_wdt_driver = {
+	.probe	= csky_wdt_probe,
+	.remove	= csky_wdt_remove,
+	.driver = {
+		.name = DRIVER_NAME,
+		.of_match_table = csky_wdt_of_match,
+	},
+};
+
+module_platform_driver(csky_wdt_driver);
+
+MODULE_AUTHOR("Huoqing Cai <huoqing_cai@c-sky.com>");
+MODULE_DESCRIPTION("CSKY Watchdog");
+MODULE_LICENSE("GPL v2");
diff --git a/addons/drivers/watchdog/csky-wdt.h b/addons/drivers/watchdog/csky-wdt.h
new file mode 100644
index 0000000..d2450a2
--- /dev/null
+++ b/addons/drivers/watchdog/csky-wdt.h
@@ -0,0 +1,40 @@
+#ifndef __CSKY_WDT_H__
+#define __CSKY_WDT_H__
+
+#include <linux/watchdog.h>
+
+#define DRIVER_NAME	"csky-wdt"
+
+/* WDT control registers */
+#define WDT_CR		0x00	/*Control Register*/
+#define WDT_TORR	0x04	/*Timeout Range Register*/
+#define WDT_CCVR	0x08	/*Current Counter Value Register*/
+#define WDT_CRR		0x0c	/*Current Counter Value Register*/
+#define WDT_STAT	0x10	/*Interrupt Status Register*/
+#define WDT_EOI		0x14	/*Interrupt Clear Register*/
+
+/* Bitfields in WDT */
+#define WDTCNF_TORR_DEFAULT	0x0f
+#define WDTCNF_CCR_EN		0x76
+#define WDTCNF_CR_EN		BIT(0)
+#define WDTCNF_CR_RMOD_INT	BIT(1)
+#define WDTCNF_CR_DIS		(~ WDTCNF_CR_EN)
+#define WDTCNF_CR_RMOD_RST	(~ WDTCNF_CR_RMOD_INT)
+
+#define WDT_MAX_COUNTS		BIT(31)
+
+
+struct csky_wdt_priv {
+	struct device		*dev;
+	struct watchdog_device	wdd;
+	void __iomem		*iobase;
+	struct clk		*clk_apb;
+	struct notifier_block	restart_handler;
+	int			irq;
+	u32			wdt_period;
+	unsigned long		wdt_cnts;
+	unsigned long		wdt_freq;
+};
+
+#endif /* __CSKY_WDT_H__ */
+
diff --git a/addons/sound/soc/codecs/Kconfig b/addons/sound/soc/codecs/Kconfig
new file mode 100644
index 0000000..f62ea40
--- /dev/null
+++ b/addons/sound/soc/codecs/Kconfig
@@ -0,0 +1,7 @@
+
+config SND_CSKY_DUMMY_CODEC
+	tristate "C-SKY I2S Dummy Codec Support"
+	default n
+	help
+	  This is a dummy codec.
+
diff --git a/addons/sound/soc/codecs/Makefile b/addons/sound/soc/codecs/Makefile
new file mode 100644
index 0000000..6faa214
--- /dev/null
+++ b/addons/sound/soc/codecs/Makefile
@@ -0,0 +1,2 @@
+obj-$(CONFIG_SND_CSKY_DUMMY_CODEC) += csky-dummy-codec.o
+
diff --git a/addons/sound/soc/codecs/csky-dummy-codec.c b/addons/sound/soc/codecs/csky-dummy-codec.c
new file mode 100644
index 0000000..97d8e68
--- /dev/null
+++ b/addons/sound/soc/codecs/csky-dummy-codec.c
@@ -0,0 +1,99 @@
+/*
+ * C-SKY SoCs Dummy Audio Codec driver
+ *
+ * Copyright (C) 2017 C-SKY MicroSystems Co.,Ltd.
+ *
+ * Author: Lei Ling <lei_ling@c-sky.com>
+ *
+ * This software is licensed under the terms of the GNU General Public
+ * License version 2, as published by the Free Software Foundation, and
+ * may be copied, distributed, and modified under those terms.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include <linux/init.h>
+#include <linux/slab.h>
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/device.h>
+#include <sound/core.h>
+#include <sound/pcm.h>
+#include <sound/initval.h>
+#include <sound/soc.h>
+
+static const struct snd_soc_dapm_widget dummy_codec_dapm_widgets[] = {
+	SND_SOC_DAPM_OUTPUT("VOUTL"),
+	SND_SOC_DAPM_OUTPUT("VOUTR"),
+};
+
+static const struct snd_soc_dapm_route dummy_codec_dapm_routes[] = {
+	{ "VOUTL", NULL, "Playback" },
+	{ "VOUTR", NULL, "Playback" },
+};
+
+#define STUB_RATES	SNDRV_PCM_RATE_8000_192000
+#define STUB_FORMATS	(SNDRV_PCM_FMTBIT_S8 | \
+			 SNDRV_PCM_FMTBIT_U8 | \
+			 SNDRV_PCM_FMTBIT_S16_LE | \
+			 SNDRV_PCM_FMTBIT_U16_LE | \
+			 SNDRV_PCM_FMTBIT_S24_LE | \
+			 SNDRV_PCM_FMTBIT_U24_LE | \
+			 SNDRV_PCM_FMTBIT_S32_LE | \
+			 SNDRV_PCM_FMTBIT_U32_LE)
+
+static struct snd_soc_dai_driver dummy_codec_dai = {
+	.name = "csky-dummy-codec-dai",
+	.playback = {
+		.stream_name = "Playback",
+		.channels_min = 1,
+		.channels_max = 384,
+		.rates = STUB_RATES,
+		.formats = STUB_FORMATS,
+	},
+};
+
+static const struct snd_soc_codec_driver soc_codec_dev_dummy_codec = {
+	.component_driver = {
+		.dapm_widgets		= dummy_codec_dapm_widgets,
+		.num_dapm_widgets	= ARRAY_SIZE(dummy_codec_dapm_widgets),
+		.dapm_routes		= dummy_codec_dapm_routes,
+		.num_dapm_routes	= ARRAY_SIZE(dummy_codec_dapm_routes),
+	},
+};
+
+static int dummy_codec_probe(struct platform_device *pdev)
+{
+	return snd_soc_register_codec(&pdev->dev,
+				      &soc_codec_dev_dummy_codec,
+				      &dummy_codec_dai, 1);
+}
+
+static int dummy_codec_remove(struct platform_device *pdev)
+{
+	snd_soc_unregister_codec(&pdev->dev);
+	return 0;
+}
+
+static const struct of_device_id dummy_codec_codec_match[] = {
+	{ .compatible = "csky,i2s-dummy-codec", },
+	{}
+};
+MODULE_DEVICE_TABLE(of, dummy_codec_codec_match);
+
+static struct platform_driver dummy_codec_codec_driver = {
+	.probe	= dummy_codec_probe,
+	.remove	= dummy_codec_remove,
+	.driver	= {
+		.name		= "dummy-codec",
+		.of_match_table	= dummy_codec_codec_match,
+	},
+};
+module_platform_driver(dummy_codec_codec_driver);
+
+MODULE_DESCRIPTION("C-SKY SoCs Dummy Audio Codec Driver");
+MODULE_AUTHOR("Lei Ling <lei_ling@c-sky.com>");
+MODULE_LICENSE("GPL v2");
diff --git a/addons/sound/soc/csky/Kconfig b/addons/sound/soc/csky/Kconfig
new file mode 100644
index 0000000..e3a837e
--- /dev/null
+++ b/addons/sound/soc/csky/Kconfig
@@ -0,0 +1,16 @@
+menu "C-SKY Audio support"
+
+config SND_CSKY_I2S
+	tristate "C-SKY I2S Support"
+	select SND_SOC_GENERIC_DMAENGINE_PCM
+	default n
+	help
+	  C-SKY I2S Support.
+
+config SND_CSKY_PCM
+	bool "C-SKY PCM Support"
+	select SND_DMAENGINE_PCM
+	default n
+
+endmenu
+
diff --git a/addons/sound/soc/csky/Makefile b/addons/sound/soc/csky/Makefile
new file mode 100644
index 0000000..d857784
--- /dev/null
+++ b/addons/sound/soc/csky/Makefile
@@ -0,0 +1,2 @@
+obj-$(CONFIG_SND_CSKY_I2S) += csky-i2s.o
+obj-$(CONFIG_SND_CSKY_PCM) += csky-pcm.o csky-pcm-pio.o
\ No newline at end of file
diff --git a/addons/sound/soc/csky/csky-i2s.c b/addons/sound/soc/csky/csky-i2s.c
new file mode 100644
index 0000000..4565bdf
--- /dev/null
+++ b/addons/sound/soc/csky/csky-i2s.c
@@ -0,0 +1,688 @@
+/*
+ * C-SKY SoCs I2S Controller driver
+ *
+ * Copyright (C) 2017 C-SKY MicroSystems Co.,Ltd.
+ *
+ * Author: Lei Ling <lei_ling@c-sky.com>
+ *
+ * This software is licensed under the terms of the GNU General Public
+ * License version 2, as published by the Free Software Foundation, and
+ * may be copied, distributed, and modified under those terms.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include <linux/clk.h>
+#include <linux/dmaengine.h>
+#include <linux/module.h>
+#include <linux/of_device.h>
+#include <linux/platform_device.h>
+#include <linux/pm_runtime.h>
+#include <linux/regmap.h>
+#include <linux/reset.h>
+#include <sound/dmaengine_pcm.h>
+#include <sound/pcm_params.h>
+#include <sound/soc.h>
+#include <sound/soc-dai.h>
+#include "csky-i2s.h"
+
+#define BUFFER_BYTES_MAX	(512 * 1024)
+#define PERIOD_BYTES_MIN	32
+#define PERIOD_BYTES_MAX	(8 * 1024)
+#define PERIODS_MIN		4
+#define PERIODS_MAX		(BUFFER_BYTES_MAX / PERIOD_BYTES_MIN)
+
+#define DEFAULT_FIFO_DEPTH		32 /* in words */
+#define DEFAULT_INTR_TX_THRESHOLD	16
+#define DEFAULT_INTR_RX_THRESHOLD	16
+#define DEFAULT_DMA_TX_THRESHOLD	16
+#define DEFAULT_DMA_RX_THRESHOLD	16
+
+static int csky_i2s_calc_mclk_div(struct csky_i2s *i2s,
+				  unsigned int rate,
+				  unsigned int word_size)
+{
+	unsigned int mclk;
+	int div;
+
+	if (i2s->sclk_ws_divider != 64) {
+		if (word_size == 16)
+			mclk = 256 * rate;
+		else if (word_size == 24)
+			mclk = 384 * rate;
+		else
+			return -EINVAL;
+	} else { /* sclk=64fs */
+		if ((i2s->audio_fmt == SND_SOC_DAIFMT_I2S) ||
+		    (i2s->audio_fmt == SND_SOC_DAIFMT_LEFT_J))
+			mclk = 8 * 64 * rate; /* mclk = 8 * sclk */
+		else
+			mclk = 4 * 64 * rate; /* mclk = 4 * sclk */
+	}
+
+	/* div0 = src_clk/(2*mclk) - 1; */
+	div = i2s->src_clk / 2 / mclk - 1;
+	return div;
+}
+
+static int csky_i2s_calc_spdifclk_div(struct csky_i2s *i2s,
+				      unsigned int rate,
+				      unsigned int word_size)
+{
+	/* DIV1_LEVEL[0X94] usually is configured as 17 or 11.  Why ? */
+	return 17;
+}
+
+static int csky_i2s_calc_fs_div(struct csky_i2s *i2s, unsigned int word_size)
+{
+	unsigned int multi; /* sclk = multi * fs */
+	int div;
+
+	if (i2s->sclk_ws_divider != 64) {
+		if ((i2s->audio_fmt == SND_SOC_DAIFMT_I2S) ||
+		    (i2s->audio_fmt == SND_SOC_DAIFMT_LEFT_J)) {
+			if (word_size == 16)
+				multi = 32; /* sclk=32fs */
+			else if (word_size == 24)
+				multi = 48; /* sclk=48fs */
+			else
+				return -EINVAL;
+		} else { /* SND_SOC_DAIFMT_RIGHT_J */
+			if (word_size == 16)
+				multi = 64; /* sclk=64fs */
+			else if (word_size == 24)
+				multi = 96; /* sclk=96fs */
+			else
+				return -EINVAL;
+		}
+	} else {
+		multi = 64; /* sclk=64fs */
+	}
+
+	/* div2 = sclk/(2*fs) - 1 = multi/2 - 1; */
+	div = multi / 2 - 1;
+	return div;
+}
+
+static int csky_i2s_calc_refclk_div(struct csky_i2s *i2s, unsigned int rate)
+{
+	unsigned int ref_clk;
+	int div;
+
+	switch (rate) {
+	/* clk_domain_1/2/3: ref_clk = 3072khz */
+	case 8000:
+	case 16000:
+	case 32000:
+	case 48000:
+	case 96000:
+		ref_clk = 3072000;
+		break;
+	/* clk_domain_4: ref_clk = 2116.8khz */
+	case 11025:
+	case 22050:
+	case 44100:
+	case 88200:
+		ref_clk = 2116800;
+		break;
+	default:
+		return -EINVAL;
+	}
+
+	/* div3 = src_clk / (ref_clk*2) - 1; */
+	div = i2s->src_clk / 2 / ref_clk - 1;
+	return div;
+}
+
+static int csky_i2s_set_clk_rate(struct csky_i2s *i2s,
+				 unsigned int rate,
+				 unsigned int word_size)
+{
+	int mclk_div, spdifclk_div, fs_div, refclk_div;
+	int ret;
+
+	if (!IS_ERR_OR_NULL(i2s->i2s_clk)) {
+		switch (rate) {
+		case 8000:
+		case 16000:
+		case 32000:
+		case 48000:
+		case 96000:
+			ret = clk_set_rate(i2s->i2s_clk, i2s->clk_fs_48k);
+			if (ret)
+				return ret;
+			i2s->src_clk = clk_get_rate(i2s->i2s_clk);
+			break;
+		case 11025:
+		case 22050:
+		case 44100:
+		case 88200:
+			ret = clk_set_rate(i2s->i2s_clk, i2s->clk_fs_44k);
+			if (ret)
+				return ret;
+			i2s->src_clk = clk_get_rate(i2s->i2s_clk);
+			break;
+		default:
+			return -EINVAL;
+		}
+	}
+
+	i2s->sample_rate = rate;
+	mclk_div = csky_i2s_calc_mclk_div(i2s, rate, word_size);
+	if (mclk_div < 0)
+		return -EINVAL;
+
+	spdifclk_div = csky_i2s_calc_spdifclk_div(i2s, rate, word_size);
+	if (spdifclk_div < 0)
+		return -EINVAL;
+
+	fs_div = csky_i2s_calc_fs_div(i2s, word_size);
+	if (fs_div < 0)
+		return -EINVAL;
+
+	refclk_div = csky_i2s_calc_refclk_div(i2s, rate);
+	if (refclk_div < 0)
+		return -EINVAL;
+
+	csky_i2s_writel(i2s, IIS_DIV0_LEVEL, mclk_div);
+	csky_i2s_writel(i2s, IIS_DIV1_LEVEL, spdifclk_div);
+	csky_i2s_writel(i2s, IIS_DIV2_LEVEL, fs_div);
+	csky_i2s_writel(i2s, IIS_DIV3_LEVEL, refclk_div);
+	return 0;
+}
+
+static int csky_i2s_hw_params(struct snd_pcm_substream *substream,
+			      struct snd_pcm_hw_params *params,
+			      struct snd_soc_dai *dai)
+{
+	struct csky_i2s *i2s = snd_soc_dai_get_drvdata(dai);
+	u32 width;
+	u32 val;
+
+	if (params_channels(params) > 2)
+		return -EINVAL;
+
+	val = csky_i2s_readl(i2s, IIS_FSSTA);
+	val &= ~(FSSTA_RES_MASK << FSSTA_RES_SHIFT);
+
+	switch (params_physical_width(params)) {
+	case 16:
+		if (params_channels(params) == 2)
+			width = DMA_SLAVE_BUSWIDTH_4_BYTES;
+		else
+			width = DMA_SLAVE_BUSWIDTH_2_BYTES;
+
+		val |= FSSTA_RES16_FIFO16;
+		break;
+	case 24:
+		width = DMA_SLAVE_BUSWIDTH_3_BYTES;
+		val |= FSSTA_RES24_FIFO24;
+		break;
+	case 32:
+		width = DMA_SLAVE_BUSWIDTH_4_BYTES;
+		val |= FSSTA_RES24_FIFO24;
+		break;
+	default:
+		return -EINVAL;
+	}
+	i2s->playback_dma_data.addr_width = width;
+
+	csky_i2s_writel(i2s, IIS_FSSTA, val);
+	return csky_i2s_set_clk_rate(i2s, params_rate(params),
+				     params_width(params));
+}
+
+static int csky_i2s_set_fmt(struct snd_soc_dai *dai, unsigned int fmt)
+{
+	struct csky_i2s *i2s = snd_soc_dai_get_drvdata(dai);
+	u32 val;
+
+	val = csky_i2s_readl(i2s, IIS_IISCNF_OUT);
+	val &= ~(OUT_AUDFMT_MASK << OUT_AUDFMT_SHIFT);
+	val &= ~(OUT_WS_POLARITY_MASK << OUT_WS_POLARITY_SHIFT);
+	val &= ~(OUT_M_S_MASK << OUT_M_S_SHIFT);
+
+	/* DAI Mode */
+	switch (fmt & SND_SOC_DAIFMT_FORMAT_MASK) {
+	case SND_SOC_DAIFMT_I2S:
+		val |= IISCNF_OUT_AUDFMT_I2S;
+		break;
+	case SND_SOC_DAIFMT_LEFT_J:
+		val |= IISCNF_OUT_AUDFMT_LEFT_J;
+		break;
+	case SND_SOC_DAIFMT_RIGHT_J:
+		val |= IISCNF_OUT_AUDFMT_RIGHT_J;
+		break;
+	default:
+		return -EINVAL;
+	}
+
+	/* DAI clock polarity */
+	switch (fmt & SND_SOC_DAIFMT_INV_MASK) {
+	case SND_SOC_DAIFMT_NB_NF:
+		val |= IISCNF_OUT_WS_POLARITY_NORMAL;
+		break;
+	case SND_SOC_DAIFMT_NB_IF:
+		/* Invert frame clock */
+		val |= IISCNF_OUT_WS_POLARITY_INVERTED;
+		break;
+	case SND_SOC_DAIFMT_IB_IF:
+	case SND_SOC_DAIFMT_IB_NF:
+	default:
+		return -EINVAL;
+	}
+
+	/* DAI clock master masks */
+	switch (fmt & SND_SOC_DAIFMT_MASTER_MASK) {
+	case SND_SOC_DAIFMT_CBS_CFS:
+		/* BCLK and LRCLK master */
+		val |= IISCNF_OUT_MASTER;
+		break;
+	case SND_SOC_DAIFMT_CBM_CFM:
+		/* BCLK and LRCLK slave */
+		val |= IISCNF_OUT_SLAVE;
+		break;
+	default:
+		return -EINVAL;
+	}
+
+	csky_i2s_writel(i2s, IIS_IISCNF_OUT, val);
+	i2s->audio_fmt = fmt & SND_SOC_DAIFMT_FORMAT_MASK;
+	return 0;
+}
+
+/* apply to hdmi */
+#ifdef CONFIG_HDMI
+extern void csky_hdmi_audio_config(unsigned int sample_rate, unsigned int audio_fmt);
+#endif
+
+static void csky_i2s_start_playback(struct csky_i2s *i2s)
+{
+	if (i2s->use_pio)
+		csky_i2s_writel(i2s, IIS_IMR, IIS_FIFOINT_TX_FIFO_EMPTY);
+	else
+		csky_i2s_writel(i2s, IIS_DMACR, DMACR_EN_TX_DMA);
+
+	csky_i2s_writel(i2s, IIS_AUDIOEN, AUDIOEN_IIS_EN);
+
+#ifdef CONFIG_HDMI
+	/* applay to hdmi audio */
+	if (i2s->config_hdmi == 1)
+		csky_hdmi_audio_config(i2s->sample_rate, i2s->audio_fmt);
+#endif
+}
+
+static void csky_i2s_stop_playback(struct csky_i2s *i2s)
+{
+	csky_i2s_writel(i2s, IIS_IMR, 0); /* disable fifo interrupts */
+	csky_i2s_writel(i2s, IIS_DMACR, 0); /* disable tx dma */
+	csky_i2s_writel(i2s, IIS_AUDIOEN, 0);
+}
+
+static int csky_i2s_trigger(struct snd_pcm_substream *substream,
+			    int cmd,
+			    struct snd_soc_dai *dai)
+{
+	struct csky_i2s *i2s = snd_soc_dai_get_drvdata(dai);
+
+	switch (cmd) {
+	case SNDRV_PCM_TRIGGER_START:
+	case SNDRV_PCM_TRIGGER_PAUSE_RELEASE:
+	case SNDRV_PCM_TRIGGER_RESUME:
+		if (substream->stream == SNDRV_PCM_STREAM_PLAYBACK)
+			csky_i2s_start_playback(i2s);
+		else
+			return -EINVAL;
+		break;
+
+	case SNDRV_PCM_TRIGGER_STOP:
+	case SNDRV_PCM_TRIGGER_PAUSE_PUSH:
+	case SNDRV_PCM_TRIGGER_SUSPEND:
+		if (substream->stream == SNDRV_PCM_STREAM_PLAYBACK)
+			csky_i2s_stop_playback(i2s);
+		else
+			return -EINVAL;
+		break;
+
+	default:
+		return -EINVAL;
+	}
+
+	return 0;
+}
+
+static int csky_i2s_startup(struct snd_pcm_substream *substream,
+			    struct snd_soc_dai *dai)
+{
+	return 0;
+}
+
+static void csky_i2s_shutdown(struct snd_pcm_substream *substream,
+			      struct snd_soc_dai *dai)
+{
+}
+
+static const struct snd_soc_dai_ops csky_i2s_dai_ops = {
+	.set_fmt	= csky_i2s_set_fmt,
+	.hw_params	= csky_i2s_hw_params,
+	.trigger	= csky_i2s_trigger,
+	.startup	= csky_i2s_startup,
+	.shutdown	= csky_i2s_shutdown,
+};
+
+static void csky_i2s_init(struct csky_i2s *i2s)
+{
+	csky_i2s_writel(i2s, IIS_AUDIOEN, 0); /* disable I2S */
+
+	csky_i2s_writel(i2s, IIS_FICR, IIS_FIFOINT_ALL); /* clear FIFO intr */
+	csky_i2s_writel(i2s, IIS_CMIR, IIS_MODEINT_ALL); /* clear Mode intr */
+
+	csky_i2s_writel(i2s, IIS_FSSTA,
+			FSSTA_RATE_SET_BY_USER |
+			FSSTA_RES16_FIFO16);
+
+	/* set the center count of FS when ref_clk = 3.072MHz */
+	csky_i2s_writel(i2s, IIS_FADTLR,
+			FADTLR_48FTR(0x40) |
+			FADTLR_44FTR(0x46) |
+			FADTLR_32FTR(0x60) |
+			FADTLR_96FTR(0x20));
+
+	csky_i2s_writel(i2s, IIS_IMR, 0); /* disable FIFO intr */
+
+	csky_i2s_writel(i2s, IIS_RXFTLR, i2s->intr_rx_threshold);
+	if (i2s->use_pio)
+		csky_i2s_writel(i2s, IIS_TXFTLR, i2s->intr_tx_threshold);
+	else
+		csky_i2s_writel(i2s, IIS_TXFTLR, 0);
+
+	csky_i2s_writel(i2s, IIS_DMARDLR, i2s->dma_rx_threshold);
+	csky_i2s_writel(i2s, IIS_DMATDLR, i2s->dma_tx_threshold);
+
+	csky_i2s_writel(i2s, IIS_MIMR, 0x0); /* disable Mode intr */
+
+	csky_i2s_writel(i2s, IIS_SCCR, 0x0); /* no sample compress */
+
+	csky_i2s_writel(i2s, IIS_FUNCMODE,
+			FUNCMODE_MODE_WEN |
+			FUNCMODE_MODE_TX); /* tx mode */
+	csky_i2s_writel(i2s, IIS_IISCNF_OUT,
+			IISCNF_OUT_AUDFMT_I2S |
+			IISCNF_OUT_WS_POLARITY_NORMAL |
+			IISCNF_OUT_MASTER); /* master, i2s mode */
+	return;
+}
+
+static int csky_i2s_dai_probe(struct snd_soc_dai *dai)
+{
+	struct csky_i2s *i2s = snd_soc_dai_get_drvdata(dai);
+
+	snd_soc_dai_init_dma_data(dai,
+				  &i2s->playback_dma_data,
+				  NULL /* capture not supported yet */);
+
+	snd_soc_dai_set_drvdata(dai, i2s);
+
+	csky_i2s_init(i2s);
+	return 0;
+}
+
+static struct snd_soc_dai_driver csky_i2s_dai = {
+	.probe = csky_i2s_dai_probe,
+	.playback = {
+		.stream_name = "Playback",
+		.channels_min = 1,
+		.channels_max = 2,
+		.rates = SNDRV_PCM_RATE_8000_48000 |
+			 SNDRV_PCM_RATE_88200 | SNDRV_PCM_RATE_96000,
+		.formats = SNDRV_PCM_FMTBIT_S16_LE | SNDRV_PCM_FMTBIT_U16_LE |
+			   SNDRV_PCM_FMTBIT_S24_LE | SNDRV_PCM_FMTBIT_U24_LE,
+	},
+	.ops = &csky_i2s_dai_ops,
+	.symmetric_rates = 1,
+};
+
+static const struct snd_soc_component_driver csky_i2s_component = {
+	.name	= "csky-dai",
+};
+
+static const struct snd_pcm_hardware csky_pcm_dma_hardware = {
+	.info		= (SNDRV_PCM_INFO_MMAP
+			| SNDRV_PCM_INFO_MMAP_VALID
+			| SNDRV_PCM_INFO_INTERLEAVED
+			| SNDRV_PCM_INFO_BLOCK_TRANSFER
+			| SNDRV_PCM_INFO_RESUME
+			| SNDRV_PCM_INFO_PAUSE),
+	.channels_min		= 1,
+	.channels_max		= 2,
+	.buffer_bytes_max	= BUFFER_BYTES_MAX,
+	.period_bytes_min	= PERIOD_BYTES_MIN,
+	.period_bytes_max	= PERIOD_BYTES_MAX,
+	.periods_min		= PERIODS_MIN,
+	.periods_max		= PERIODS_MAX,
+};
+
+static irqreturn_t csky_i2s_irq_handler(int irq, void *dev_id)
+{
+	struct csky_i2s *i2s = dev_id;
+	u32 val;
+
+	val = csky_i2s_readl(i2s, IIS_ISR);
+	/* clear interrupts */
+	csky_i2s_writel(i2s, IIS_FICR, val);
+
+	if (val & IIS_FIFOINT_TX_FIFO_EMPTY) {
+		if (i2s->use_pio) {
+			csky_pcm_pio_push_tx(i2s);
+			csky_i2s_writel(i2s, IIS_FICR, val);
+		}
+	}
+
+	return IRQ_HANDLED;
+}
+
+static int csky_i2s_probe(struct platform_device *pdev)
+{
+	struct csky_i2s *i2s;
+	struct resource *res;
+	struct snd_dmaengine_pcm_config *pcm_conf;
+	struct clk *tmp_clk;
+	int ret;
+
+	i2s = devm_kzalloc(&pdev->dev, sizeof(*i2s), GFP_KERNEL);
+	if (!i2s)
+		return -ENOMEM;
+	platform_set_drvdata(pdev, i2s);
+
+	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	i2s->regs = devm_ioremap_resource(&pdev->dev, res);
+	if (IS_ERR(i2s->regs))
+		return PTR_ERR(i2s->regs);
+
+	i2s->irq = platform_get_irq(pdev, 0);
+	if (i2s->irq < 0) {
+		dev_err(&pdev->dev, "Failed to retrieve irq number\n");
+		return i2s->irq;
+	}
+
+	ret = devm_request_irq(&pdev->dev, i2s->irq,
+			       csky_i2s_irq_handler, 0, pdev->name, i2s);
+	if (ret < 0) {
+		dev_err(&pdev->dev, "Failed to request irq\n");
+		return ret;
+	}
+
+	if (of_property_read_u32(pdev->dev.of_node, "clock-frequency",
+				 &i2s->src_clk) < 0) {
+		/* get i2s clk */
+
+		i2s->i2s_clk = devm_clk_get(&pdev->dev, "audio");
+		if (IS_ERR(i2s->i2s_clk)) {
+			dev_err(&pdev->dev, "Failed to get clk 'audio'\n");
+			return PTR_ERR(i2s->i2s_clk);
+		}
+
+		ret = clk_prepare_enable(i2s->i2s_clk);
+		if (ret) {
+			dev_err(&pdev->dev, "Failed to enable clk 'audio'\n");
+			return ret;
+		}
+
+		i2s->src_clk = clk_get_rate(i2s->i2s_clk);
+
+		/* get i2s clk gate */
+
+		i2s->i2s_clk_gate = devm_clk_get(&pdev->dev, "gate");
+		if (IS_ERR(i2s->i2s_clk_gate)) {
+			dev_err(&pdev->dev, "Failed to get clk 'gate'\n");
+			ret = PTR_ERR(i2s->i2s_clk_gate);
+			goto err_clk;
+		}
+
+		ret = clk_prepare_enable(i2s->i2s_clk_gate);
+		if (ret) {
+			dev_err(&pdev->dev, "Failed to enable clk 'gate'\n");
+			goto err_clk;
+		}
+
+		/* get clk for 44.1k fs */
+		tmp_clk = devm_clk_get(&pdev->dev, "clk-for-fs-44k");
+		if (IS_ERR(tmp_clk)) {
+			dev_err(&pdev->dev,
+				"Failed to get clk 'clk-for-fs-44k'\n");
+			ret = PTR_ERR(tmp_clk);
+			goto err_clk;
+		}
+		i2s->clk_fs_44k = clk_get_rate(tmp_clk);
+
+		/* get clk for 48k fs */
+		tmp_clk = devm_clk_get(&pdev->dev, "clk-for-fs-48k");
+		if (IS_ERR(tmp_clk)) {
+			dev_err(&pdev->dev,
+				"Failed to get clk 'clk-for-fs-48k'\n");
+			ret = PTR_ERR(tmp_clk);
+			goto err_clk;
+		}
+		i2s->clk_fs_48k = clk_get_rate(tmp_clk);
+	}
+
+	if (of_find_property(pdev->dev.of_node, "dmas", NULL)) {
+		dev_info(&pdev->dev, "use dma\n");
+		i2s->use_pio = false;
+	} else {
+		dev_info(&pdev->dev, "use pio\n");
+		i2s->use_pio = true;
+	}
+
+	if (of_property_read_u32(pdev->dev.of_node, "fifo-depth",
+				 &i2s->fifo_depth) < 0)
+		i2s->fifo_depth = DEFAULT_FIFO_DEPTH;
+	if (of_property_read_u32(pdev->dev.of_node, "intr-tx-threshold",
+				 &i2s->intr_tx_threshold) < 0)
+		i2s->intr_tx_threshold = DEFAULT_INTR_TX_THRESHOLD;
+	if (of_property_read_u32(pdev->dev.of_node, "intr-rx-threshold",
+				 &i2s->intr_rx_threshold) < 0)
+		i2s->intr_rx_threshold = DEFAULT_INTR_RX_THRESHOLD;
+	if (of_property_read_u32(pdev->dev.of_node, "dma-tx-threshold",
+				 &i2s->dma_tx_threshold) < 0)
+		i2s->dma_tx_threshold = DEFAULT_DMA_TX_THRESHOLD;
+	if (of_property_read_u32(pdev->dev.of_node, "dma-rx-threshold",
+				 &i2s->dma_rx_threshold) < 0)
+		i2s->dma_rx_threshold = DEFAULT_DMA_RX_THRESHOLD;
+
+	of_property_read_u32(pdev->dev.of_node, "sclk-ws-divider",
+			     &i2s->sclk_ws_divider);
+
+	i2s->playback_dma_data.maxburst =
+			i2s->fifo_depth - i2s->dma_tx_threshold;
+
+	i2s->dev = &pdev->dev;
+	i2s->playback_dma_data.addr = res->start + IIS_DR;
+	i2s->audio_fmt = SND_SOC_DAIFMT_I2S;
+
+	ret = devm_snd_soc_register_component(&pdev->dev,
+					      &csky_i2s_component,
+					      &csky_i2s_dai, 1);
+	if (ret) {
+		dev_err(&pdev->dev, "Failed to register DAI\n");
+		goto err_clk;
+	}
+
+	pcm_conf = devm_kzalloc(&pdev->dev, sizeof(*pcm_conf), GFP_KERNEL);
+	if (!pcm_conf) {
+		dev_err(&pdev->dev, "Failed to allocate memory for pcm_conf\n");
+		ret = -ENOMEM;
+		goto err_clk;
+	}
+
+	if (i2s->use_pio) {
+		ret = csky_pcm_pio_register(pdev);
+		if (ret) {
+			dev_err(&pdev->dev,
+				"Could not register PIO PCM: %d\n", ret);
+			goto err_clk;
+		}
+	} else {
+		pcm_conf->prepare_slave_config =
+				csky_snd_dmaengine_pcm_prepare_slave_config;
+		pcm_conf->pcm_hardware = &csky_pcm_dma_hardware;
+		pcm_conf->prealloc_buffer_size = BUFFER_BYTES_MAX;
+
+		ret = csky_snd_dmaengine_pcm_register(&pdev->dev, pcm_conf, 0);
+		if (ret) {
+			dev_err(&pdev->dev, "Failed to register PCM\n");
+			goto err_clk;
+		}
+	}
+
+	if (of_property_read_bool(pdev->dev.of_node, "config-hdmi"))
+		i2s->config_hdmi = 1;
+	else
+		i2s->config_hdmi = 0;
+
+	return 0;
+
+err_clk:
+	if (!IS_ERR(i2s->i2s_clk))
+		clk_disable_unprepare(i2s->i2s_clk);
+	if (!IS_ERR(i2s->i2s_clk_gate))
+		clk_disable_unprepare(i2s->i2s_clk_gate);
+
+	return ret;
+}
+
+static int csky_i2s_remove(struct platform_device *pdev)
+{
+	struct csky_i2s *i2s = dev_get_drvdata(&pdev->dev);
+
+	if (!IS_ERR(i2s->i2s_clk))
+		clk_disable_unprepare(i2s->i2s_clk);
+	if (!IS_ERR(i2s->i2s_clk_gate))
+		clk_disable_unprepare(i2s->i2s_clk_gate);
+
+	csky_snd_dmaengine_pcm_unregister(&pdev->dev);
+	return 0;
+}
+
+static const struct of_device_id csky_i2s_match[] = {
+	{ .compatible = "csky,i2s-v1", },
+	{}
+};
+MODULE_DEVICE_TABLE(of, csky_i2s_match);
+
+static struct platform_driver csky_i2s_driver = {
+	.probe	= csky_i2s_probe,
+	.remove	= csky_i2s_remove,
+	.driver	= {
+		.name		= "csky-i2s",
+		.of_match_table	= csky_i2s_match,
+	},
+};
+module_platform_driver(csky_i2s_driver);
+
+MODULE_DESCRIPTION("C-SKY SoCs I2S Controller Driver");
+MODULE_AUTHOR("Lei Ling <lei_ling@c-sky.com>");
+MODULE_LICENSE("GPL v2");
diff --git a/addons/sound/soc/csky/csky-i2s.h b/addons/sound/soc/csky/csky-i2s.h
new file mode 100644
index 0000000..e083755
--- /dev/null
+++ b/addons/sound/soc/csky/csky-i2s.h
@@ -0,0 +1,214 @@
+/*
+ * C-SKY SoCs I2S Controller driver
+ *
+ * Copyright (C) 2017 C-SKY MicroSystems Co.,Ltd.
+ *
+ * Author: Lei Ling <lei_ling@c-sky.com>
+ *
+ * This software is licensed under the terms of the GNU General Public
+ * License version 2, as published by the Free Software Foundation, and
+ * may be copied, distributed, and modified under those terms.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef __CSKY_I2S_H__
+#define __CSKY_I2S_H__
+
+#include <sound/dmaengine_pcm.h>
+
+/* Hardware register definitions */
+#define IIS_AUDIOEN	0x00	/* Enable/Disable IIS/SPDIF */
+#define IIS_FUNCMODE	0x04	/* Function Mode(receiver/transmitter) */
+#define IIS_IISCNF_IN	0x08	/* Input: IIS Configuration */
+#define IIS_FSSTA	0x0C	/* Input: Config Sample Frequency / Work Mode */
+#define IIS_IISCNF_OUT	0x10	/* Output: IIS Configuration */
+#define IIS_FADTLR	0x14	/* FS Auto Detected Threshold Level Register */
+#define IIS_SCCR	0x18	/* Sample Compress Control Register */
+#define IIS_TXFTLR	0x1C	/* Transmit FIFO Threshold Level */
+#define IIS_RXFTLR	0x20	/* Receive FIFO Threshold Level */
+#define IIS_TXFLR	0x24	/* Transmit FIFO Level */
+#define IIS_RXFLR	0x28	/* Receive FIFO Level */
+#define IIS_SR		0x2C	/* Status Register */
+#define IIS_IMR		0x30	/* FIFO Interrupt Mask */
+#define IIS_ISR		0x34	/* FIFO Interrupt Status */
+#define IIS_RISR	0x38	/* Raw FIFO Interrupt Status */
+#define IIS_FICR	0x3C	/* FIFO Interrupt Clear */
+#define IIS_DMACR	0x4C	/* DMA Control(enable/disable rx/tx dma) */
+#define IIS_DMATDLR	0x50	/* DMA Transmit Data Level */
+#define IIS_DMARDLR	0x54	/* DMA Receive Data Level */
+#define IIS_DR		0x60	/* Data Register */
+#define IIS_SRCR	0x70	/* SPDIF Receiver Configuration */
+#define IIS_SRSSR	0x74	/* SPDIF Receiver Signal Status */
+#define IIS_STSSR	0x78	/* SPDIF Transmitter Signal Status */
+#define IIS_SCSR	0x7C	/* SPDIF Channel status */
+#define IIS_MIMR	0x80	/* Mode Interrupt Mask */
+#define IIS_MISR	0x84	/* Mode Interrupt Status */
+#define IIS_RMISR	0x88	/* Raw Mode Interrupt Status */
+#define IIS_CMIR	0x8C	/* Clear Mode Interrupt */
+#define IIS_DIV0_LEVEL	0x90	/* clock divider for mclk */
+#define IIS_DIV1_LEVEL	0x94	/* clock divider for spdif_clk */
+#define IIS_DIV2_LEVEL	0x98	/* clock divider for wsclk */
+#define IIS_DIV3_LEVEL	0x9C	/* clock divider for ref_clk */
+
+/* Bitfields in IIS_AUDIOEN */
+#define AUDIOEN_IIS_EN		(1 << 0)	/* IIS enable */
+#define AUDIOEN_SPDIF_EN	(1 << 1)	/* SPDIF enable */
+
+/* Bitfields in IIS_FUNCMODE */
+#define FUNCMODE_MODE_RX	(0 << 0)
+#define FUNCMODE_MODE_TX	(1 << 0)
+#define FUNCMODE_MODE_WEN	(1 << 1)	/* MODE write enable */
+
+/* Bitfields in IIS_IISCNF_IN */
+#define IISCNF_IN_AUDFMT_I2S		(0 << 0)
+#define IISCNF_IN_AUDFMT_RIGHT_J	(1 << 0)
+#define IISCNF_IN_AUDFMT_LEFT_J		(2 << 0)
+#define IISCNF_IN_WS_POLARITY_NORMAL	(0 << 2)
+#define IISCNF_IN_WS_POLARITY_INVERTED	(1 << 2)
+#define IISCNF_IN_SAMPLE_SOURCE_VOICE	(1 << 4)
+#define IISCNF_IN_SLAVE			(0 << 8)
+#define IISCNF_IN_MASTER		(1 << 8)
+
+/* Bitfields in IIS_FSSTA */
+#define FSSTA_RATE_SET_BY_USER	(0 << 0)	/* input rate is set by user */
+#define FSSTA_RATE_AUTO_DETECT	(1 << 0)	/* input rate auto detected */
+#define FSSTA_RES16_FIFO16	(0 << 1)
+#define FSSTA_RES16_FIFO24	(1 << 1)
+#define FSSTA_RES24_FIFO16	(2 << 1)
+#define FSSTA_RES24_FIFO24	(3 << 1)
+#define FSSTA_RES_MASK		0x3
+#define FSSTA_RES_SHIFT		1
+#define FSSTA_AFR(x)		((x) << 4)	/* Audio Fundamental Rate */
+#define FSSTA_AFR_MASK		0x3
+#define FSSTA_ARS(x)		((x) << 6)	/* Audio Rate Scale(I2S only) */
+#define FSSTA_ARS_MASK		0x3
+
+/* Bitfields in IIS_IISCNF_OUT */
+#define IISCNF_OUT_AUDFMT_I2S		(0 << 0)
+#define IISCNF_OUT_AUDFMT_RIGHT_J	(1 << 0)
+#define IISCNF_OUT_AUDFMT_LEFT_J	(2 << 0)
+#define OUT_AUDFMT_MASK			0x3
+#define OUT_AUDFMT_SHIFT		0
+#define IISCNF_OUT_WS_POLARITY_NORMAL	(0 << 2)
+#define IISCNF_OUT_WS_POLARITY_INVERTED	(1 << 2)
+#define OUT_WS_POLARITY_MASK		0x1
+#define OUT_WS_POLARITY_SHIFT		2
+#define IISCNF_OUT_SAMPLE_SOURCE_VOICE	(1 << 3)
+#define IISCNF_OUT_MASTER		(0 << 4)
+#define IISCNF_OUT_SLAVE		(1 << 4)
+#define OUT_M_S_MASK			0x1
+#define OUT_M_S_SHIFT			4
+
+/* Bitfields in IIS_FADTLR */
+#define FADTLR_48FTR(x)		((x) << 0)	/* the center count of 48K */
+#define FADTLR_48FTR_MASK	0x7F
+#define FADTLR_44FTR(x)		((x) << 8)	/* the center count of 44.1K */
+#define FADTLR_44FTR_MASK	0x7F
+#define FADTLR_32FTR(x)		((x) << 16)	/* the center count of 32K */
+#define FADTLR_32FTR_MASK	0x7F
+#define FADTLR_96FTR(x)		((x) << 24)	/* the center count of 96K */
+#define FADTLR_96FTR_MASK	0x3F
+
+/* Bitfields in IIS_SCCR */
+/* TODO */
+
+/* Bitfields in IIS_SR */
+#define SR_RX_BUSY		(1 << 0)
+#define SR_TX_BUSY		(1 << 1)
+#define SR_TX_FIFO_NOT_FULL	(1 << 2)
+#define SR_TX_FIFO_EMPTY	(1 << 3)
+#define SR_RX_FIFO_NOT_EMPTY	(1 << 4)
+#define SR_RX_FIFO_FULL		(1 << 5)
+
+/* Bitfields in IIS_IMR/IIS_ISR/IIS_RISR/IIS_FICR */
+#define IIS_FIFOINT_TX_FIFO_EMPTY	(1 << 0)
+#define IIS_FIFOINT_TX_FIFO_OVERFLOW	(1 << 1)
+#define IIS_FIFOINT_RX_FIFO_UNDERFLOW	(1 << 2)
+#define IIS_FIFOINT_RX_FIFO_OVERFLOW	(1 << 3)
+#define IIS_FIFOINT_RX_FIFO_FULL	(1 << 4)
+#define IIS_FIFOINT_ALL	(IIS_FIFOINT_TX_FIFO_EMPTY | \
+			 IIS_FIFOINT_TX_FIFO_OVERFLOW | \
+			 IIS_FIFOINT_RX_FIFO_UNDERFLOW | \
+			 IIS_FIFOINT_RX_FIFO_OVERFLOW | \
+			 IIS_FIFOINT_RX_FIFO_FULL)
+
+/* Bitfields in IIS_DMACR */
+#define DMACR_EN_RX_DMA		(1 << 0)	/* receiver dma enable */
+#define DMACR_EN_TX_DMA		(1 << 1)	/* transmitter dma enable*/
+
+/* Bitfields in IIS_SRCR */
+/* TODO */
+/* Bitfields in IIS_SRSSR */
+/* TODO */
+/* Bitfields in IIS_STSSR */
+/* TODO */
+/* Bitfields in IIS_SCSR */
+/* TODO */
+
+/* Bitfields in IIS_MIMR/IIS_MISR/IIS_RMISR/IIS_CMIR */
+#define IIS_MODEINT_I2S_RX_BUSY_CHANGE		(1 << 0)
+#define IIS_MODEINT_I2S_TX_BUSY_CHANGE		(1 << 1)
+#define IIS_MODEINT_SPDIF_RX_BUSY_CHANGE	(1 << 2)
+#define IIS_MODEINT_SPDIF_TX_BUSY_CHANGE	(1 << 3)
+#define IIS_MODEINT_INPUT_FS_CHANGE		(1 << 4)
+#define IIS_MODEINT_SPDIF_SCSR_DATA_CHANGE	(1 << 5)
+#define IIS_MODEINT_ALL	(IIS_MODEINT_I2S_RX_BUSY_CHANGE | \
+			 IIS_MODEINT_I2S_TX_BUSY_CHANGE | \
+			 IIS_MODEINT_SPDIF_RX_BUSY_CHANGE | \
+			 IIS_MODEINT_SPDIF_TX_BUSY_CHANGE | \
+			 IIS_MODEINT_INPUT_FS_CHANGE | \
+			 IIS_MODEINT_SPDIF_SCSR_DATA_CHANGE)
+
+struct csky_i2s {
+	struct device *dev;
+	void __iomem *regs;
+	int irq;
+	unsigned int src_clk;
+	struct clk *i2s_clk;
+	struct clk *i2s_clk_gate;
+	unsigned int clk_fs_44k; /* clock for 11.025k/22.05k/44.1k/88.2k fs */
+	unsigned int clk_fs_48k; /* clock for 8k/16k/32k/48k/96k fs */
+	unsigned int sample_rate;
+	unsigned int audio_fmt;
+	unsigned int config_hdmi;
+	unsigned int sclk_ws_divider; /* sclk = sclk_ws_divider * wsclk */
+	struct snd_dmaengine_dai_dma_data playback_dma_data;
+
+	unsigned int fifo_depth; /* in words */
+	unsigned int intr_tx_threshold;
+	unsigned int intr_rx_threshold;
+	unsigned int dma_tx_threshold;
+	unsigned int dma_rx_threshold;
+
+	/* data related to PIO transfers (TX) */
+	bool use_pio;
+	struct snd_pcm_substream __rcu *tx_substream;
+	unsigned int (*tx_fn)(struct csky_i2s *dev,
+			      struct snd_pcm_runtime *runtime,
+			      unsigned int tx_ptr,
+			      bool *period_elapsed);
+	unsigned int tx_ptr;
+};
+
+#define csky_i2s_readl(i2s, offset) \
+		readl((i2s)->regs + (offset))
+#define csky_i2s_writel(i2s, offset, val) \
+		writel((val), (i2s)->regs + (offset))
+
+extern int csky_snd_dmaengine_pcm_register(struct device *dev,
+		const struct snd_dmaengine_pcm_config *config,
+		unsigned int flags);
+extern void csky_snd_dmaengine_pcm_unregister(struct device *dev);
+extern int csky_snd_dmaengine_pcm_prepare_slave_config(
+		struct snd_pcm_substream *substream,
+		struct snd_pcm_hw_params *params,
+		struct dma_slave_config *slave_config);
+
+extern int csky_pcm_pio_register(struct platform_device *pdev);
+extern void csky_pcm_pio_push_tx(struct csky_i2s *i2s);
+
+#endif /* __CSKY_I2S_H__ */
diff --git a/addons/sound/soc/csky/csky-pcm-pio.c b/addons/sound/soc/csky/csky-pcm-pio.c
new file mode 100644
index 0000000..385ec62
--- /dev/null
+++ b/addons/sound/soc/csky/csky-pcm-pio.c
@@ -0,0 +1,300 @@
+/*
+ * C-SKY SoCs PIO PCM for I2S driver
+ *
+ * Copyright (C) 2017 C-SKY MicroSystems Co.,Ltd.
+ *
+ * Author: Lei Ling <lei_ling@c-sky.com>
+ *
+ * The PIO PCM is specially suited for I2S devices that don't have DMA support.
+ *
+ * This software is licensed under the terms of the GNU General Public
+ * License version 2, as published by the Free Software Foundation, and
+ * may be copied, distributed, and modified under those terms.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include <linux/io.h>
+#include <linux/rcupdate.h>
+#include <sound/pcm.h>
+#include <sound/pcm_params.h>
+#include "csky-i2s.h"
+
+#define BUFFER_BYTES_MAX	(256 * 1024)
+#define PERIOD_BYTES_MIN	4096
+#define PERIODS_MIN		4
+
+static unsigned int
+csky_pcm_pio_tx_16_mono(struct csky_i2s *i2s,
+			struct snd_pcm_runtime *runtime,
+			unsigned int tx_ptr,
+			bool *period_elapsed)
+{
+	const u16 *p = (void *)runtime->dma_area;
+	unsigned int period_pos = tx_ptr % runtime->period_size;
+	int cnt = i2s->fifo_depth - i2s->intr_tx_threshold;
+	int i;
+
+	for (i = 0; i < cnt; i++) {
+		iowrite16(*(p + tx_ptr), i2s->regs + IIS_DR);
+		period_pos++;
+		if (++tx_ptr >= runtime->buffer_size)
+			tx_ptr = 0;
+	}
+
+	*period_elapsed = period_pos >= runtime->period_size;
+	return tx_ptr;
+}
+
+static unsigned int
+csky_pcm_pio_tx_16_stereo(struct csky_i2s *i2s,
+			  struct snd_pcm_runtime *runtime,
+			  unsigned int tx_ptr,
+			  bool *period_elapsed)
+{
+	const u32 *p = (void *)runtime->dma_area;
+	unsigned int period_pos = tx_ptr % runtime->period_size;
+	int cnt = i2s->fifo_depth - i2s->intr_tx_threshold;
+	int i;
+
+	for (i = 0; i < cnt; i++) {
+		iowrite32(*(p + tx_ptr), i2s->regs + IIS_DR);
+		period_pos++;
+		if (++tx_ptr >= runtime->buffer_size)
+			tx_ptr = 0;
+	}
+
+	*period_elapsed = period_pos >= runtime->period_size;
+	return tx_ptr;
+}
+
+static unsigned int
+csky_pcm_pio_tx_32(struct csky_i2s *i2s,
+		   struct snd_pcm_runtime *runtime,
+		   unsigned int tx_ptr,
+		   bool *period_elapsed)
+{
+	const u32 *p = (void *)runtime->dma_area;
+	u32 offset;
+	unsigned int period_pos = tx_ptr % runtime->period_size;
+	int cnt = i2s->fifo_depth - i2s->intr_tx_threshold;
+	int i = 0;
+
+	while (i < cnt) {
+		offset = tx_ptr * runtime->channels;
+
+		iowrite32(*(p + offset), i2s->regs + IIS_DR);
+		i++;
+		if (runtime->channels == 2) {
+			iowrite32(*(p + offset + 1), i2s->regs + IIS_DR);
+			i++;
+		}
+
+		period_pos++;
+		if (++tx_ptr >= runtime->buffer_size)
+			tx_ptr = 0;
+	}
+
+	*period_elapsed = period_pos >= runtime->period_size;
+	return tx_ptr;
+}
+
+static const struct snd_pcm_hardware csky_pcm_pio_hardware = {
+	.info = SNDRV_PCM_INFO_INTERLEAVED |
+		SNDRV_PCM_INFO_MMAP |
+		SNDRV_PCM_INFO_MMAP_VALID |
+		SNDRV_PCM_INFO_BLOCK_TRANSFER,
+	.channels_min = 1,
+	.channels_max = 2,
+	.buffer_bytes_max = BUFFER_BYTES_MAX,
+	.period_bytes_min = PERIOD_BYTES_MIN,
+	.period_bytes_max = BUFFER_BYTES_MAX / PERIODS_MIN,
+	.periods_min = PERIODS_MIN,
+	.periods_max = BUFFER_BYTES_MAX / PERIOD_BYTES_MIN,
+};
+
+void csky_pcm_pio_push_tx(struct csky_i2s *i2s)
+{
+	struct snd_pcm_substream *tx_substream;
+	bool tx_active;
+	bool period_elapsed;
+	unsigned int tx_ptr;
+	unsigned int new_tx_ptr;
+
+#ifdef RCU_USED
+	rcu_read_lock();
+	tx_substream = rcu_dereference(i2s->tx_substream);
+#else
+	tx_substream = i2s->tx_substream;
+#endif
+
+	tx_active = tx_substream && snd_pcm_running(tx_substream);
+	if (tx_active) {
+		tx_ptr = READ_ONCE(i2s->tx_ptr);
+		new_tx_ptr = i2s->tx_fn(i2s, tx_substream->runtime,
+					tx_ptr, &period_elapsed);
+	#ifdef CONFIG_HAVE_CMPXCHG_LOCAL
+		cmpxchg(&i2s->tx_ptr, tx_ptr, new_tx_ptr);
+	#else
+		if (i2s->tx_ptr == tx_ptr)
+			i2s->tx_ptr = new_tx_ptr;
+	#endif
+		if (period_elapsed)
+			snd_pcm_period_elapsed(tx_substream);
+	}
+
+#ifdef RCU_USED
+	rcu_read_unlock();
+#endif
+}
+EXPORT_SYMBOL_GPL(csky_pcm_pio_push_tx);
+
+static int csky_pcm_pio_open(struct snd_pcm_substream *substream)
+{
+	struct snd_pcm_runtime *runtime = substream->runtime;
+	struct snd_soc_pcm_runtime *rtd = substream->private_data;
+	struct csky_i2s *i2s = snd_soc_dai_get_drvdata(rtd->cpu_dai);
+
+	snd_soc_set_runtime_hwparams(substream, &csky_pcm_pio_hardware);
+	snd_pcm_hw_constraint_integer(runtime, SNDRV_PCM_HW_PARAM_PERIODS);
+	runtime->private_data = i2s;
+	return 0;
+}
+
+static int csky_pcm_pio_close(struct snd_pcm_substream *substream)
+{
+#ifdef RCU_USED
+	synchronize_rcu();
+#endif
+	return 0;
+}
+
+static int csky_pcm_pio_hw_params(struct snd_pcm_substream *substream,
+				  struct snd_pcm_hw_params *hw_params)
+{
+	struct snd_pcm_runtime *runtime = substream->runtime;
+	struct csky_i2s *i2s = runtime->private_data;
+	int ret;
+
+	if (params_channels(hw_params) > 2)
+		return -EINVAL;
+
+	if (substream->stream != SNDRV_PCM_STREAM_PLAYBACK) {
+		dev_err(i2s->dev, "only playback is available\n");
+		return -EINVAL;
+	}
+
+	switch (params_physical_width(hw_params)) {
+	case 16:
+		if (params_channels(hw_params) == 1)
+			i2s->tx_fn = csky_pcm_pio_tx_16_mono;
+		else
+			i2s->tx_fn = csky_pcm_pio_tx_16_stereo;
+		break;
+	case 24:
+		dev_err(i2s->dev, "storage size 24 not supported\n");
+		return -EINVAL;
+	case 32:
+		i2s->tx_fn = csky_pcm_pio_tx_32;
+		break;
+	default:
+		dev_err(i2s->dev, "invalid format\n");
+		return -EINVAL;
+	}
+
+	ret = snd_pcm_lib_malloc_pages(substream,
+				       params_buffer_bytes(hw_params));
+	if (ret < 0)
+		return ret;
+	else
+		return 0;
+}
+
+static int csky_pcm_pio_hw_free(struct snd_pcm_substream *substream)
+{
+	return snd_pcm_lib_free_pages(substream);
+}
+
+static int csky_pcm_pio_trigger(struct snd_pcm_substream *substream, int cmd)
+{
+	struct snd_pcm_runtime *runtime = substream->runtime;
+	struct csky_i2s *i2s = runtime->private_data;
+	int ret = 0;
+
+	switch (cmd) {
+	case SNDRV_PCM_TRIGGER_START:
+	case SNDRV_PCM_TRIGGER_RESUME:
+	case SNDRV_PCM_TRIGGER_PAUSE_RELEASE:
+		WRITE_ONCE(i2s->tx_ptr, 0);
+#ifdef RCU_USED
+		rcu_assign_pointer(i2s->tx_substream, substream);
+#else
+		i2s->tx_substream = substream;
+#endif
+		break;
+	case SNDRV_PCM_TRIGGER_STOP:
+	case SNDRV_PCM_TRIGGER_SUSPEND:
+	case SNDRV_PCM_TRIGGER_PAUSE_PUSH:
+#ifdef RCU_USED
+		rcu_assign_pointer(i2s->tx_substream, NULL);
+#else
+		i2s->tx_substream = NULL;
+#endif
+		break;
+	default:
+		ret = -EINVAL;
+		break;
+	}
+
+	return ret;
+}
+
+static snd_pcm_uframes_t
+csky_pcm_pio_pointer(struct snd_pcm_substream *substream)
+{
+	struct snd_pcm_runtime *runtime = substream->runtime;
+	struct csky_i2s *i2s = runtime->private_data;
+	snd_pcm_uframes_t pos = READ_ONCE(i2s->tx_ptr);
+
+	return pos < runtime->buffer_size ? pos : 0;
+}
+
+static int csky_pcm_pio_new(struct snd_soc_pcm_runtime *rtd)
+{
+	size_t size = csky_pcm_pio_hardware.buffer_bytes_max;
+
+	return snd_pcm_lib_preallocate_pages_for_all(rtd->pcm,
+			SNDRV_DMA_TYPE_CONTINUOUS,
+			snd_dma_continuous_data(GFP_KERNEL), size, size);
+}
+
+static void csky_pcm_pio_free(struct snd_pcm *pcm)
+{
+	snd_pcm_lib_preallocate_free_for_all(pcm);
+}
+
+static const struct snd_pcm_ops csky_pcm_pio_ops = {
+	.open = csky_pcm_pio_open,
+	.close = csky_pcm_pio_close,
+	.ioctl = snd_pcm_lib_ioctl,
+	.hw_params = csky_pcm_pio_hw_params,
+	.hw_free = csky_pcm_pio_hw_free,
+	.trigger = csky_pcm_pio_trigger,
+	.pointer = csky_pcm_pio_pointer,
+};
+
+static const struct snd_soc_platform_driver csky_pcm_pio_platform = {
+	.pcm_new = csky_pcm_pio_new,
+	.pcm_free = csky_pcm_pio_free,
+	.ops = &csky_pcm_pio_ops,
+};
+
+int csky_pcm_pio_register(struct platform_device *pdev)
+{
+	return devm_snd_soc_register_platform(&pdev->dev,
+					      &csky_pcm_pio_platform);
+}
+EXPORT_SYMBOL_GPL(csky_pcm_pio_register);
diff --git a/addons/sound/soc/csky/csky-pcm.c b/addons/sound/soc/csky/csky-pcm.c
new file mode 100644
index 0000000..a9d5f46
--- /dev/null
+++ b/addons/sound/soc/csky/csky-pcm.c
@@ -0,0 +1,600 @@
+/*
+ * C-SKY SoCs I2S PCM driver
+ *
+ * Copyright (C) 2017 C-SKY MicroSystems Co.,Ltd.
+ *
+ * Author: Lei Ling <lei_ling@c-sky.com>
+ *
+ * based on soc-generic-dmaengine-pcm.c
+ *
+ * This software is licensed under the terms of the GNU General Public
+ * License version 2, as published by the Free Software Foundation, and
+ * may be copied, distributed, and modified under those terms.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/dmaengine.h>
+#include <linux/slab.h>
+#include <sound/pcm.h>
+#include <sound/pcm_params.h>
+#include <sound/soc.h>
+#include <linux/dma-mapping.h>
+#include <linux/of.h>
+
+#include <sound/dmaengine_pcm.h>
+#include <linux/dma/dw.h>
+
+struct dmaengine_pcm_runtime_data {
+	struct dma_chan *dma_chan;
+	dma_cookie_t cookie;
+	unsigned int pos;
+};
+
+static inline struct dmaengine_pcm_runtime_data *
+substream_to_prtd(const struct snd_pcm_substream *substream)
+{
+	return substream->runtime->private_data;
+}
+
+static void dmaengine_pcm_dma_complete(void *arg)
+{
+	struct snd_pcm_substream *substream = arg;
+	struct dmaengine_pcm_runtime_data *prtd = substream_to_prtd(substream);
+
+	prtd->pos += snd_pcm_lib_period_bytes(substream);
+	if (prtd->pos >= snd_pcm_lib_buffer_bytes(substream))
+		prtd->pos = 0;
+
+	snd_pcm_period_elapsed(substream);
+}
+
+static int
+csky_dmaengine_pcm_prepare_and_submit(struct snd_pcm_substream *substream)
+{
+	struct dmaengine_pcm_runtime_data *prtd = substream_to_prtd(substream);
+	struct dma_chan *chan = prtd->dma_chan;
+	struct dma_async_tx_descriptor *desc;
+	enum dma_transfer_direction direction;
+	unsigned long flags = DMA_CTRL_ACK;
+	struct dw_cyclic_desc *cdesc;
+
+	direction = snd_pcm_substream_to_dma_direction(substream);
+
+	if (!substream->runtime->no_period_wakeup)
+		flags |= DMA_PREP_INTERRUPT;
+
+	prtd->pos = 0;
+
+	cdesc = dw_dma_cyclic_prep(chan,
+				   substream->runtime->dma_addr,
+				   snd_pcm_lib_buffer_bytes(substream),
+				   snd_pcm_lib_period_bytes(substream),
+				   direction);
+	if (IS_ERR(cdesc)) {
+		return PTR_ERR(cdesc);
+	}
+
+	cdesc->period_callback = dmaengine_pcm_dma_complete;
+	cdesc->period_callback_param = substream;
+	return 0;
+}
+
+static int
+csky_snd_dmaengine_pcm_trigger(struct snd_pcm_substream *substream, int cmd)
+{
+	struct dmaengine_pcm_runtime_data *prtd = substream_to_prtd(substream);
+	struct snd_pcm_runtime *runtime = substream->runtime;
+	int ret;
+
+	switch (cmd) {
+	case SNDRV_PCM_TRIGGER_START:
+	case SNDRV_PCM_TRIGGER_RESUME:
+	case SNDRV_PCM_TRIGGER_PAUSE_RELEASE:
+		ret = csky_dmaengine_pcm_prepare_and_submit(substream);
+		if (ret)
+			return ret;
+
+		dw_dma_cyclic_start(prtd->dma_chan);
+		break;
+
+	case SNDRV_PCM_TRIGGER_STOP:
+	case SNDRV_PCM_TRIGGER_SUSPEND:
+	case SNDRV_PCM_TRIGGER_PAUSE_PUSH:
+		dw_dma_cyclic_stop(prtd->dma_chan);
+		break;
+	default:
+		return -EINVAL;
+	}
+
+	return 0;
+}
+
+int csky_snd_pcm_lib_free_pages(struct snd_pcm_substream *substream)
+{
+	struct snd_pcm_runtime *runtime;
+
+	if (PCM_RUNTIME_CHECK(substream))
+		return -EINVAL;
+
+	runtime = substream->runtime;
+	if (runtime->dma_area == NULL)
+		return 0;
+
+	dw_dma_cyclic_free(snd_dmaengine_pcm_get_chan(substream));
+
+	if (runtime->dma_buffer_p != &substream->dma_buffer) {
+		/* it's a newly allocated buffer.  release it now. */
+		snd_dma_free_pages(runtime->dma_buffer_p);
+		kfree(runtime->dma_buffer_p);
+	}
+	snd_pcm_set_runtime_buffer(substream, NULL);
+	return 0;
+}
+
+/*
+ * The platforms dmaengine driver does not support reporting the amount of
+ * bytes that are still left to transfer.
+ */
+#define SND_DMAENGINE_PCM_FLAG_NO_RESIDUE BIT(31)
+
+struct dmaengine_pcm {
+	struct dma_chan *chan[SNDRV_PCM_STREAM_LAST + 1];
+	const struct snd_dmaengine_pcm_config *config;
+	struct snd_soc_platform platform;
+	unsigned int flags;
+};
+
+static struct dmaengine_pcm *soc_platform_to_pcm(struct snd_soc_platform *p)
+{
+	return container_of(p, struct dmaengine_pcm, platform);
+}
+
+static struct device *dmaengine_dma_dev(struct dmaengine_pcm *pcm,
+	struct snd_pcm_substream *substream)
+{
+	if (!pcm->chan[substream->stream])
+		return NULL;
+
+	return pcm->chan[substream->stream]->device->dev;
+}
+
+int csky_snd_dmaengine_pcm_prepare_slave_config(
+		struct snd_pcm_substream *substream,
+		struct snd_pcm_hw_params *params,
+		struct dma_slave_config *slave_config)
+{
+	struct snd_soc_pcm_runtime *rtd = substream->private_data;
+	struct snd_dmaengine_dai_dma_data *dma_data;
+	int ret;
+
+	dma_data = snd_soc_dai_get_dma_data(rtd->cpu_dai, substream);
+
+	ret = snd_hwparams_to_dma_slave_config(substream, params, slave_config);
+	if (ret)
+		return ret;
+
+	snd_dmaengine_pcm_set_config_from_dai_data(substream,
+						   dma_data, slave_config);
+	return 0;
+}
+EXPORT_SYMBOL_GPL(csky_snd_dmaengine_pcm_prepare_slave_config);
+
+static int dmaengine_pcm_hw_params(struct snd_pcm_substream *substream,
+	struct snd_pcm_hw_params *params)
+{
+	struct snd_soc_pcm_runtime *rtd = substream->private_data;
+	struct dmaengine_pcm *pcm = soc_platform_to_pcm(rtd->platform);
+	struct dma_chan *chan = snd_dmaengine_pcm_get_chan(substream);
+	int (*prepare_slave_config)(struct snd_pcm_substream *substream,
+				    struct snd_pcm_hw_params *params,
+				    struct dma_slave_config *slave_config);
+	struct dma_slave_config slave_config;
+	int ret;
+
+	memset(&slave_config, 0, sizeof(slave_config));
+
+	if (!pcm->config)
+		prepare_slave_config =
+			csky_snd_dmaengine_pcm_prepare_slave_config;
+	else
+		prepare_slave_config = pcm->config->prepare_slave_config;
+
+	if (prepare_slave_config) {
+		ret = prepare_slave_config(substream, params, &slave_config);
+		if (ret)
+			return ret;
+
+		ret = dmaengine_slave_config(chan, &slave_config);
+		if (ret)
+			return ret;
+	}
+
+	return snd_pcm_lib_malloc_pages(substream, params_buffer_bytes(params));
+}
+
+static int
+dmaengine_pcm_set_runtime_hwparams(struct snd_pcm_substream *substream)
+{
+	struct snd_soc_pcm_runtime *rtd = substream->private_data;
+	struct dmaengine_pcm *pcm = soc_platform_to_pcm(rtd->platform);
+	struct device *dma_dev = dmaengine_dma_dev(pcm, substream);
+	struct dma_chan *chan = pcm->chan[substream->stream];
+	struct snd_dmaengine_dai_dma_data *dma_data;
+	struct dma_slave_caps dma_caps;
+	struct snd_pcm_hardware hw;
+	u32 addr_widths = BIT(DMA_SLAVE_BUSWIDTH_1_BYTE) |
+			  BIT(DMA_SLAVE_BUSWIDTH_2_BYTES) |
+			  BIT(DMA_SLAVE_BUSWIDTH_4_BYTES);
+	int i, ret;
+
+	if (pcm->config && pcm->config->pcm_hardware)
+		return snd_soc_set_runtime_hwparams(substream,
+				pcm->config->pcm_hardware);
+
+	dma_data = snd_soc_dai_get_dma_data(rtd->cpu_dai, substream);
+
+	memset(&hw, 0, sizeof(hw));
+	hw.info = SNDRV_PCM_INFO_MMAP | SNDRV_PCM_INFO_MMAP_VALID |
+		  SNDRV_PCM_INFO_INTERLEAVED;
+	hw.periods_min = 2;
+	hw.periods_max = UINT_MAX;
+	hw.period_bytes_min = 256;
+	hw.period_bytes_max = dma_get_max_seg_size(dma_dev);
+	hw.buffer_bytes_max = SIZE_MAX;
+	hw.fifo_size = dma_data->fifo_size;
+
+	if (pcm->flags & SND_DMAENGINE_PCM_FLAG_NO_RESIDUE)
+		hw.info |= SNDRV_PCM_INFO_BATCH;
+
+	ret = dma_get_slave_caps(chan, &dma_caps);
+	if (ret == 0) {
+		if (dma_caps.cmd_pause)
+			hw.info |= SNDRV_PCM_INFO_PAUSE | SNDRV_PCM_INFO_RESUME;
+		if (dma_caps.residue_granularity <=
+					DMA_RESIDUE_GRANULARITY_SEGMENT)
+			hw.info |= SNDRV_PCM_INFO_BATCH;
+
+		if (substream->stream == SNDRV_PCM_STREAM_PLAYBACK)
+			addr_widths = dma_caps.dst_addr_widths;
+		else
+			addr_widths = dma_caps.src_addr_widths;
+	}
+
+	/*
+	 * If SND_DMAENGINE_PCM_DAI_FLAG_PACK is set keep
+	 * hw.formats set to 0, meaning no restrictions are in place.
+	 * In this case it's the responsibility of the DAI driver to
+	 * provide the supported format information.
+	 */
+	if (!(dma_data->flags & SND_DMAENGINE_PCM_DAI_FLAG_PACK))
+		/*
+		 * Prepare formats mask for valid/allowed sample types. If the
+		 * dma does not have support for the given physical word size,
+		 * it needs to be masked out so user space can not use the
+		 * format which produces corrupted audio.
+		 * In case the dma driver does not implement the slave_caps the
+		 * default assumption is that it supports 1, 2 and 4 bytes
+		 * widths.
+		 */
+		for (i = 0; i <= SNDRV_PCM_FORMAT_LAST; i++) {
+			int bits = snd_pcm_format_physical_width(i);
+
+			/*
+			 * Enable only samples with DMA supported physical
+			 * widths
+			 */
+			switch (bits) {
+			case 8:
+			case 16:
+			case 24:
+			case 32:
+			case 64:
+				if (addr_widths & (1 << (bits / 8)))
+					hw.formats |= (1LL << i);
+				break;
+			default:
+				/* Unsupported types */
+				break;
+			}
+		}
+
+	return snd_soc_set_runtime_hwparams(substream, &hw);
+}
+
+static int dmaengine_pcm_open(struct snd_pcm_substream *substream)
+{
+	struct snd_soc_pcm_runtime *rtd = substream->private_data;
+	struct dmaengine_pcm *pcm = soc_platform_to_pcm(rtd->platform);
+	struct dma_chan *chan = pcm->chan[substream->stream];
+	int ret;
+
+	ret = dmaengine_pcm_set_runtime_hwparams(substream);
+	if (ret)
+		return ret;
+
+	snd_pcm_hw_constraint_pow2(substream->runtime, 0,
+				   SNDRV_PCM_HW_PARAM_BUFFER_BYTES);
+	snd_pcm_hw_constraint_pow2(substream->runtime, 0,
+				   SNDRV_PCM_HW_PARAM_PERIOD_BYTES);
+	snd_pcm_hw_constraint_integer(substream->runtime,
+				      SNDRV_PCM_HW_PARAM_PERIODS);
+
+	return snd_dmaengine_pcm_open(substream, chan);
+}
+
+static struct dma_chan *dmaengine_pcm_compat_request_channel(
+	struct snd_soc_pcm_runtime *rtd,
+	struct snd_pcm_substream *substream)
+{
+	struct dmaengine_pcm *pcm = soc_platform_to_pcm(rtd->platform);
+	struct snd_dmaengine_dai_dma_data *dma_data;
+	dma_filter_fn fn = NULL;
+
+	dma_data = snd_soc_dai_get_dma_data(rtd->cpu_dai, substream);
+
+	if ((pcm->flags & SND_DMAENGINE_PCM_FLAG_HALF_DUPLEX) && pcm->chan[0])
+		return pcm->chan[0];
+
+	if (pcm->config && pcm->config->compat_request_channel)
+		return pcm->config->compat_request_channel(rtd, substream);
+
+	if (pcm->config)
+		fn = pcm->config->compat_filter_fn;
+
+	return snd_dmaengine_pcm_request_channel(fn, dma_data->filter_data);
+}
+
+static bool dmaengine_pcm_can_report_residue(struct device *dev,
+	struct dma_chan *chan)
+{
+	struct dma_slave_caps dma_caps;
+	int ret;
+
+	ret = dma_get_slave_caps(chan, &dma_caps);
+	if (ret != 0) {
+		dev_warn(dev, "Failed to get DMA channel capabilities\n");
+		return false;
+	}
+
+	if (dma_caps.residue_granularity == DMA_RESIDUE_GRANULARITY_DESCRIPTOR)
+		return false;
+
+	return true;
+}
+
+static int dmaengine_pcm_new(struct snd_soc_pcm_runtime *rtd)
+{
+	struct dmaengine_pcm *pcm = soc_platform_to_pcm(rtd->platform);
+	const struct snd_dmaengine_pcm_config *config = pcm->config;
+	struct device *dev = rtd->platform->dev;
+	struct snd_dmaengine_dai_dma_data *dma_data;
+	struct snd_pcm_substream *substream;
+	size_t prealloc_buffer_size;
+	size_t max_buffer_size;
+	unsigned int i;
+	int ret;
+
+	if (config && config->prealloc_buffer_size) {
+		prealloc_buffer_size = config->prealloc_buffer_size;
+		max_buffer_size = config->pcm_hardware->buffer_bytes_max;
+	} else {
+		prealloc_buffer_size = 512 * 1024;
+		max_buffer_size = SIZE_MAX;
+	}
+
+
+	for (i = SNDRV_PCM_STREAM_PLAYBACK;
+	     i <= SNDRV_PCM_STREAM_CAPTURE; i++) {
+		substream = rtd->pcm->streams[i].substream;
+		if (!substream)
+			continue;
+
+		dma_data = snd_soc_dai_get_dma_data(rtd->cpu_dai, substream);
+
+		if (!pcm->chan[i] &&
+		    (pcm->flags & SND_DMAENGINE_PCM_FLAG_CUSTOM_CHANNEL_NAME))
+			pcm->chan[i] = dma_request_slave_channel(dev,
+				dma_data->chan_name);
+
+		if (!pcm->chan[i] &&
+		    (pcm->flags & SND_DMAENGINE_PCM_FLAG_COMPAT)) {
+			pcm->chan[i] = dmaengine_pcm_compat_request_channel(rtd,
+				substream);
+		}
+
+		if (!pcm->chan[i]) {
+			dev_err(rtd->platform->dev,
+				"Missing dma channel for stream: %d\n", i);
+			return -EINVAL;
+		}
+
+		ret = snd_pcm_lib_preallocate_pages(substream,
+				SNDRV_DMA_TYPE_DEV,
+				dmaengine_dma_dev(pcm, substream),
+				prealloc_buffer_size,
+				max_buffer_size);
+		if (ret)
+			return ret;
+
+		if (!dmaengine_pcm_can_report_residue(dev, pcm->chan[i]))
+			pcm->flags |= SND_DMAENGINE_PCM_FLAG_NO_RESIDUE;
+	}
+
+	return 0;
+}
+
+static snd_pcm_uframes_t dmaengine_pcm_pointer(
+	struct snd_pcm_substream *substream)
+{
+	struct snd_pcm_runtime	*runtime = substream->runtime;
+	snd_pcm_uframes_t	frames;
+	unsigned long		bytes;
+
+	bytes = dw_dma_get_src_addr(snd_dmaengine_pcm_get_chan(substream));
+	bytes -= runtime->dma_addr;
+
+	frames = bytes_to_frames(runtime, bytes);
+	if (frames >= runtime->buffer_size)
+		frames -= runtime->buffer_size;
+
+	return frames;
+}
+
+static const struct snd_pcm_ops dmaengine_pcm_ops = {
+	.open		= dmaengine_pcm_open,
+	.close		= snd_dmaengine_pcm_close,
+	.ioctl		= snd_pcm_lib_ioctl,
+	.hw_params	= dmaengine_pcm_hw_params,
+	.hw_free	= csky_snd_pcm_lib_free_pages,
+	.trigger	= csky_snd_dmaengine_pcm_trigger,
+	.pointer	= dmaengine_pcm_pointer,
+};
+
+static const struct snd_soc_platform_driver dmaengine_pcm_platform = {
+	.component_driver = {
+		.probe_order = SND_SOC_COMP_ORDER_LATE,
+	},
+	.ops		= &dmaengine_pcm_ops,
+	.pcm_new	= dmaengine_pcm_new,
+};
+
+static const char * const dmaengine_pcm_dma_channel_names[] = {
+	[SNDRV_PCM_STREAM_PLAYBACK] = "tx",
+	[SNDRV_PCM_STREAM_CAPTURE] = "rx",
+};
+
+static int dmaengine_pcm_request_chan_of(struct dmaengine_pcm *pcm,
+	struct device *dev, const struct snd_dmaengine_pcm_config *config)
+{
+	unsigned int i;
+	const char *name;
+	struct dma_chan *chan;
+
+	if ((pcm->flags & (SND_DMAENGINE_PCM_FLAG_NO_DT |
+			   SND_DMAENGINE_PCM_FLAG_CUSTOM_CHANNEL_NAME)) ||
+	    !dev->of_node)
+		return 0;
+
+	if (config && config->dma_dev) {
+		/*
+		 * If this warning is seen, it probably means that your Linux
+		 * device structure does not match your HW device structure.
+		 * It would be best to refactor the Linux device structure to
+		 * correctly match the HW structure.
+		 */
+		dev_warn(dev, "DMA channels sourced from device %s",
+			 dev_name(config->dma_dev));
+		dev = config->dma_dev;
+	}
+
+	for (i = SNDRV_PCM_STREAM_PLAYBACK; i <= SNDRV_PCM_STREAM_CAPTURE;
+	     i++) {
+		if (pcm->flags & SND_DMAENGINE_PCM_FLAG_HALF_DUPLEX)
+			name = "rx-tx";
+		else
+			name = dmaengine_pcm_dma_channel_names[i];
+		if (config && config->chan_names[i])
+			name = config->chan_names[i];
+		chan = dma_request_slave_channel_reason(dev, name);
+		if (IS_ERR(chan)) {
+			if (PTR_ERR(chan) == -EPROBE_DEFER)
+				return -EPROBE_DEFER;
+			pcm->chan[i] = NULL;
+		} else {
+			pcm->chan[i] = chan;
+		}
+		if (pcm->flags & SND_DMAENGINE_PCM_FLAG_HALF_DUPLEX)
+			break;
+	}
+
+	if (pcm->flags & SND_DMAENGINE_PCM_FLAG_HALF_DUPLEX)
+		pcm->chan[1] = pcm->chan[0];
+
+	return 0;
+}
+
+static void dmaengine_pcm_release_chan(struct dmaengine_pcm *pcm)
+{
+	unsigned int i;
+
+	for (i = SNDRV_PCM_STREAM_PLAYBACK; i <= SNDRV_PCM_STREAM_CAPTURE;
+	     i++) {
+		if (!pcm->chan[i])
+			continue;
+		dma_release_channel(pcm->chan[i]);
+		if (pcm->flags & SND_DMAENGINE_PCM_FLAG_HALF_DUPLEX)
+			break;
+	}
+}
+
+/**
+ * csky_snd_dmaengine_pcm_register - Register a dmaengine based PCM device
+ * @dev: The parent device for the PCM device
+ * @config: Platform specific PCM configuration
+ * @flags: Platform specific quirks
+ */
+int csky_snd_dmaengine_pcm_register(struct device *dev,
+		const struct snd_dmaengine_pcm_config *config,
+		unsigned int flags)
+{
+	struct dmaengine_pcm *pcm;
+	int ret;
+
+	pcm = kzalloc(sizeof(*pcm), GFP_KERNEL);
+	if (!pcm)
+		return -ENOMEM;
+
+	pcm->config = config;
+	pcm->flags = flags;
+
+	ret = dmaengine_pcm_request_chan_of(pcm, dev, config);
+	if (ret)
+		goto err_free_dma;
+
+	ret = snd_soc_add_platform(dev, &pcm->platform,
+		&dmaengine_pcm_platform);
+	if (ret)
+		goto err_free_dma;
+
+	return 0;
+
+err_free_dma:
+	dmaengine_pcm_release_chan(pcm);
+	kfree(pcm);
+	return ret;
+}
+EXPORT_SYMBOL_GPL(csky_snd_dmaengine_pcm_register);
+
+/**
+ * csky_snd_dmaengine_pcm_unregister - Removes a dmaengine based PCM device
+ * @dev: Parent device the PCM was register with
+ *
+ * Removes a dmaengine based PCM device previously registered with
+ * csky_snd_dmaengine_pcm_register.
+ */
+void csky_snd_dmaengine_pcm_unregister(struct device *dev)
+{
+	struct snd_soc_platform *platform;
+	struct dmaengine_pcm *pcm;
+
+	platform = snd_soc_lookup_platform(dev);
+	if (!platform)
+		return;
+
+	pcm = soc_platform_to_pcm(platform);
+
+	snd_soc_remove_platform(platform);
+	dmaengine_pcm_release_chan(pcm);
+	kfree(pcm);
+}
+EXPORT_SYMBOL_GPL(csky_snd_dmaengine_pcm_unregister);
+
+MODULE_DESCRIPTION("C-SKY SoCs I2S PCM Driver");
+MODULE_AUTHOR("Lei Ling <lei_ling@c-sky.com>");
+MODULE_LICENSE("GPL v2");
-- 
1.9.1

